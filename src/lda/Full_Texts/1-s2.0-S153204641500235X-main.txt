Journal of Biomedical Informatics 58 (2015) 235–246

Contents lists available at ScienceDirect

Journal of Biomedical Informatics
journal homepage: www.elsevier.com/locate/yjbin

Rough-set-based ADR signaling from spontaneous reporting data
with missing values
Wen-Yang Lin a,⇑, Lin Lan a, Feng-Hsiung Huang a,b, Min-Hsien Wang a
a
b

Dept. of Computer Science and Information Engineering, National University of Kaohsiung, Kaohsiung, Taiwan
Dept. of Pharmacy, Kaohsiung Veterans General Hospital, Kaohsiung, Taiwan

a r t i c l e

i n f o

Article history:
Received 30 April 2015
Revised 13 September 2015
Accepted 22 October 2015
Available online 29 October 2015
Keywords:
Adverse drug reaction
Missing data
Pharmacovigilance
Rough set theory
Spontaneous reporting data

a b s t r a c t
Spontaneous reporting systems of adverse drug events have been widely established in many countries
to collect as could as possible all adverse drug events to facilitate the detection of suspected ADR signals
via some statistical or data mining methods. Unfortunately, due to privacy concern or other reasons, the
reporters sometimes may omit consciously some attributes, causing many missing values existing in the
reporting database. Most of research work on ADR detection or methods applied in practice simply
adopted listwise deletion to eliminate all data with missing values. Very little work has noticed the possibility and examined the effect of including the missing data in the process of ADR detection.
This paper represents our endeavor towards the exploration of this question. We aim at inspecting the
feasibility of applying rough set theory to the ADR detection problem. Based on the concept of utilizing
characteristic set based approximation to measure the strength of ADR signals, we propose twelve different rough set based measuring methods and show only six of them are feasible for the purpose.
Experimental results conducted on the FARES database show that our rough-set-based approach exhibits
similar capability in timeline warning of suspicious ADR signals as traditional method with missing deletion, and sometimes can yield noteworthy measures earlier than the traditional method.
Ó 2015 Elsevier Inc. All rights reserved.

1. Introduction
Adverse Drug Reactions (ADRs) are uncomfortable or harmful
reactions (side effects) in normal doses of drug usage. In other
words, an ADR expresses the association between drugs and harmful side effects. Some serious ADRs may lead to death or lifethreatening outcomes of patients. For example, in 1950 the new
drug Thalidomide made in German caused more than 12,000 fetus
limb deformities and more than 1300 people were suffering from
polyneuritis for over 20 countries in Europe and Japan. Unfortunately, not all ADRs can be disclosed before the approval of drugs
for marketing. Therefore, spontaneous reporting systems (SRSs)
of adverse drug reactions have been widely established in many
countries to collect as could as possible all adverse drug events
to facilitate the detection of suspected ADR signals via some statistical or data mining methods.
Although different SRSs were running under different reporting
regulations, most of them require, when the patient produces
⇑ Corresponding author.
E-mail addresses: wylin@nuk.edu.tw (W.-Y. Lin), m1015516@mail.nuk.edu.tw
(L. Lan), ffhung@vghks.gov.tw (F.-H. Huang), m1025509@mail.nuk.edu.tw
(M.-H. Wang).
http://dx.doi.org/10.1016/j.jbi.2015.10.013
1532-0464/Ó 2015 Elsevier Inc. All rights reserved.

uncomfortable or harmful adverse reactions by normal drug of
usage, the responsible hospitals, related pharmaceutical companies should, and/or the patient himself can report the events to
SRSs. Unfortunately, the reporting data usually contain some missing values due to omitting or personal privacy concern. Data with
missing values may affect results of analysis, which leads to the
development of appropriate processing methods to increase the
accuracy of signal detection.
Most of the reporting systems use listwise deletion [12] to process data with missing values; that is, simply deleting records with
null values to maintain data completeness. The advantage of this
simple method is easy to implement for data analysis, while it
may affect the accuracy of the results, especially when the amount
of data is relatively small. Indeed, small non-missing data is not
uncommon for ADR reporting data. Firstly, records of rarely used
or newly marketed drugs usually are in small amount. Secondly,
the data size also decreases significantly when stratified signal
detection is performed [13], e.g., considering a specific group of
patients with dedicated age and/or sex. Although previous research
work has shown that rough set theory can be used to handle data
with missing values in the process of data analysis [11,17], e.g.,
data classification, there has been no work, to the best of our
knowledge, conducted on applying rough set theory to the ADR

236

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246

detection problem. This motivates us to study if incorporating
rough-set-based strategies to process the reporting data with missing values can be helpful for the detection of ADR signals.
In this paper, we present the concept of applying rough set theory to handling ADR detection from incomplete SRS dataset with
missing data, and propose twelve different methods for measuring
the strength of an ADR signal. We discuss the feasibility of the proposed twelve measuring methods and show only six of them are
suitable for ADR signal measuring. We conducted preliminary
experiments using the public FAERS datasets [9] to examine the
effectiveness of rough-set-based ADR detection against traditional
detection, from the viewpoint of timeline surveillance and warning
of marketed drugs. The results show that most of the time the
rough-set-based approach exhibits similar signaling capability to
that of traditional approach. However, in some cases our approach,
by providing an approximate range of signal strength, demonstrates better warning ability in timeline surveillance. This occurs
especially when the amount of event cases with no missing value
is relatively small, i.e., less than three, but the amount increases
dramatically when missing values are included.
The remainders of this paper are organized as follows. In Section 2, we introduce background knowledge related to this work,
including ADR detection and rough set theory. Section 3 presents
our proposed rough set based method for measuring ADR signals
from incomplete SRS data with missing values. In Section 4, we
show and discuss the results of the experiments conducted over
FAERS dataset. Finally, we describe conclusions and future work
in Section 5.
2. Background and related work
2.1. ADR detection
Contemporary detection methods of ADR signals can be broadly
divided into two categories [4]: frequentist methods and Bayesian
methods.
Frequentist methods are widely used in most real ADR monitoring systems due to their simplicity to calculate and interpret. This
category is mainly based on the statistical 2⁄2 contingency table as
shown in Table 1 to estimate the proportion of suspected ADRs in
spontaneous reporting systems caused by the drug of interest vs.
other drugs. If the ratio is higher than a threshold, then disproportionality occurs, which means the drug of interest is regarded to
have a significant association with the suspected reaction. In the
past decade, there have been various frequentist methods, each
of which differs mainly on the metric for measuring the disproportionality. The most representative metrics are Proportional Reporting Ratio (PRR) [8] and Reporting Odds Ratio (ROR) [7]. Formulas of
these two measures are defined as follows:

PRR ¼

a=ða þ bÞ
;
c=ðc þ dÞ

ROR ¼

a=c
b=d

Table 1
The 2  2 contingency table for ADR signal detection.

Drug of interest
Other drugs
Total

Another category of more complex methods, Bayesian methods,
were developed based on Bayesian statistics to estimate the (posterior) probability that the suspected adverse reaction occurs given
the use of the suspected drug. Representatives of this category are
Bayesian Confidence Propagation Neural Network (BCPNN) [2,3]
and Multi-item Gamma Poisson Shrinker (MGPS) [1].
In the field of adverse drug reactions, most of detection methods can be used and every method has its own advantages and disadvantages. Therefore, one can select one or more suitable
detection methods according to different analysis purposes.
2.2. Rough set theory
The rough set theory [16] is a useful tool for the analysis of
imprecise, uncertainly or incomplete data. The theory is based on
the concept of rough set, a formal approximation of a crisp set
composed of objects represented by values of attributes. Classically, the set of objects concerned is represented as an information
system or information table. In the following, we introduce the
basic concepts of rough set theory and its extension to handle data
with missing values.
(1) Information system and decision table: An information system
is a pair IS ¼ fU; Ag, where U denotes a nonempty finite set
of objects called the universe and A denotes a nonempty
finite set of attributes. A decision table is a special form of
information systems, in which the attribute set A is divided
into a set of conditional attributes C and a decision attribute
d, i.e. A ¼ C [ fdg. For example, in Table 2 there are three
condition attributes A ¼ fHeight; Weight; Ageg and one decision attribute d ¼ fOv erweightg.
(2) Indiscernibility relation: Consider an information system
IS ¼ fU; Ag. Let B # A be a subset of attributes. The indiscernibility relation induced by B, denoted as IB , is an equivalence relation defined as

ðx; yÞ 2 IB if and only if for all a 2 B; aðx; aÞ ¼ aðy; aÞ;
where x and y are two cases in IS, and aðx; aÞ and aðy; aÞ
denote the values of x and y, respectively, in attribute a. In
other words, the indiscernibility relation induced by B
defines a set of equivalence classes, within each of which
the members have the same values in all attributes in B.
For example, if B = {Weight, Age}, clearly ð2; 5Þ 2 IB since both
cases have the same weight and age. And all cases in Table 2
will be divided into six equivalence classes, i.e., {1, 4}, {2, 5},
{3}, {6}, {7}, {8}.
(3) Lower and upper approximations: Let X represent a subset of
elements of the universe U. The lower approximation indicates the set of elements certainly belonging to the set X,
while the upper approximation indicates the set of elements
possibly belonging to the set X. Given an information system
IS ¼ ðU; AÞ and P # A, the lower approximation of X induced
by P in IS, denoted as PX, and the upper approximation of
X induced by P in IS, denoted as PX, are defined as follows:
Table 2
An example of decision table.

Reaction of interest

Other reactions

Total

Case

Height

Weight

Age

Overweight

a
c
aþc

b
d
bþd

aþb
cþd
N=a+b+c+d

1
2
3
4
5
6
7
8

170
165
165
145
145
170
145
170

75
50
60
75
50
45
50
45

18
30
18
18
30
45
45
30

Yes
Yes
No
No
No
Yes
No
Yes

a: number of reports of the suspected drug lead to the suspected reaction.
b: number of reports of the suspected drug lead to all other reactions.
c: number of reports of all other drugs in the database lead to the suspected
reactions.
d: number of reports of all other drugs lead to all other reactions.

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246

PX ¼ fe 2 Uj½eP # Xg;

PX ¼ fe 2 Uj½eP \ X – £g

where ½eP denotes the equivalence class of e induced by attribute set P. For example, consider Table 2. Let X = {1, 2, 6, 8}
and P = {Weight, Age}. Below are the equivalence classes of
each case.

½1P ¼ f1; 4g;

½2P ¼ f2; 5g;

½5P ¼ f2; 5g;

½6P ¼ f6g;

½3P ¼ f3g;
½7P ¼ f7g;

PX ¼ f1; 2; 4; 5; 6; 8g

(4) Accuracy of approximations: The accuracy of an approximation of X induced by P, denoted as rP ðXÞ, is calculated as
dividing the cardinality of the lower approximation by the
cardinality of the upper approximation, i.e.,

rP ðXÞ ¼

jPXj
:
jPXj

Grzymala-Busse, considers both ‘‘lost” and ‘‘don’t care” missing
values. Since the characteristic relation is a general form of the tolerance and similarity relations, in this paper we adopt this term
(denoted as R), and use subscripts T and S to denote the tolerance
(RT ) and similarity versions ðRS Þ, respectively.
Definition 1. Let P # A be a subset of attributes. The similarity
characteristic relation, denoted by RS ðPÞ, is defined as:

½4P ¼ f1; 4g;
½8P ¼ f8g

And the lower and upper approximations of X induced by P
are:

PX ¼ f6; 8g;

237

ð1Þ

If rP ðXÞ ¼ 1, the lower and upper approximations are identical, and we say subset X is definable in U in terms of attribute
set P. In other words, X can be regarded as not ‘‘imprecise” in
terms of P, and so there is no room of vagueness needed to be
captured by applying rough set theory. If rP ðXÞ < 1, subset X
can be defined by its lower and upper approximation and is
roughly definable in U in terms of P.

ðx; yÞ 2 RS ðPÞ if and only if aðx; aÞ ¼ aðy; aÞ for all

a 2 P such that aðx; aÞ – ?:

And the similarity characteristic set is defined as K S ðP; xÞ ¼
fyjðx; yÞ 2 RS ðPÞg, where x and y are two cases in the decision table,
and aðx; aÞ denotes the value of x in attribute a.
Definition 2. Let P # A be a subset of attributes. The tolerance
characteristic relation, denoted by RT ðPÞ, is defined as:

ðx; yÞ 2 RT ðPÞ if and only if aðx; aÞ ¼ aðy; aÞ or

aðx; aÞ ¼  or aðy; aÞ ¼  for all a 2 P:

And the tolerance characteristic set is K T ðP; xÞ ¼ fyjðx; yÞ 2 RT ðPÞg.
Example 1. Consider Table 3. Let P = {Height, Weight, Gender}. Then
the similarity and tolerance characteristic sets of all cases induced
by P are:

K S ðP; 1Þ ¼ f1g

K T ðP; 1Þ ¼ f1; 5g

K S ðP; 2Þ ¼ f2; 4g K T ðP; 2Þ ¼ f2; 4g

2.3. Rough set strategies to data with missing data
In real world applications, a data collection usually contains
missing values, making the data incomplete for analysis. Classically, the data is usually presented in the form of a decision table,
where missing values can be interpreted from two aspects: lost
and do not care. A ‘‘lost” missing value, denoted as ‘‘?”, indicates
that the value is important but is erased, and a ‘‘don’t care” missing
value, denoted as ‘‘⁄”, indicates that the value is not important or
redundant (see Table 3).
Various researchers have extended rough set theory for dealing
with data with missing values [10,14,18]. We only present the concepts that are useful in our research, including the characteristic
relation, characteristic set, and the refined lower and upper
approximations.
The conventional rough set theory is under the assumption that
information systems are complete, i.e., without missing data, and
relies on the indiscernibility relation to derive the concept of lower
and upper approximations. However, the indiscernibility relation
is not applicable to data with missing values. Different extensions
of the indiscernibility relation have been proposed, including the
tolerance relation [14], similarity relation [18], and characteristic
relation [10], which are described in what follows.
The tolerance relation was proposed by Kryszkiewicz to process
data with ‘‘don’t care” missing values, the similarity relation was
proposed by Stefanowski and Tsoukias to process data with ‘‘lost”
missing values, while the characteristic relation, proposed by

Table 3
An example of an incomplete decision table containing ‘‘lost” (?) or ‘‘don’t care” (⁄)
missing values.
Case

Height

Weight

Gender

Overweight

1
2
3
4
5

170
165
170
165
?/⁄

50
?/⁄
80
50
?/⁄

Male
Female
?/⁄
Female
Male

Yes
No
No
No
Yes

K S ðP; 3Þ ¼ f3g
K S ðP; 4Þ ¼ f4g

K T ðP; 3Þ ¼ f3; 5g
K T ðP; 4Þ ¼ f2; 4g

K S ðP; 5Þ ¼ f1; 5g K T ðP; 5Þ ¼ f1; 3; 5g
Based on the concept of characteristic relation and characteristic set, Grzymala-Busse [10] proposed three different extensions of
the lower and upper approximations for processing data with
missing values: singleton, subset, and concept approximations.
The first extension is called singleton approximation, which
considers all cases in U and is similar to the original definitions of
lower and upper approximations. Hereafter, for identification
purpose we add subscripts g (singleton), s (subset), and c (concept)
into the approximation, and add superscript K (stand for characteristic relation) to distinguish it from the conventional approximation derived by indiscernibility relation.
Definition 3. The singleton lower approximation of X induced by
P, denoted by P Kg X, is the set of all cases whose characteristic set
is contained in X, i.e.,

PKg X ¼ fx 2 UjKðP; xÞ # Xg
The singleton upper approximation of X in P, denoted by P Kg X, is the
set of cases whose characteristic set having an non-empty intersection with X, i.e.,

PKg X ¼ fx 2 UjKðP; xÞ \ X – £g
Note that the characteristic set KðP; xÞ presented in the above
definition can be any types of characteristic sets. The second extension, called subset approximation, uses the union of characteristic
sets to define approximation.
Definition 4. The subset lower approximation of X induced by
P; P Ks X, is the union of characteristic sets that are contained in X, i.e.,

PKs X ¼ [fKðP; xÞjx 2 U; KðP; xÞ # Xg

238

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246

The subset upper approximation of X induced by P; PKs X, is the
union of characteristic sets which have an nonempty intersection
with X, i.e.,

PKs X ¼ [fKðP; xÞjx 2 U; KðP; xÞ \ X – £g
The third definition called concept approximation is more stringent than the subset version in that it only considers those cases in
X.
Definition 5. The concept lower and upper approximations of X
induced by P are defined as follows:

PKc X ¼ [fKðP; xÞjx 2 X; KðP; xÞ # Xg

of this rule is over a specified threshold to becoming a noteworthy
ADR signal.
In this study, the SRS data was obtained from the FDA Adverse
Event Reporting System (FAERS) database [9]. The FAERS database
is composed of seven data files, including DEMO, DRUG, REAC,
OUTC, RPSR, THER, and INDI. We selected three data files that are
essential for ADR signal detection, i.e., DEMO, DRUG, and REAC.
From the DEMO data file we chosen four attributes about personal
information of patients, including ISR (primary report id),
EVENT_DT, AGE, and GNDR_COD. These attributes except ISR
may contain null values. From the DRUG and REAC files we chosen
the DRUGNAME and PT attributes, which do not contain null values. Details of the chosen attributes are presented in Table 4.
3.2. Rough set based measuring

PKc X ¼ [fKðP; xÞjx 2 X; KðP; xÞ \ X – £g
Example 2. Let X be the set of cases with Overweight = ‘‘Yes” in
Table 3, i.e., X = {1, 5} and P = {Height, Weight, Gender}. The corresponding singleton, subset, and concept approximations of X are:

Since all contemporary measures relies on the contingency
2  2 table, our basic idea is applying rough set theory to the calculation of the contingency 2  2 table. Consider the rule in (2)
and the following corresponding contingency table.

PKg f1; 5g ¼ f1g PKs f1; 5g ¼ f1; 5g PKc f1; 5g ¼ f1g

Predc

symptom

other symptoms

PKg f1; 5g ¼ f1; 3; 5g PKs f1; 5g ¼ f1; 3; 5g PKc f1; 5g ¼ f1; 3; 5g

drug
other drugs

a
c

b
d

Note that for complete decision tables, all of the three approximations, singleton, subset, and concept, are amalgamated into the
same definition. However, it is not true for incomplete decision
tables.

3. Rough set based ADR detection
3.1. Problem description
As mentioned in Section 1, the SRS data may contain some
missing values due to omitting or personal privacy problem. To
facilitate the discussion, the reporting data is presented as an information system IS ¼ ðU; AÞ containing missing values which can be
either one of two categories: lost (?) or don’t care (⁄). Our purpose
is to examine the feasibility of rough set theory to the ADR detection, focusing on whether the inclusion of missing data through
rough set based approximation can be helpful for the predicting
capability of generated signals. Therefore, the problem can be
described as given a SRS dataset that contains missing values and
is represented in the form of a data table, we like to compute the
strength (using PRR or ROR measure) of any given suspected ADR
rule of the following form:

Predc; drug ! symptom

ð2Þ

where Predc denotes extra conditions associated with the signal,
e.g., Sex = ‘‘female”, Age = ‘‘>18”, and we will examine if the strength

Table 4
Description of the attributes selected from the FAERS dataset.
File name

Selected attribute
name

Containing
null values

Null
probability (07Q2)

DEMO

ISR
EVENT_DT
AGE
GNDR_COD


p
p
p

0
31.3
38.8
5.8

DRUG
REAC

DRUGNAME
PT




0
0

DEMO: to record personal information for each patient.
DRUG: to record the medicines taken by each patient.
REAC: to record the observed adverse reactions for each report.

If the information system is complete, then each of the cell values, a; b; c; d, on the contingency table are deterministic. Unfortunately, as we have shown previously, the attributes involved in
the Predicate may contain missing values, causing the cell values
imprecise. We thus adopt the concept of lower and upper approximations to obtain an approximate range for each cell values and in
accordance compute the strength of the corresponding rule.
For simplicity, let X a ; X b ; X c , and X d denote the sets of cases satisfying the corresponding cell conditions in the contingency table.
Clearly, for complete data we have a = jX a j, b = jX b j, c = jX c j, and
d = jX d j. But for incomplete data we need to compute the lower
and upper approximations for X a ; X b ; X c , and X d . Let P denote the
set of attributes for the approximation computation. Each cell
value can be denoted by a range, i.e.,

 c : ½c; c; d : ½d; d

; b : ½b; b;
a : ½a; a

ð3Þ

Accordingly, we have

a ¼ jPK X a j; b ¼ jPK X b j; c ¼ jPK X c j; d ¼ jPK X d j
 ¼ jPK X j; c ¼ jPK X c j; d
 ¼ jPK X j
 ¼ jPK X a j; b
a
b

ð4Þ

d

Then the strength (range value) of the rule can be computed by
performing a simple range calculation according to the formula of
PRR and ROR. The resulting formulas are as follows:


ðc þ dÞ
a
aðc þ dÞ
6 PRR 6
;

cða þ bÞ
 þ bÞ
cða


d
a
ad
6 ROR 6

cb
c  b

ð5Þ

We consider two different options for defining the set P: global
covering and local covering. The global covering specifies all attributes in the data to P, i.e., P ¼ A. The local covering instead only
considers the set of attributes forming the rule of concern (and
so the contingency table). For convenience, we denote this attribute set as B, for B # A.
Since there are two different interpretations of missing values,
i.e., lost or don’t care, and three different versions of approximations, i.e., singleton, subset, and concept approximations, in total,
we obtain twelve different ways for computing the cell values
defined in (3) and (4), as shown in Fig. 1. Fig. 1 also depicts
the research framework adopted in this study, inspecting the

239

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246
Table 5
An incompletely data table with lost missing values.

Fig. 1. The research framework for incomplete ADR signal detection.

feasibility for applying rough set theory to the ADR signals detection from an incomplete SRS dataset containing missing values.
We assume that the template of the rule to be discovered is given,
either by the user or generated by a pre-procedure of candidate
rule generation. In the remainder of this section, we will examine
the feasibility of the twelve ways (versions) for computing the cell
values.
3.3. Feasibility analysis
We analyze the feasibility of the twelve different methods by
examining whether each one of them can yield reasonable approximations for data with missing values. To facilitate the discussion,
we first introduce the concept of satisfiable approximation and
indistinguishable approximation.
Consider a rule of the form defined in (2) and the corresponding
contingency table. Let C be the attribute set for defining the extra
conditions, i.e., Predc, for forming the contingency table. For example, if Predc = {Sex = ‘‘female”, Age = ‘‘>18”}, then C = {Sex, Age}.
Definition 6. Let y be any case in U. We say y satisfies the Predc
condition if for each attribute t in C, aðy; tÞ ¼ aðPredc; tÞ or
aðy; tÞ ¼ ? or aðy; tÞ ¼ , where a(Predc, tÞ denotes the condition
value of attribute t in Predc.
Definition 7. An approximation of the contingency set X (X can be
X a ; X b ; X c , or X d ) defined on an attribute set P is a C-satisfiable
approximation if all members in either the lower approximation
PX or upper approximation PX satisfy the Predc condition specified
by C.
Example 3. Consider the data with lost missing values in Table 3.
We would like to compute the strength of the following rule:

Gender ¼ g1; Drug ¼ d2 ! PT ¼ s1
The corresponding contingency sets are X a = {4}, X b ¼ £, X c = {3, 7,
8}, and X d ¼ £, and C = {Gender}. Now assume the subset approximation with similarity characteristic set and global covering is
applied. Then, we obtain the following characteristic sets of all cases
in Table 5.

ISR

Age

Gender

Drug

PT

1
2
3
4
5
6
7
8

?
a2
a1
a1
?
?
?
a1

?
?
g1
g1
?
g2
g1
g1

d1
d2, d3
d1
d2, d3
d2, d3
d1
d1
d3

s1
s1,
s1
s1,
s1,
s1
s1
s1,

s2
s2
s2

s2

Note that case 6 in the upper approximation of X c contradicts condition Gender = g1. Therefore, the subset approximation with similarity characteristic set and global covering is not C-satisfiable.
Definition 8. An approximation of the contingency set X (X can be
X a ; X b ; X c , or X d ) defined on an attribute set P is indistinguishable if
the lower approximation of the contingency set X is always equal
to the corresponding upper approximation, i.e., PK X ¼ PK X.
Example 4. Consider Table 5 and the rule in Example 3 again.
Assume that the concept approximation with similarity characteristic set and global covering is applied. Below are the lower and
upper approximations of X a ; X b ; X c , and X d .

PKc X a ¼ f4g;
PKc X a

¼ f4g;

PKc X b ¼ £;
PKc X b

¼ £;

PKc X c ¼ f3; 7; 8g;

PKc X d ¼ £

¼ f3; 7; 8g;

PKc X d ¼ £

PKc X c

Since the lower and upper approximations are the same, this
approximation is indistinguishable.
In what follows we present the important properties required
to determine the feasibility of the twelve measurements. All
detailed proofs are presented in Appendix to keep the content
more concise and readable.
Lemma 1. The subset approximation defined by tolerance characteristic set K T for contingency sets X a ; X b ; X c , and X d , is not C-satisfiable
with respect to P, for P  B.
Lemma 2. The subset approximation defined by similarity characteristic set K S for contingency sets X a ; X b ; X c , and X d , is not C-satisfiable
with respect to P, for P  B.
Lemma 3. The concept approximation defined by similarity characteristic set K S is indistinguishable for contingency sets X a ; X b ; X c , and
X d , with respect to P, for P  B, i.e., PKc S X ¼ P Kc S X, for X being
X a ; X b ; X c , or X d .
Lemma 4. The concept approximation defined by tolerance characteristic set K T is not indistinguishable for contingency sets X a ; X b ; X c ,
and X d , with respect to P, for P  B, i.e., PKc T X – PKc T X, for X being
X a ; X b ; X c , or X d .
Finally, we show that the singleton approximation defined
either by similarity or tolerance characteristic set is C-satisfiable
and not indistinguishable.

K S ðP; 1Þ ¼ f1; 3; 6; 7g K S ðP; 5Þ ¼ f2; 4; 5g
K S ðP; 2Þ ¼ f2g

K S ðP; 6Þ ¼ f6g

K S ðP; 3Þ ¼ f3g

K S ðP; 7Þ ¼ f3; 7g

K S ðP; 4Þ ¼ f4g

K S ðP; 8Þ ¼ f8g

Lemma 5. The singleton approximation defined by similarity characteristic set K S for contingency sets X a ; X b ; X c , and X d , is C-satisfiable
with respect to P, for P  B.

Below are the lower and upper approximations of X a ; X b ; X c , and X d .

PKs X a
PKs X a

¼ f4g;
¼ f4g;

PKs X b
PKs X b

¼ £;
¼ £;

PKs X c
PKs X c

¼ f3; 7; 8g;

PKs X d

¼ f1; 3; 6; 7; 8g;

¼£

PKs X d ¼ £

Lemma 6. The singleton approximation defined by tolerance characteristic set K T is not indistinguishable for contingency sets X a ; X b ; X c ,
and X d , with respect to P, for P  B, i.e., PKg T X – PKg T X, for X being
X a ; X b ; X c , or X d .

240

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246

Table 6
Summarization of the feasible and infeasible approximation methods.
Lost

Singleton
Subset
Concept

Table 7
The resulting CS_list, corresponding to tolerance characteristic set, in terms of
attribute set {Height, Gender} for the example in Table 3.

Don’t care

Global
p

Local
p

x

x

Global
p

Local
p

p

p

p

: feasible approximation.
: infeasible approximation, due to unsatisfiable property.
x: infeasible approximation, due to indistinguishable property.

In summary, the twelve approximation methods can be divided
into two categories, the feasible methods and the infeasible methods, as shown in Table 6. For convenience, we denote the six feasible methods in terms of characteristic sets (similarity or tolerance),
attribute covering (global or local), and approximation definition
(singleton, subset, or concept) as follows:

Value Pair

ID list

165, Male
165, Female
165, ⁄
170, Male
170, Female
170, ⁄
⁄, Male
⁄, Female
⁄, ⁄

5
2,
2,
1,
3
1,
1,
2,
1,

4
4
3, 5
3,
3,
3,
2,

5
5
4
3, 4, 5

Theorem
7. Accuracy(M1) P Accuracy(M2) P Accuracy(M5) P
Accuracy(M3) P Accuracy(M4) = Accuracy(M6).

3.5. The detection method
Method 1 M(s, g, g): Similarity set, global covering, singleton
approximation.
Method 2 M(s, l, g): Similarity set, local covering, singleton
approximation.
Method 3 M(t, g, g): Tolerance set, global covering, singleton
approximation.
Method 4 M(t, l, g): Tolerance set, local covering, singleton
approximation.
Method 5 M(t, g, c): Tolerance set, global covering, concept
approximation.
Method 6 M(t, l, c): Tolerance set, local covering, concept
approximation.
3.4. Comparative analysis
We further conducted a comparative analysis of the derived six
rough-set-based measurements in terms of the accuracy derived
from (1). To this purpose, we first define the Accuracy ðÞ of a rough
set based measuring method as the ratio of lower and upper signal
values. That is,

PRRl aðc þ dÞcða þ bÞ
¼
 cða
 ;
PRRu a
ðc þ dÞ
 þ bÞ

RORl a  d  c  b
¼
  c  b

RORu a
d

ð6Þ

We showed that there exists a proper order of the six rough-setbased methods in terms of the measurement accuracy, summarized in Theorem 7, where M1–M6 refer to the six methods. Details
of the proof are described in Appendix.

Given a SRS dataset with missing values, we assume that the
rule representing the ADR signal to be discovered is provided by
the user. Our algorithm, as shown in Fig. 2, computes the strength
of the rule according to the following parameters, attribute covering (global or local), characteristic set (tolerance or similarity),
approximation (singleton, subset, or concept), and the signal measure (PRR or ROR).
The most expensive step of our algorithm is Step 1. Computing
the characteristic set of a given case requires pairwise case comparison throughout the whole SRS table. For a SRS table consisting
of n cases, this procedure consumes Oðn2 Þ case comparisons, and so
we developed a more efficient method. The basic idea is as follows.
We introduced a structure called CS_list (Characteristic Set list)
to store the case_IDs that belong to the same characteristic set, i.e.,
indistinguishable in terms of the attributes of concern. For example, consider Table 3. The resulting CS_list, corresponding to tolerance characteristic set, in terms of attribute set {Height, Gender} is
depicted in Table 7, where column Value Pair denotes the possible
combinations in terms of {Height, Gender} and ID List the set of
cases belong to the characteristic set of this value pair. Once the
CS_list has been pre-computed, the characteristic set of a given case
can be generated in a minute. As such, we performed a preprocessing to generate six different CS_lists corresponding to the six
rough-set-based measurements. Note this process is performed
only once and can be computed offline. With the CS_list available,
we can achieve a near on-line signal measuring for each rule of
interest, as will be demonstrated in the experiments.

Input:
STab: the SRS data table;
RTemp: the rule template;
ACtype: the type of attribute coverings;
CStype: the type of characteristic sets;
APtype: the type of approximations;
MStype: the type of measures.
Output: The rule and the strength.
Steps:
1. Compute the characteristic sets of all records in STab according to ACtype and CStype;
2. Generate the four contingency sets, Xa, Xb, Xc, and Xd, according to the rule template RTemp;
3. Generate the lower and upper approximations of Xa, Xb, Xc, and Xd, according to the selected approximation
APtype;
4. Compute the rule strength using the approximate contingency a*, b*, c*, and d*, according to the measure MStype;
5. Return the rule with the computed strength;
Fig. 2. Algorithmic framework of the proposed ADR detection method.

241

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246
Table 8
Selected drugs marketed in US and associated ADRs.
Rule no.

Drug name

Adverse reaction

Group (age or gender)

Marked year

Withdrawn or warning year

ADRs of withdrawn drugs
R1-1
AVANDIA
R1-2
R1-3
R2
TYSABRI
R3
ZELNORM

Myocardial infarction
Death
Cerebrovascular accident
Progressive multifocal leukoencephalopathy
Cerebrovascular accident

18

1999

2010

18
Female

2004
2002

2005
2007

ADRs of non-withdrawn drugs
R4
WARFARIN
R5
REVATIO

Myocardial infarction
Death

60
18

1940
2008

2014
2014

Table 9
The accuracy of each rough set based method (For X a ).
Rule

R1-1
R1-2
R1-3
R2
R3
R4
R5
Average

Method
M1

M2

M3

M4

M5

M6

0.926
0.909
0.959
0.945
1.000
1.000
0.922
0.952

0.894
0.881
0.947
0.940
0.994
1.000
0.918
0.939

0.854
0.851
0.903
0.900
0.996
1.000
0.881
0.912

0.818
0.822
0.885
0.885
0.994
1.000
0.877
0.897

0.855
0.852
0.903
0.900
0.996
1.000
0.881
0.912

0.818
0.822
0.885
0.885
0.994
1.000
0.877
0.897

4. Experiments
We conducted a series of experiments to inspect the effectiveness of our methods. All of the available collections of the FAERS
dataset, from 2004Q1 to 2013Q3, were used. Each quarterly collection contains around 60,000 to 230,000 reports. All experiments
were performed on a PC with CPU i7-2600, 3 GB RAM, and
120 GB SSD.
We aim to compare the predicting capability of our rough-setbased methods with deletion method, the most common technique
for handling missing data, on timeline warning of serious ADR signals. Two variants of deletion method were considered: listwise
deletion and pairwise deletion. The listwise deletion method eliminates any records containing missing value in at least one attribute, while pairwise deletion withholds the records with missing
values not occurring on the attributes of concern.
Two groups of drugs were used in these experiments, including
three withdrawn drugs [5,9], AVANDIA, TYSABRI, and ZELNORM,
and two non-withdrawn drugs but labeled in the FDA warning list
(MedWatch) [15], WARFARIN and REVATIO. Other criteria for
choosing these drugs are: (1) There are enough cases associated
with these drugs reported in the FAERS dataset (yearly number
of reports > 3); (2) These drugs yield known ADRs associated with
specific populations. Table 8 lists detailed information of these
drugs and the associated ADRs. For convenience, each ADR is
denoted by a rule. The AGE attribute was discretized into three
levels, ‘‘<18”, ‘‘18–60”, and ‘‘>60”, in accordance with these rules.
All signals were measured by two commonly used criteria, PRR
and ROR, though we only show the results measured by PRR since
similar phenomena were observed for ROR. The threshold for an
ADR rule being significant followed the widely adopted setting,
PRR P 2 and a P 3 [6], where a denotes the number of reports satisfy the rule.
4.1. Accuracy comparison
We first compared the accuracy of the six rough-set-based
methods. For this purpose, we computed for each method the average accuracy of each rule’s strength over all quarters, and then

obtained the final average over all rules. Since the accuracies of
all contingency sets and rule signals exhibit similar phenomenon,
we only show the results for contingency set X a (see Table 9). Obviously, the results are consistent with the analysis presented in Section 3.4; Method 1 outperforms all the others, while Methods 4 and
6 exhibit the worst performance.
4.2. Prediction comparison
Since Method 1 exhibits the best accuracy, we then compared
Method 1 with listwise deletion and pairwise deletion. The results
are displayed in Fig. 3, where PRR_ld, PRR_pd, PRR_low, and
PRR_up denote the PRRs generated by listwise deletion, pairwise
deletion, lower and upper approximation by our method, respectively. Note rule R4 is omitted because all methods for this rule
failed to generate significant strength (with PRR P 2). The contingency a values are shown for convenience to inspect the condition
a P 3.
As the results demonstrate, most of the time our method exhibit
similar capability of timeline warning as that of deletion method,
both predicting ADR signals earlier than the time FDA issued warning or withdrawal announcement. However, in some cases our
method, by providing an approximate range of signal strength,
can predict the signal earlier than both the listwise and pairwise
deletions. For example, for R1-1 our method generates stable
strengths higher than threshold starting from 2007Q2 while the
listwise and pairwise methods do so from 2007Q4, and for R1-2
the result is 2008Q3 (our method) vs. 2008Q4 (listwise and pairwise deletions).
We also observe that listwise deletion and pairwise deletion
yields nearly the same signal strength over all cases, though pairwise sometimes generate higher strength of rule due to larger a
values it maintains, making pairwise a little better than listwise
in signal prediction. For example, see the results for rule R3 during
07Q3 to 10Q1, and 10Q4 to 12Q2 for R5. This enhancement on the
other hand would bias the signal of concern. For example, for rule
R2 we observe two extraordinary large values yielded by pairwise
deletion at 05Q2 and 07Q2, for which a report containing missing
value that is dismissed by listwise deletion and our method is
taken into account.
Another important phenomenon is solely using quarterly generated patterns for monitoring ADR signals is not reliable. For example, the noteworthy signal for R1-2 generated by our method
during 08Q3 to 10Q3 is faded out and appear again during 12Q4
to 13Q1. This is mainly contributed by the well-known underreporting problem [19], causing large variances among the number
of cases reported over different quarters. For this reason, cumulative ADR measurements usually are adopted as auxiliaries.
Fig. 4 shows the cumulative counterpart of Fig. 3. In general, the
results coincide with those exhibited in Fig. 3. The curves generated by the deletion method, either listwise or pairwise, are situated between those by our method, which also reinforces the
superiority of our method in earlier detection of high-profile

242

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246

(a) Rule R1-1

(b) Rule R1-2

(c) Rule R1-3

(d) Rule R2

(e) Rule R3

(f) Rule R5

Fig. 3. Comparison of our method and traditional method on quarterly generated signal strengths.

signals. A noteworthy observation occurs to Fig. 4(b), where both
deletion methods fail to identify Rule 1–2 as significant, while
our method exhibits the potential for this ADR signal.
4.3. Performance comparison
Finally, we compared the execution times of our method with
listwise and pairwise deletions. Two different implementations of

our method were considered, including the naïve approach and
CS_list pre-computed approach. Since the results are similar for
all ADR rules measured by the six methods, we only show the
results of running rule R1-1 with method M1 over 2004Q2 and
2012Q1, where 2004Q2 represents the smallest dataset containing
around 60,000 records, while 2012Q1 is the largest dataset containing around 230,000 records. The preprocessing times for generating CS_list from 2004Q2 and 2012Q1 requires two and eight

243

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246

(a) Rule R1-1

(b) Rule R1-2

(c) Rule R1-3

(d) Rule R2

(e) Rule R3

(f) Rule R5

Fig. 4. Comparison of our method and traditional method on cumulative quarterly signal strengths.

minutes, respectively. From the results shown in Table 10, our
CS_list version, even including the CS_list generation time, significantly outperforms naïve implementation, achieving 150x
speedup. Both implementations of our method are relatively
expensive compared with listwise and pairwise deletions.
However, the computation overhead caused by using our method,

Table 10
Execution time compariosn for rule R1-1 with M1.
Dataset

2004Q2
2012Q1

Listwise (s)

0.4
1.7

Pairwise (s)

0.5
1.8

RS method
Naïve

CS_list (s)

40 min
20 h

19
104

244

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246

especially the CS_list version, shall be acceptable compared with
quarterly duration for data collection and signal reporting.
5. Conclusions
Although it is well known that the SRS dataset contains lots of
missing data, most of published research work on this topic
adopted listwise deletion to eliminate data with missing values.
No work has noticed the possibility and examined the effect of
including the missing data in the process of ADR detection. In this
paper, we have inspected the feasibility of applying rough set theory to the ADR detection problem. Specifically, we have proposed
twelve different rough-set-based measuring methods and showed
that, in terms of two novel concepts, satisfiable and indistinguishable properties, only six of them are feasible for the purpose. We
also have conducted a comparative analysis of these six methods
in terms of measurement accuracy, showing Method 1 the most
effective.
We have compared our method with traditional frequentist
methods with listwise deletion or pairwise deletion in timeline
warning of noteworthy ADR signals. Experimental results show
that most of the time our method exhibits similar capability of
timeline warning as that of traditional method but in some cases
it can yield noteworthy measures earlier. From the preliminary
results, we conclude that rough-set-based ADR signal measuring
method that takes missing data into account is feasible and may
be regarded as an auxiliary for the traditional measuring method.
In the future, we will conduct more comprehensive experiments on other drugs and improve the efficiency of our algorithm.
Besides, our method only applicable to ADR rules with extra condition, that is, there is at least one incomplete attribute other than
Drug and PT involved in the rule condition. We will also devise
other rough-set-based approaches to eliminate this limitation.
Another restriction of our rough-set-based approach goes into
continuous attributes. The rough set theory is based on the concept
of indiscernibility relation, from which lower and upper approximations are derived. Although theoretically this relation applies
both for attributes with discrete and continuous domains, in practice it is only valuable for discrete attributes, because in a decision
table all objects may have been discernible with respect to continuous attributes. This is why discretization is needed for continuous
attributes before employs rough set theory. Since the characteristic
relation for dealing with missing values is derived from the indiscernibility relation, discretization for continuous attributes is also
necessary. It will be a challenging issue for how to deal with continuous attributes without discretization.
Conflict of interest
None declared.
Acknowledgment
This work was supported by the National Science Council of Taiwan under Grant No. NSC101-2221-E-390-027.
Appendix A
In this appendix, we present the detailed proof of all theorems.
First, we prove Lemmas 1 to 6.
Lemma 1. The subset approximation defined by tolerance characteristic set K T for contingency sets X a ; X b ; X c , and X d , is not C-satisfiable
with respect to P, for P  B.

Proof. We only consider the case of X a and P = B. It is easy to apply
similar strategies to prove other cases. To prove P Ks T X a is not Csatisfiable, we will show that indeed, the upper approximation
PKs T X a is not C-satisfiable. h
Lemma 2. The subset approximation defined by similarity characteristic set K S for contingency sets X a ; X b ; X c , and X d , is not C-satisfiable
with respect to P, for P  B.
Proof. The proof is similar to that in Lemma 1. h
Lemma 3. The concept approximation defined by similarity characteristic set K S is indistinguishable for contingency sets X a ; X b ; X c , and
X d , with respect to P, for P  B, i.e., PKc S X ¼ P Kc S X, for X being
X a ; X b ; X c , or X d .
Proof. Again, we only consider the case of X a and P = B. Recall the
following definitions for PKc S X a and PKc S X a .

PKc S X a ¼ [fK S ðP; xÞjx 2 X a ; K S ðP; xÞ # X a g
PKc S X a ¼ [fK S ðP; xÞjx 2 X a ; K S ðP; xÞ \ X a – £g
According to the definition of K S ðP; xÞ, if a case y 2 K S ðP; xÞ, then

aðx; tÞ ¼ aðy; tÞ for any attribute t 2 P and aðx; tÞ – ?. Since x 2 X a , it

follows that all attribute values of x in B are not lost, i.e., for all
t 2 B, aðx; tÞ – ?, and so are y. This means if y 2 K S ðP; xÞ then
y 2 X a as well. In other words, K S ðP; xÞ # X a and we have

PKc S X a ¼ PKc S X a ¼ X a ;
which proves the lemma. h
It is interesting to note that in the proof of Lemma 3, if the concept approximation is defined by the tolerance characteristic set,
then a member y 2 K T ðP; xÞ may not belong to X a . This is because
y may contain some don’t care attributes in B, which hinders it
from a member of X a . This leads to the proof of Lemma 4.
Lemma 4. The singleton approximation defined by similarity characteristic set K S for contingency sets X a ; X b ; X c , and X d , is C-satisfiable
with respect to P, for P  B.

Proof. Once again, we only consider the case of X a and P = B. The
other cases can be proved by similar strategies. According to the
definitions, we have

PKg S X a ¼ fx 2 UjK S ðP; xÞ # X a g
PKg S X a ¼ fx 2 UjK S ðP; xÞ \ X a – £g
Assume that P Kg S X a is not C-satisfiable, which implies there
exists at least one case x 2 PKg S X a and aðx; tÞ – ? such that
aðx; tÞ – aðPredc; tÞ for some attribute t 2 C. According to the definition of K S ðP; xÞ, every member y in K S ðP; xÞ should have the same
value on attribute t and so aðy; tÞ – aðPredc; tÞ, which contradicts
the fact that y 2 X a . Similarly, if P Kg S X a is not C-satisfiable, we will
conclude K S ðP; xÞ \ X a ¼ £, also a contradiction. h
Lemma 5. The singleton approximation defined by tolerance characteristic set K T is not indistinguishable for contingency sets X a ; X b ; X c ,
and X d , with respect to P, for P  B, i.e., PKg T X – PKg T X, for X being
X a ; X b ; X c , or X d .

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246

Proof. Recall the definition of K T ðP; xÞ. A case y in K T ðP; xÞ may
have a null value on some attribute t; t 2 B, while aðx; tÞ – .
Clearly, x does not belong to PKg S X a because y is not in X a , which
invalidates condition K T ðP; xÞ # X a . However, this does not hinder
x from being a member of P Kg S X a . The lemma follows. h
The next part of this appendix details the proof of Theorem 7. To
this purpose, we first show the subsumptive properties of the two
types of characteristic sets. Let A and B denote the set of attributes
defined in Section 3.2, B # A, and K denote the similarity ðK S Þ or tolerance characteristic set ðK T Þ.

245

(b) Now, consider x 2 BKg T X. According to definition, we know
K T ðB; xÞ \ X – £. To show that x 2 BKc T X we have to show
that there exists a case y; x 2 K T ðB; yÞ, such that y 2 X and
K T ðB; yÞ \ X – £. Let y 2 K T ðB; xÞ \ X. It is easy to show
x 2 K T ðB; yÞ. That is, y is just the case we need. Hence,
x 2 BKc T X. On the other hand, let x 2 BKc T X. Then, there must
exist some y 2 X and K T ðB; yÞ \ X – £, such that
x 2 K T ðB; yÞ. It is easy to show y 2 K T ðB; xÞ. Since y 2 X, we
obtain K T ðB; xÞ \ X – £, leading to x 2 BKc T X. This proves
BKg T X ¼ BKc T X. h

Lemma A-1. KðA; xÞ # KðB; xÞ.
Corollary A-5. Accuracy(M4) = Accuracy(M6).
Proof. Consider any case y 2 KðA; xÞ. Clearly y 2 KðB; xÞ as well
according to the definition of characteristic set. On the other hand,
consider y 2 KðB; xÞ. If aðy; tÞ – aðx; tÞ and aðx; tÞ – ? or ⁄ for some
attribute t 2 A  B, then y R KðA; xÞ. The lemma follows. h
Let X be X a ; X b ; X c , or X c . We further analyze the subsumptive
relations between different types of rough-set-based approximations. For simplicity, we only show the relations facilitating comparative analysis of our proposed six measurements.
Lemma A-2.
(a) AKg X  BKg X.

Lemma A-6.
(a) AKg T X # AKc T X.
(b) AKg T X ¼ AKc T X.
Proof. The proof is similar to that for Lemmas A-4. The only difference is that if x 2 AKc T X, then x may not be in AKg T X. This is because
the fact that x 2 X does not guarantee K T ðA; xÞ # X even we know
x 2 K T ðA; yÞ, for y 2 X and K T ðA; yÞ # X. h
Corollary A-7. Accuracy(M3) 6 Accuracy(M5).

(b) AKg X # BKg X.
Lemma A-8.
Proof. Consider x 2 AKg X. According to the definition, we have
KðA; xÞ # X. Since KðA; xÞ # KðB; xÞ; KðB; xÞ # X may not be held,
which implies x may not be in BKg X. On the other hand, consider
x 2 BKg X. By definition and KðA; xÞ # KðB; xÞ, we have KðA; xÞ # X,
leading to x 2 AKg X. Thus, AKg X  BKg X. By similar approach, we can
show AKg X # BKg X. h
Then, according to Lemmas A-2, it is easy to obtain the following result.
Corollary A-3. Accuracy(M1) P Accuracy(M2), Accuracy(M3) P
Accuracy(M4).
Next, we compare method M3 with M5, and M4 with M6.

(a) BKg S X  AKc T X.
(b) BKg S X ¼ AKc T X.
Proof.
(a) Consider x 2 BKg S X. By definition, we know K S ðB; xÞ # X and so
x 2 X. To show that x 2 AKc T X, we have to show that there
exists a case y; x 2 K T ðA; yÞ, such that y 2 X and K T ðA; yÞ # X.
First, suppose ydoes exist, i.e., x 2 K T ðA; yÞ, which implies
that 8t 2 B, aðx; tÞ ¼ aðy; tÞ –  or aðy; tÞ ¼ . In the latter
case, clearly y R X, while the first case does not guarantee
K T ðA; yÞ # X; for example, consider a case w 2 K T ðA; yÞ with
aðw; tÞ ¼  for some t 2 B. Therefore, we conclude that x
may not belong to AKc T X. On the other hand, suppose

Lemma A-4.
(a) BKg T X ¼ BKc T X.
(b) BKg T X ¼ BKc T X.

Proof.
(a) Consider any case x 2 BKg T X. According to the definition, we
have K T ðB; xÞ # X and so x 2 X. To show x 2 BKc T X, we have
to show that there exist some y; x 2 K T ðB; yÞ such that y 2 X
and K T ðB; yÞ # X. This is trivial since x itself satisfies the condition. Hence, x 2 BKc T X. Next, we consider any case x 2 BKc T X.
According to definition, x must belong to some characteristic
set, say K T ðB; yÞ, for y 2 X and K T ðB; yÞ # X. Clearly x 2 X.
Then
for
all
t 2 B,
aðx; tÞ ¼ aðy; tÞ, leading to
K T ðB; xÞ ¼ K T ðB; yÞ # X. That it, x 2 BKg T X, which completes
the proof for BKg T X ¼ BKc T X.

x 2 AKc T X, which implies 9y 2 X and K T ðA; yÞ # X, such that
x 2 K T ðA; yÞ. Clearly, x 2 X, implying aðx; tÞ – ? for all t 2 B,
and so 8w 2 K S ðB; xÞ, aðw; tÞ ¼ aðx; tÞ or all t 2 B. Thus,
K S ðB; xÞ # X, and so x 2 BKg S X. It follows that BKg S X  AKc T X.
(b) Consider x 2 BKg S X. By definition, we have K S ðB; xÞ \ X – £.
Let y 2 K S ðB; xÞ \ X. The fact that y 2 K S ðB; xÞ means 8t 2 B,
aðx; tÞ = aðy; tÞ = ? or aðx; tÞ = ?, and so we have x 2 K T ðB; yÞ
(Note that ‘?’ is interpreted as ‘⁄’ as we consider K T Þ. Since
y 2 K T ðB; yÞ; K T ðB; yÞ \ X – £. Hence, x 2 AKc T X. Next, consider
x 2 AKc T X. By definition, there must exist some y 2 X and
K T ðA; yÞ \ X – £, such that x 2 K T ðA; yÞ. Clearly, x 2 K T ðB; yÞ
by Lemmas A-1. By similar statement, we know y 2 K S ðB; xÞ
(In this case, ‘⁄’ is interpreted as ‘?’). Since y 2 X and
y 2 K S ðB; xÞ, i.e., K S ðB; xÞ \ X – £, we conclude x 2 BKg S X. It
follows that BKg S X ¼ AKc T X. h
Corollary A-9. Accuracy(M2) P Accuracy(M5).
Finally, combing the results in Corollaries A-3, A-5, A-7, and A-9
we obtain the result in Theorem 7.

246

W.-Y. Lin et al. / Journal of Biomedical Informatics 58 (2015) 235–246

References
[1] J.S. Almenoff, K.K. LaCroix, N.A. Yuen, D. Fram, W. DuMouchel, Comparative
performance of two quantitative safety signalling methods: implications for
use in a pharmacovigilance department, Drug Safety 29 (10) (2006) 875–887.
[2] A. Bate, Bayesian confidence propagation neural network, Drug Safety 30 (7)
(2007) 623–625.
[3] A. Bate, M. Lindquist, I.R. Edwards, S. Olsson, R. Orre, A. Lansner, R.M. De
Freitas, A Bayesian neural network method for adverse drug reaction signal
generation, Eur. J. Clin. Pharmacol. 54 (4) (1998) 315–321.
[4] B.K. Chen, Y.T. Yang, Post-marketing surveillance of prescription drug safety:
past, present, and future, J. Legal Med. 34 (2) (2013) 193–213.
[5] P.M. Coloma, G. Trifirò, V. Patadia, M. Sturkenboom, Postmarketing safety
surveillance: where does signal detection using electronic healthcare records
fit into the big picture?, Drug Safety 24 (6) (2013) 343–348
[6] G. Deshpande, V. Gogolak, S.W. Smith, Data mining in drug safety: review of
published threshold criteria for defining signals of disproportionate reporting,
Pharmac. Med. 24 (1) (2010) 37–43.
[7] A.C. Egberts, R.H. Meyboom, E.P. van Puijenbroek, Use of measures of
disproportionality in pharmacovigilance: three Dutch examples, Drug Safety
25 (6) (2002) 453–458.
[8] S.J. Evans, P.C. Waller, S. Davis, Use of proportional reporting ratios (PRRs) for
signal generation from spontaneous adverse drug reaction reports, Drug Safety
10 (6) (2001) 483–486.
[9] FDA Adverse Event Reporting System, <http://www.fda.gov/Drugs/
GuidanceComplianceRegulatoryInformation/Surveillance/AdverseDrugEffects/
ucm083765.htm>.

[10] J.W. Grzymala-Busse, Rough set strategies to data with missing attribute
values, in: Proc. Workshop on Foundations and Novel Approaches in Data
Mining, IEEE ICDM2003, vol. 9, 2006, pp. 197–212.
[11] A.E. Hassanien, A. Abraham, J.F. Peters, G. Schaefer, Rough sets in medical
informatics applications, in: J. Mehnen, M. Koeppen, A. Saad, A. Tiwari (Eds.),
Applications of Soft Computing, vol. 58, Springer-Verlag, Heidelberg, 2009, pp.
23–30.
[12] R. Harpaz, W. DuMouchel, N.H. Shah, D. Madigan, P. Ryan, C. Friedman, Novel
data mining methodologies for adverse drug event discovery and analysis,
Clin. Pharmacol. Therapeut. 91 (6) (2012) 1010–1021.
[13] J. Hopstadius, G.N. Norén, A. Bate, I.R. Edwards, Impact of stratification on
adverse drug reaction surveillance, Drug Safety 31 (11) (2008) 1035–1048.
[14] M. Kryszkiewicz, Rough set approach to incomplete information systems, in:
Proc. 2nd Annual Joint Conf. on Information Sciences, 1995, pp. 194–197.
[15] MedWatch: The FDA Safety Information and Adverse Event Reporting
Program, <http://www.fda.gov/Safety/MedWatch/>.
[16] Z. Pawlak, Rough sets, Int. J. Comput. Inform. Sci. 11 (5) (1982) 341–356.
[17] S. Rissino, G.L. Torres, Rough set theory — fundamental concepts, principals,
data extraction, and applications, in: J. Ponce, A. Karahoca (Eds.), Data Mining
and Knowledge Discovery in Real Life Applications, I-Tech Education and
Publishing, Vienna, 2009, pp. 36–58.
[18] J. Stefanowski, A. Tsoukias, On the extension of rough sets under incomplete
information, in: Proc. 7th Int. Workshop on New Directions in Rough Sets, Data
Mining, and Granular-Soft Computing, 1999, pp. 73–81.
[19] P.G.M. van der Heijden, E.P. van Puijenbroek, S. van Buuren, J.W. van der
Hofstede, On the assessment of adverse drug reactions from spontaneous
reporting systems: the influence of under-reporting on odds ratios, Stat. Med.
21 (14) (2002) 2027–2044.

