Received May 31, 2021, accepted June 16, 2021, date of publication June 21, 2021, date of current version July 1, 2021.
Digital Object Identifier 10.1109/ACCESS.2021.3091394

Sentence-Level Aspect-Based Sentiment Analysis
for Classifying Adverse Drug Reactions (ADRs)
Using Hybrid Ontology-XLNet Transfer Learning
ASMAA HASHEM SWEIDAN
AND HAYTHAM AL-FEEL3

1,

NASHWA EL-BENDARY

2,

(Senior Member, IEEE),

1 Faculty

of Computers and Information, Fayoum University, Faiyum 63514, Egypt
of Computing and Information Technology, Arab Academy for Science, Technology and Maritime Transport (AASTMT), Aswan 81531, Egypt
3 Department of Computer Science, Community College, Imam Abdulrahman Bin Faisal University, Dammam 34212, Saudi Arabia
2 College

Corresponding author: Asmaa Hashem Sweidan (aha07@fayoum.edu.eg)

ABSTRACT This paper presents a hybrid ontology-XLNet sentiment analysis classification approach for
sentence-level aspects. The main objective of the proposed approach allows discovering user social data
considering the extracted in-depth inference about sentiment depending on the context. Thus, in this paper,
we investigate the contribution of utilizing the lexicalized ontology to improve the aspect-based sentiment
analysis performance through extracting the indirect relationships in user social data. The XLNet model
is utilized for extracting the neighboring contextual meaning and concatenating it with each embeddings
word to produce a more comprehensive context and enhance feature extraction. In the proposed approach,
Bidirectional Long Short Term Memory (Bi-LSTM) networks are used for classifying the aspects in online
user reviews. Various experiments considering Adverse Drug Reactions (ADRs) discovery are conducted on
six drug-related social data real-world datasets to evaluate the performance of the proposed approach using
several measures. Obtained experimental results show that the proposed approach outperformed other tested
state-of-the-art related approaches through improving feature extraction of unstructured social media text
and accordingly improving the overall accuracy of sentiment classification. A significant accuracy of 98%
and F-measure of 96.4% are achieved by the proposed ADRs aspect-based sentiment analysis approach.
INDEX TERMS Aspect, sentiment analysis, adverse drug reactions (ADRs), XLNet, ontology, transfer
learning.

I. INTRODUCTION

One of the leading causes of morbidity and mortality is
Adverse Drug Reactions (ADRs), which is a major public
health concern [1]. ADRs or adverse drug effects (ADEs)
refer to unfavorable idiosyncratic effects caused during
the therapeutic use of drugs for certain disease treatment.
Although clinical trials are used to test the efficacy and safety
of drugs, ADRs are still undiscovered and can be detected
only after long-term use, when used with other medications,
or when used by patients who were excluded from the experiments. Also, it is estimated that more than 90% of adverse
reactions are still not reported. According to this issue, ADRs
research has become common to extract and assess social
media posts as a persistent source for gathering the unknown
The associate editor coordinating the review of this manuscript and
approving it for publication was Zhan Bu
90828

.

or unreported negative effects of drugs. Consequently, due to
the growing interest of users in identifying information about
the characteristics of various products, sentiment analysis has
emerged as an active area of critical research [2].
Aspect-based sentiment analysis aims to allow the extraction of fine-grained aspects (topics) together with the
sentiment, which is expressed on those topics [3]. The
major aim of aspect-based sentiment analysis is to detect
aspects and identify the sentiments related to each aspect
expressed by users in social data [4]. The fundamental tasks
of aspect-based sentiment analysis include extracting the
main terms, identifying the sentiments expressed towards
the extracted aspects, and visualizing the extracted main
feature-based opinion related information [5]–[7].
Feature extraction from unstructured textual data in Natural Language Processing (NLP) developed many approaches
for text mining; such as, the probabilistic approach of

This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/

VOLUME 9, 2021

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

Bag-Of-Words (BOW) with Machine Learning (ML), the
distributed representation of words approach (word embeddings), like Word2vec algorithm applied with Deep Learning (DL) [8], [9], and transfer learning, like Bidirectional
Encoder Representations from Transformers (BERT) [10]
and XLNet [11] techniques. The BERT model is designed
to pre-train deep bidirectional representations of unlabeled
text by co-conditioning both left and right context in all
layers. A different contextual embeddings is produced by
BERT according to the input sentence [12]. Nevertheless,
BERT corrupts the input with masks, suffers a discrepancy
between pre-training and fine-tuning, and ignores the interdependency between masked positions, thus leading to the
loss of important information [13]–[15]. On the other hand,
the XLNet model is a generalized auto-regressive model,
where all previous tokens depend on the next token. XLNet
is generalized because of utilizing a mechanism called permutation language modeling that captures the bidirectional
context and integrates the idea of auto-regressive models with
bidirectional context modeling. Thus, this paper utilizes the
XLNet technique because it overcomes BERT’s drawbacks
and it also achieves better performance in many NLP tasks
than most of other pre-training approaches [16], [17].
In this paper, the user opinion about drugs is used to
detect and extract unreported drug reactions and classify it
according to users social data (reviews, posts). The proposed
approach uses lexicalized ontology and XLNet techniques
for feature extraction of word and sentence-level embeddings
vectors. The proposed approach also utilizes a lexicalized
domain ontology to extract indirect relationships between
entities and their properties [18], and to accordingly determine the polarity of drug features of an aspect in conjunction
with direct relationships in users social data.
Subsequently, XLNet (bidirectional context) word embeddings is used in the proposed approach to determine the relationships between aspects and their word context, which is
concatenated with each embeddings word to produce a more
comprehensive context and enhance the quality of feature
extraction.
The main objective of this paper is to develop a hybrid
ontology-XLNet transfer learning model for sentence-level
aspect-based sentiment analysis. Also, the proposed approach
allows the discovery of using social data considering the
extracted in-depth inference about sentiment depending on
the context through utilizing lexicalized ontology as a domain
knowledge-driven solution to improve the performance of
aspect-based sentiment analysis with extracting the indirect
relationships in user social data. Moreover, the proposed
approach extracts medical attributes and their relationships
with drugs to assess ADRs. Then, drug effects are classified
from social media by merging semantic via its ontology
language and context sentiment via XLNet and utilize them
to extract features with Bi-LSTM to recognize long-distance
dependencies and classify drug reviews.
Accordingly, the main contributions of this paper are summarized in the following points:
VOLUME 9, 2021

•

•

•

•

•

Presenting a novel method for analyzing text sentiment
through categorizing text content into predefined sentiment categories at a comprehensive linguistic level
taking into account the aspects of each entity.
Extracting local features and global features to improve
feature extraction and enhancement of the relationship
between knowledge.
Expanding the recently released XLNet transfer learning model with the lexicalized ontology layer for feature extraction and utilizing Bidirectional Long Short
Term Memory (Bi-LSTM) networks for classifying the
aspects in online user reviews.
Developing a hybrid ontology-XLNet transfer learning
approach for Adverse Drug Reactions (ADRs) identification from social data based on sentence-level aspect
sentiment analysis.
Studying the generalizability and the effectiveness of
the proposed approach on six drug-related social data
real-world benchmark datasets.

The remaining of this paper is organized as follows. Section II reviews several related state-of-the-art
literature and identifies the main challenges of current
research. Section III presents the phases of the proposed
approach. Section IV explains the tested datasets and
describes the experimental results obtained as well as presenting findings and limitations. Section V presents conclusions
and discusses future work.
II. RELATED WORK

This section starts with introducing an exhaustive survey of
recent studies with proposed approaches based on ontology
and Deep Learning (DL) techniques for addressing the sentiment analysis problems. Subsequently, some state-of-the-art
literature that primarily focus on drug effects extraction and
detection based on aspect-based sentiment analysis are discussed.
In [19], the authors proposed a monitoring system to assist
travel based on DL and ontology. The proposed system
utilized fuzzy ontology and the Word2vec embeddings to
establish the feature extraction module and classified the text
data using the Bi-LSTM model. The proposed system was
experimented based on a data collection of news articles from
the online transportation reports, TripAdvisor data, Facebook
data, and Twitter data, and achieved an accuracy of 84%.
Along the same line, in [20], the authors of [19] in collaboration with other researchers proposed a transportation
sentiment analysis system based on word embeddings and
ontology with Latent Dirichlet Allocation (LDA) topic modeling. The proposed system utilized fuzzy ontology with LDA
and the Word2vec model to establish the feature extraction
module and classified the data using ML algorithms. The
proposed system was experimented based on the same data
collection of online transportation posts of [19] and outperformed the system proposed in [19] by achieving an enhance
accuracy of 93%.
90829

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

Also, in [21], the authors proposed a system using social
network data for traffic accident detection and condition
analysis based on applying ontology with LDA (OLDA) and
Bi-LSTM network. The proposed system utilized OLDA to
extract information and label sentences. The sentiment analysis then uses user opinions to assess the polarity of traffic
incidents, which aids in determining accurate traffic conditions. Finally, the fastText and Bi-LSTM models are used
as classifiers. The proposed system achieved an accuracy
of 97%.
Moreover, in [22], the authors proposed a DL model
for sentiment analysis; namely, attention-based bidirectional
CNN-RNN deep model (ABCDM). The proposed model
used CNN and Bi-LSTM in order to derive both past and
future contexts by considering temporal information flow in
both directions using two separate Bi-LSTM networks with
Gated Recurrent Unit (GRU) layers. In addition, the attention function is used on the outputs of the ABCDM’s bidirectional layers to place more or less focus on various
terms. The proposed system employs convolution and pooling processes to minimize feature dimensionality and extract
position-invariant local features. The proposed system utilized a data collection from long reviews and short Twitter
posts datasets, and achieved an accuracy of 92%.
In the same vein, the authors in [23] used GloVe (Global
Vectors) and BERT embeddings modules and a multi-head
attention module was employed to captures the context and
aspect’s long-range semantic dependencies based on BiLSTM. Then, the location encoding module eliminates the
noise generated by various dependency parsing processes.
To improve capturing syntactic information, the proposed
module makes use of the syntactic dependency tree for effectively leveraging the edge information of the parsing tree,
then the final representation is obtained by the output module.
The proposed model examined the Twitter posts used in
several datasets from SemEval 2014 task, SemEval 2015 task,
and SemEval 2016 task, and achieved an average accuracy
of 81%.
On the other hand, for the literature considering
healthcare-related studies and approaches focusing on drug
effects extraction and detection using aspect-based sentiment
analysis, ontology, and DL techniques, the authors in [24]
proposed a big data approach based on ontology and DL
for intelligent healthcare monitoring. The proposed system
utilized ontology to extract semantic information for entities
and aspects and their relations in the areas of diabetes and
pulse/blood pressure. The proposed system used Bi-LSTM
as a classifier and was experimented on data collected
from wearable devices, medical records, social networking
platforms, and webpages for drug reviews. The proposed
approach achieved an accuracy of 90%.
The authors in [25], proposed a word embeddings-based
approach for producing a sentiment lexicon of medical fields.
The proposed approach used a sentiment lexicon based
on SentiWordNet (SWN), term-weighted feature representation based on position encoding, and Word2vec (skip-gram
90830

model) methods for features extraction and applied the
Naive Bayes, Support Vector Machine, and Random Forest ML algorithms for drug reviews classification. The proposed medical SWN lexicon approach achieved a precision
of 56.17% and an F-measure of 55.54% compared to the
original SWN lexicon model.
Also, in [26], the authors utilized an approach that applies
a weakly supervised mechanism (WSM), which merges
the power of Convolutional Neural Network (CNN) and
Bi-LSTM models. The WSM uses weakly labeled data for
pre-training model parameters and then uses classified data to
fine-tune the initial parameters of the network. The proposed
system was experimented on the AskaPatient dataset, and
achieved 86.72%, 86.81%, 87.92%, and 85.73% for accuracy,
F1 score, precision, and recall, respectively.
Moreover, in [27], the authors proposed a system that classifies medical relationships in clinical records based on CNN
Deep Learning. The proposed system used Word2vec word
embeddings and word position information, then fed them
into CNN network to generate local features. The proposed
system tested on clinical records, and achieved a precision
of 72.9%, a recall of 66.7%, and an F-measure of 69.6%.
Also, the authors in [28] proposed a document representation system based on Fuzzy Bag-of-Words model (FBOW).
The proposed system applied fuzzy mapping to replace the
original hard planning module with Word2vec technique and
enhance the FBoW model, which semantically compares
ambiguous terms and grants similar words with a basic term
using word cluster instead of an individual words. The authors
in this research used three measures to assess the word and
cluster similarity on seven real-world document datasets.
Additionally, in [29], the authors proposed a deep-learning
approach that labeled words with ADRs membership tags
in an input sequence. The input features word embeddings
vectors were generated by task-independent pre-training
or through ADRs tags detection training. The proposed
approach was experimented on the Twitter dataset, and
achieved an F-measure of 0.77.
In [30], the authors proposed a novel sentiment analysis
algorithm used with CNN to improve ADEs detection and
extraction in Twitter data. Furthermore, the proposed system uses sentiment analysis and investigated its impact on
the extraction of ADEs from user posts on Twitter (user
tweets). The proposed approach was experimented on a Twitter dataset from PSB 2016 Social Media Shared Task, and
achieved a precision of 70.21%, a recall of 59.64%, and an
F1 score 64.50%.
Also, the authors in [31] proposed a deep-learning model
for ADEs classification through using a semi-supervised
CNN model as a classifier. The proposed model was also
tested on the Twitter PSB 2016 Social Media Shared Task
for ADEs classification, and achieved a precision of 70.21%,
a recall of 59.64%, and an F-measure of 64.50%.
The authors in [32], proposed a deep-learning approach
for detecting ADRs in Electronic Health Records (EHRs).
The proposed approach used embeddings based on lemmas
VOLUME 9, 2021

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

and Joint AB-LSTM model for discovering ADRs. The proposed approach was tested on EHRs dataset, and achieved an
F-measure of 73.3%.
In addition, the authors in [33] proposed a model based on
DL and Bidirectional Encoder Representations from Transformers (BERT) models for ADEs extraction and detection
to identify drug side effects. The proposed model used sentence embeddings and BERT word embeddings for feature
extraction and DL LSTMs as a classifier. The proposed model
has been evaluated on WebMD and Drugs.com datasets, and
achieved 0.97, 0.974, and 0.966 for F-measure, precision,
and recall, respectively, using BERT word with sentence
embeddings.
Moreover, in [34], the authors proposed an approach that
used a pre-trained model and a fine-tuning methodology
without further time-consumption of manual labeling to
extract medical relations. The proposed approach utilized
the architecture of the BERT with a one-dimensional Convolutional Neural Networks (1D-CNN) for feature extraction. The proposed approach was experimented on three
datasets; namely, the BioCreative V chemical disease relation
corpus, traditional Chinese medicine literature corpus, and
i2b2 2012 temporal relation challenge corpus, and achieved
F1 score values of 0.7156, 0.8982, and 0.7085, respectively.
Furthermore, in [35], the authors proposed a new model for
sentence-level aspect-based sentiment classification; namely,
ALDONA hybrid model. The proposed model is created
using a lexicalized domain ontology and a neural attention
model to extract statistical relations and define the aspect
polarity. The proposed model used the CNN-boosted classification and the BERT large words embeddings for text
classification. The benchmark SemEval (Semantic Evaluation) dataset was used for evaluation, and the proposed model
achieved testing and training accuracy values of 87.1% and
93.1%, respectively.
Also, the authors in [36] developed a model to detect
ADEs based on knowledge using Unified Medical Language
System (UMLS) to extract relations and Bi-LSTM network
for classification. The proposed model was experimented on
n2c2 2018 dataset and achieved an F-measure of 0.9442.
In [37], the authors proposed an approach to detect ADRs
using BERT with Logistic regression ML algorithm as a classifier. The proposed system was experiment on two datasets;
namely, TAC 2017 and n2c2 2018, with achieved F-score
values of 93.65 and 85.59, respectively.
Several limitations in the surveyed state-of-the-art research
results are caused by using insufficient data representation
based on syntax and word frequencies rather than semantics.
These limitations, along with the weakness of the current
algorithms to understand and process data in their original representations, require novel methods to address various persistent pharmacovigilance (drug safety) problems.
Hence, the motivation behind this paper is to develop existing modelling strategies by integrating DL based feature
extraction techniques and leveraging social data from health
social media platforms to effectively enhance the current
VOLUME 9, 2021

state-of-the-art solutions in drug identification and extraction.
A summary of selected studies of the exhaustive literature
review is provided in Table 1. These studies are primarily
related to the most recent important drug extraction and
detection developments and was therefore selected for the
summary shown in Table 1.
III. THE PROPOSED ASPECT-BASED SENTIMENT
ANALYSIS APPROACH

In this paper, the proposed ontology-XLNet based aspect sentiment analysis approach for ADRs consists of three phases;
namely, Pre-processing, Feature Extraction, and Sentiment
Classification. Figure 1 depicts the general structure of the
proposed approach.
The pre-processing phase aims to eliminate unnecessary
words for the entire corpus. While, the feature extraction
phase targets evaluating the features and generating the
semantic sense of certain words that are not in the domain
through combining the strength of the lexicalized domain
ontology associated with the XLNet model. Subsequently,
sentiment classification phase takes the embeddings sequence
words as the input of the Bi-LSTM model to classify unstructured text (social media data) and generate the corresponding
sentiment classification.
A. PRE-PROCESSING

In the pre-processing phase, the proposed approach prepares
the input social data text for the features extraction phase.
The major steps of the pre-processing phase are detailed as
follows:
1) Tokenizing social input text for presenting each word
n the input social text as a token and the word can
be divided into more than one sub-word by using the
WordPiece tokenization model.
2) Removing stop words, which do not contain any information, from the sentences, like (is, the, a,.. etc.) using
the Natural Language Toolkit (NLTK).
3) Converting slang words into their standard form.
4) Stemming the words using rule-based stemmer
approach to restore or reduce the derived words inflections) to their word stem (root) form, through cutting
the words accompanied by indentation or subsequent
using a commonly unused set of indentation and suffix,
such as ’-ing’, ’-ed’, ’-pre’, etc.
5) Lemmatizing the words by removing in-flexion endings and returning the words to the base format of
dictionary. As jointly applying stemming and lemmatization makes it flexible to obtain lexical context for
each word and improves the analysis, the proposed
approach used the NLTK suffix-dropping algorithm for
lemmatization and stemming.
6) Converting uppercase to lowercase and the sequences
of more-than-twice repeated characters to its general
terms.
7) Replacing negative mentions by restoring the contracted words to the original uncontracted form. For
90831

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

TABLE 1. Summary of surveyed state-of-the-art studies for literature review primarily relate to the most recent important drug extraction.

example transforming the words ‘‘won’t’’ and ‘‘can’t’’
separately into ‘‘will not’’ and ‘‘can not’’, as social
posts contain different notions of negation. In general
terms, the negation process plays an important role in
determining sentiment polarity of social posts.
8) Spelling correction through generating all keywords
for lexical variants using Levenshtein distance then
filtering any misspelling keywords.
9) Part Of Speech (POS) tagging by assigning labels to
words in a sentence according to their corresponding sentence function. To improve the opinion mining
model, the proposed approach uses POS to reduce the
dimensionality of the matrix using Stanford POS tagger, each word is assigned a label (tag). Then, each
word property is detected by the POS and used to find
the word polarity score.
B. FEATURE EXTRACTION

In this phase, the proposed approach combines the power
of lexicalized ontology and XLNet. The ontology, which
is built using Protégé-OWL framework, is used to extract
semantic relationships among various concepts. Also, the lexicalized domain ontology reasoner is applied to extend the
90832

classical ontology and remove the vague ontology. The
proposed approach uses ontology for two main purposes:
1) ontology contains a set of drug-related entities and
their relationships that are utilized to extract entities from
social data, and 2) lexicalized ontology infers indirect
relationships between entities and their properties and
determines the polarity of drug features of an aspect in
conjunction with direct relationships in reviews, posts, or
tweets [37], [38]. After building the ontology, the proposed
approach uses XLNet word embeddings model to determine
the embeddings sentence, which is concatenated with each
embeddings word to produce a more comprehensive context
and enhance feature extraction performance.
1) LEXICALIZED ONTOLOGY

In this step, the proposed approach aims to extract the
relationship between the content and the meaning in the
input context. Thus, lexicalized ontology is used to extract
lexical-semantic meaning embeddings in the ontology and
enhance its semantic word knowledge. Also, the proposed
approach utilized lexical ontology by mapping opinion data in
SentiWordNet (SWN) to user reviews in order to identify sentiment directions. Furthermore, the procedure of lexicalized
VOLUME 9, 2021

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

FIGURE 1. Architecture of the proposed approach.

ontology extracts the ontology labels (concepts and relations)
based on POS tag extraction, followed by a search in ontology
to find occurrences in the corpus and eliminate the irrelevant
aspects [38]. The recognized semantic similarity determines
searching in SWN and calculates the features aspect polarity
and the corresponding sentiment values. In the proposed
approach, the lexicalized ontology module consists of three
components, as follows:
•
•

SentimentValue: it has Positive and Negative subclasses, and the subclass arrangement follows its status.
AspectDescription: it addresses aspects by relating the
word lexical representation to its corresponding ontology concept.

VOLUME 9, 2021

•

SentimentDescription: it defines the word and types of
different sentiments. This ontology module defines three
types of sentiments; namely:
Type-1 : represents a generic sentiment of unambiguous
consequences in all situations and for all aspects.
Type-2 : is context-dependent and thus it depends on the
context to which it is associated.
Type-3 : represents the context-dependent feeling that
depends on the aspect category.

As shown in the structure of lexicalized ontology building,
depicted in Figure 2, new subclasses are created, driven by the
domain text, since those combinations of sentiment-aspects
are not yet presented in the knowledge graph. As the
90833

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

a synset for a particular word, its frequency is calculated.
Consequently, this frequency score is more reliable than
just the word repeating measure. With ordinary words as
terms, all the occurrences of each word in any completely
different contexts are counted together. With synset terms,
however, these occurrences are context-dependent. Furthermore, if there is no synset for a word, it is replaced by its
lemma, then the similarity between terms is calculated. This
semantic similarity determines searching in SentiWordNet
and calculating features aspect polarity and its corresponding
sentiment values. Finally, word lexicalization is offered in
terms of explaining the lemmas attached to each concept
to deal with multiple words that have the same meaning.
Also, word negation is done by verifying that none of the
three previous words is in the range of negation not, no,
is not, isn’t, won’t, wasn’t, weren’t, haven’t, don’t, can’t,
can’t. When encountered, these words shift the meaning in
sentiment polarity into its opposite.
2) XLNet MODEL

FIGURE 2. Structure of Lexicalized ontology building.

categories are ordered and exclusive, it is only possible to
rely on the higher-order rank if none of the lower-order
classes are balanced (e.g. a given sentiment may only be
of type-2 if its form is not of type-1). SentimentDescription is related to its respective aspects through dimension
annotation. Also, each AspectDescription has its entities and
attributes.
Moreover, the flowchart presented in Figure 3 shows the
main steps of building lexicalized ontology. The first step in
building ontology is to add some general synsets (group of
semantically equivalent data elements) that represent words
like ’bad’, ’painful’, ’distressing’, ’severe’ for each of the
SentimentDescription that has Positive <Type> and Negative <Type> classes. For each of these classes, two general features are added. Each word in a particular class is
accordingly added to the concept as a lexical property. Furthermore, a synsetID is added as a synset property and all
synonyms are added in this class, i.e. ’painful’, ’worrying’,
as lexical properties. The synsetID contains POS #ID format, where POS signifies a part of speech tag and the ID
refers to the unique number denoted from SentiWordNet.
The next step in building lexicalized ontology is adding all
the classes representing different aspects to the ontology,
where SentimentValue is assigned for each class in SentimentDescription. For each class, all aspects that include a
category or attribute are added as an aspect property. Also,
all synonyms are added in this synset as lexicalizations with
the lexical property. In addition, it is also important to know
the fact that there is a separation in the relationship between
all classes of positive<categories/attributes> and all classes
of negative<categories/attributes>. After that, if there exists
90834

In this step, the XLNet embeddings model is employed to
determine the embeddings sentence, which is then concatenated with each embeddings word to produce a more comprehensive context and enhance the performance. In general,
the XLNet is an unsupervised learning method to describe
the language based on a new generalized modeling target
of permutation language modeling. The basic concepts of
XLNet are generalized auto-regressive pre-training for language understanding and Transformer-XL attentive language
modeling. That is to say, XLNet attempts to merge the advantages of auto-regressive models and looks at the preceding
and following words (before and after) to the token to predict
what it should be. Using the idea of permutation language
modeling in XLNet increases the expected log-likelihood
probability of the sequence concerning all possible permutations of the auto-regressive components [37].
Since the parameters of the XLNet model are shared over
all factorization orders, the model will learn from both sides,
and accordingly capture a bidirectional context similar to
autoencoder models. Moreover, Transformer-XL attentive
language model allows non-contiguous tokens to be processed together as well. This improves the understanding of
long-term relationships in the text [17].
For example, as depicted in Figure 4 that shows an illustrative diagram of processing the following sentence: (The
Gel worked but was painful), which presents a piece of raw
input text. In that sentence, it is noticeable that its beginning
has a rather different meaning from the meanings conveyed
by the other positions in the same sentence. Thus, for the
utilized XLNet embeddings model, the input sentence will
first be transformed into a stack of embeddings to predict
the word token in position, as follows: 1) Placing the special
tokens at the start [CLS] and finish [SEP] parameters of
the sequences, and 2) Converting each token into the vector
representation [V x N x d], where V represents the number
of layers, N denotes the sentence length, and d represents
VOLUME 9, 2021

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

FIGURE 3. Lexicalized ontology generation.

FIGURE 4. XLNet pipeline.

the embeddings vector length. The sentence embeddings and
the aspect embeddings are provided by computing positional
encoding for its input as shown in equations (1) and (2), where
pos is the position of a certain word token, i is the dimension
of individual embedding, and d is the embeddings dimension
to each word to get word order.
Then, the last step is 3) Calculating a number of
self-attentions after input the multi-head attention layer. The
formula of self-attention calculation is shown in equation (3),
VOLUME 9, 2021

where X is the embeddings matrix for a single sentence with
n words and M is the embedded dimension, W Q denotes the
query matrix, W K is the key matrix, and W V indicates the
value matrix. Accordingly, as Q is the query stream, which
is formed by including streaming content and embeddings
topical words that will predict (the word in the first position).
Then, the final model prediction is supposed to be made
based on the query stream, as the W c output of the XLNet
model indicates the matrix of vector map to classes for the
90835

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

target word. The procedure of XLNet is described in
Algorithm 1.


pos
(1)
PE(pos,2i) = sin
10, 0002i/dmodel


pos
PE(pos,2i+1) = cos
(2)
10, 0002i/dmodel


(X · W Q ) · (X · W K )>
Softmax
· (X · W V ) (3)
√
dk
Algorithm 1 Feature Extraction With XLNet
INPUT: POS and Feature Polarity
OUTPUT: Feature Vectors

FIGURE 5. Architecture of LSTM unit.

TABLE 2. LSTM unit components.

1:

Setting a pre-defined word ID using WordPiece vocabulary for each output word from the pre-processing phase.

2:

Placing the special tokens at the start [CLS] and finish
[SEP] of the sequences.
Converting each token into the vector representation
Computing positional encoding for its input as shown in
equations (1) and (2).
Calculating a number of self-attentions using equation (3).
Summarizing multi-attention as one self-attention before
going through a perception of a single layer.
Predicting the target words based on the words that are
permuted prior to them as shown in equation (4), where
XLNet allows gathering more information from all positions.

3:
4:
5:
6:
7:

XLNet = log(p(Xzt |Xz<t ))
8:

(4)

Using the output of the encoded token, the [CLS], to set
the output encoded into the classes under which all values
are determined with the probability distribution shown in
equation (5).
P(N |Emb) = f (C > · MC )

(5)

where C > is a feed-forward activation function and M C
is a matrix used to map function onto N classes.
As shown in Algorithm 1, the self-attention mechanism,
once used in the development of encoded vectors, this current
word attention mechanism provides for the management of
other words either to the left or to the right. In the proposed
approach, use a 24-layer transformer encode which each layer
consisting of a 16-head self-attention layer in conjunction
with a single-layer forward feeding network. The embeddings
dimension is 1024.
C. SENTIMENT CLASSIFICATION

As previously discussed, insufficient representation of entities (words) based on their frequencies and syntax rather
than semantics, cause several problems for word recognition
90836

and classification. Thus, in this research we have employed
a modern Deep Learning (DL) model; namely, Recurrent
Neural Network (RNN) [39], [40], with the Long-Short Term
Memory (LSTM) units that are designed with the capability
of learning and storing preceding information as a memory
cell. Figure 5 shows the architecture of the LSTM unit that
holds a I input gate, a F forget gate, and a O output gate
that control updating and using prior information. The components of LSTM units are described in Table 2.
The final output of LSTM is ht , which is determined using
the cell state-input matrix and the feature matrix resulting
from the output gate. The Softmax function, presented in
equation (6), is applied to the LSTM output layer to calculate
the probability value, where c and zk represent the sentiment
category and the input of the time step i, respectively. The
VOLUME 9, 2021

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

calculated probability outputs (0,1) indicate that the social
text feature can be either positive or negative, predicting the
feature sentiment label in the input text.
exp(zi )
Softmax(zi ) = PK
k=0 exp(zk )

(6)

The main aim of this phase is to detect all topics about
the service mentioned by the user from their reviews. The
purpose of this phase is to distinguish features or types of
entities related to events that may be considered sentiment
classification. Moreover, in social media, words can be used
before and after the specified term to determine their semantic
significance. Thus, the proposed approach process text forward and backward; deals with the long document text. One
of the LSTMs advantages is the ability to capture sequential
data by taking into account previous data.The procedure of
LSTM is shown in Algorithm 2.
Algorithm 2 Sentiment classification
Input: Sentence Embeddings Vector
Output: Review Classification
1:

2:
3:

Selecting the number of units or cells, and the result of
the dropout layer is the entry of each cell. The final output
layer shall have the same number of units within the
network.
Combining the outputs into one matrix and moved to a
fully connected layer.
Transforming sequence into a single output within the
range of 0 to 1 by using the fully connected layer to
finally be classified using sigmoid function as shown in
equation (7)
f (x) =

1
1 + e−x

(7)

The proposed approach used the Bi-LSTM model that
means two LSTM neural networks operating in parallel. One
network sequences the input while the other works against
the input sequence. The Bi-LSTM procedure allows both past
and future data to be captured. For example, when text vectors
are set to Bi-LSTM, the first LSTM initially designs text from
left to right, the other LSTM designs the text at the end from
right to left and fully captures feature information to analyze
sentiment.
IV. EXPERIMENTAL RESULTS AND DISCUSSION
A. DATASETS AND EVALUATION METRICS

The datasets used in the experimental work of this research
are constructed based on a set of drug reviews and Twitter
posts extracted from different resource, as follows:
1) AskaPatient [41]: a dataset contains positive, neutral,
and negative reviews of 63,782 drug reviews. Positive
or negative reviews are detected based on feature polarity.
VOLUME 9, 2021

2) WebMD [42]: Web-based health-related services containing a patients forum to share their experiences
with medications. Each reviewer opinion contains several attributes, such as condition, side Effects (ADRs),
dosage, or effectiveness of the used drug. The WebMD
dataset contains approximately 14,000 total drugs that
is crawled along with their total 241,980 associated
review.
3) DrugBank [43]: a dataset contains a list of 215063
reviews on drug conditions, effectiveness, and side
effects for a total number of 6345 drugs.
4) Twitter [44]: a dataset constructed from the posts that
were accessed via an API using Tweepy in Python,
and consists of 267,215 Twitter posts, contains drug
conditions and ADRs, indications, beneficial reactions,
and negative reactions.
5) n2c2 2018 [45]: a benchmark dataset includes 505 summaries from the MIMIC-III healthcare database. It is
divided into 70% training and 30% testing sets, containing 8 attributes with its relation; namely, ADEs,
strength, dosage, duration, frequency, form, route, and
reason for drug.
6) TAC 2017 [46]: a benchmark dataset includes information about ADRs for 200 drugs (101 drugs are used for
the training set and 99 for the testing set), which were
annotated manually. The dataset includes mentions of
the ADRs source and five attributes (Animal, DrugClass, Factor, Negation, and Severity). It also includes
the extraction of three relation types: Effect, Hypothetical, and Negated.
For performance evaluation, the accuracy measurement,
presented in equation (8), is basically used, which refers to the
ratio of correctly classified input topics to the total number of
input topics. However, as accuracy may not objectively reflect
the real performance of the proposed approach considering
probable experienced unbalance in the results, several other
performance measures are calculated; namely, recall (sensitivity), specificity, precision, F-measure, and Hamming loss,
as shown in equations (9), (10), (11), and (13), respectively.
TP + TN
(8)
TP + TN + FP + FN
TP
recall =
(9)
TP + FN
TN
specificity =
(10)
TN + FP
TP
precision =
(11)
TP + FP
In the stated equations, the True Positive (TP) value is the
result in which the model predicts the positive class correctly.
Similarly, the True Negative (TN) value is the result where
the model predicts the negative class correctly. Likewise,
the False Positive (FP) is resulted when the model predicts
the positive class inaccurately and the False Negative (FN)
is an outcome in which the model predicts the negative class
inaccurately.
accuracy =

90837

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

Moreover, for the utilized performance measurements,
the recall is the ratio of correctly resulted or predicted positive labels through the proposed approach to the total actual
positive labels (e.g. the part of relevant documents that are
successfully recovered). Likewise, the precision represents
the ratio of correctly predicted positive labels through the
proposed approach to the total predicted positive labels. Consequently, the F-measure is calculated as the harmonic mean
of precision and recall to show the cumulative effect of both
measures as shown in equation (12).
F-measure =

2 × precision × recall
precision + recall

(12)

In addition, the Hamming loss is also used as a performance measure that highlights the fraction of wrongly
classified labels, as shown in equation (13), where N and
k correspond to the total number of test instances and the
number of classes, respectively. Also, yij represents the class
label for the ith testing instance and ŷij is the label of the
predicted class. The Hamming loss is standardized over the
sample from which it is reported with the loss value is within
[0, 1]; and lower values indicate more exact predictions.
Hamming loss =

1
N ·k

k
N X
X

xor(yij , ŷij )

(13)

i=1 j=1

Furthermore, the Receiver Operating Characteristic (ROC)
is an additional utilized performance measure for assessing the proposed approach. The ROC curve defines relative trade-offs between recall also known as True Positive
Rate (TPR) and specificity also known as False Positive Rate
(FPR). In addition, the Area Under ROC Curve (AUC) allows
the comparison of several classifiers, with the area equivalent
to the likelihood that the classifier ranks an instance that is
picked randomly above a negative instance selected.
On the other hand, the Root Mean Square Error (RMSE),
and the Mean Absolute Error (MAE) measures are also calculated as shown in equations (14) and (15), respectively. The
RMSE is known as the standard error (standard deviation),
which is the square root of the variance. The MAE is computed as an average of the absolute error values.
v
u n
u1 X
RMSE = t
e2t
(14)
n
MAE =

1
n

t=1
n
X

|et |

(15)

t=1

B. EXPERIMENTAL ANALYSIS

Simulation experiments in this article are conducted on a PC
with 2.7 GHz Intel core i7 CPU and 32GB memory with
16 GB GPU. We developed the proposed approach using the
TensorFlow DL framework with Keras Python libraries and
the Protégé OWL tool for ontology creation.
The proposed aspect-based sentiment classification
approach of drug reviews using 10-fold cross validation
90838

FIGURE 6. Area under ROC curve for ranking randomly selected positive
and negative reviews using the proposed ontology-XLNet approach with
6 benchmark datasets.

is tested using 6 different datasets, with XLNet setup
of 12 layers, 768 hidden units, 12 attention heads, and
110M parameters.
Figure 6 shows the ROC curve for the proposed
ontology-XLNet approach with cross-validation with utilizing 6 benchmark datasets. In the ROC curve plot shown
in Figure 6, it is noticed that the proposed approach is closer to
the Y-axis, which means that it fairly attains the most suitable
ratio of TPR against FPR.
As also illustrated in Figure 6, for the tested datasets of
AskaPatient, WebMD, DrugBank, Twitter, n2c2 2018 and
TAC 2017, the ROC operator output shows that the proposed approach receives AUC scores of 0.98, 0.97, 0.95,
0.93, and 0.986, respectively. This means that the proposed
approach ranks the randomly selected positive reviews in a
more powerful manner than the randomly selected negative
reviews. Based on this observation, we distinguish that the
sentiment analysis model is improved by the presented experiment, but this may not be sufficient to assess the system.
Therefore, other metrics are used to evaluate the proposed
approach. Table 3 shows the performance of the proposed
approach using different datasets.
Among the 6 tested datasets, for the two tested benchmark
datasets; namely, n2c2 2018 and TAC 2017 datasets, the proposed ontology-XLNet sentiment classification approach
achieves the highest precision, accuracy, and Hamming loss
values of 0.984, 0.982, and 0.018, respectively, with the
n2c2 2018 dataset. Based on these observations, the proposed
approach achieves the highest accuracy and precision values
as well as the lowest Hamming loss value, which concludes
the ability of the proposed approach to extract the most
relevant features. On the other hand, among the four tested
healthcare social datasets, the proposed approach achieves a
significant F-measure value of 0.985 with the AskaPatient
dataset, supported by a recall ratio of 0.982. Based on the
VOLUME 9, 2021

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

FIGURE 7. Accuracy of the proposed ontology-XLNet model against the other implemented approaches.

TABLE 3. Performance measures of the proposed approach using
different datasets.

results observed, the performance of the proposed approach
obtained no significant difference in results for all the utilized
datasets, with an improved performance for feature extraction
compared to the systems proposed in [33], [36], [37] that
uses the same WebMD and n2c2 2018 datasets, because the
proposed approach extracts the context and semantic meaning
for text and overcomes the problems faced while using the
BERT model that was implemented in other systems, which
reflects the capability of the proposed approach to attain a
high TPR with a lower value of 0.02 for the Hamming loss.
C. COMPARATIVE ANALYSIS AGAINST STATE-OF-THE-ART
APPROACHES

In this subsection, the performance of the proposed ontology with XLNet (ontology + XLNet) approach is compared
against other state-of-the-art feature extraction approaches,
including Word2vec, BERT, XLNet, ontology with Word2vec
(ontology + Word2vec), and ontology with BERT (ontology + BERT). Figure 7 illustrates the results obtained
by the proposed approach against the other implemented
approaches. The depicted results clarify that the proposed
ontology + XLNet approach achieves the most significant
accuracy of 99% with the n2c2 2018 benchmark dataset,
which outperforms the accuracy achieved by the other tested
models; namely, Word2vec (83%), BERT (91%), XLNet
(92.4%), ontology + Word2vec (94.2%), and ontology +
VOLUME 9, 2021

BERT(96.8%). Based on this result, it is concluded that using
XLNet for feature extraction outperforms using BERT and
Word2vec models. The reason behind that observation is
that in Word2vec vocabulary the words match the inclusion
of a fixed-length feature, and Word2vec gets a fixed representation. However, using BERT and XLNet models allows
dynamically representing the meaning of context and word
order. Moreover, using XLNet overcomes BERT’s drawback
of ignoring the interdependence between masked positions,
which causes loss of important information.
Also, based on the obtained results, it is noticed that when
using one of the word embeddings models (Word2vec or
BERT or XLNet) without considering ontology, the approach
does not consider extraction of indirect relationships between
entities and their properties. In addition, it does not also
determine the polarity of drug traits for an aspect in conjunction with the direct relation in reviews and tweets. Therefore, the proposed system combines ontology and XLNet,
as XLNet considers terminology permutations and tries to
predict target words based on which words are exchanged
before the target words with ontology giving the semantic meaning. The high obtained accuracy means that the
proposed approach identifies the most specific features of
the datasets by relying on the semantic information of the
ontology in order to evaluate the features in the text through
helping the XLNet to extract feature terms to be used in the
sentiment classification task.
In Table 4 and Table 5, a summary of the obtained
performance measures and error measures, considering the
proposed approach against other tested approaches, are presented. For the first implemented scenario, using each of the
word embeddings models (Word2vec, BERT, XLNet) for feature extraction without considering ontology, the Word2vec
model achieves 0.819, 0.82 for accuracy and F-measure,
whereas the BERT model achieves 0.89.89 for accuracy and
F-measure and the XLNet model achieves 0.9, 0.92 for accuracy and F-measure, respectively.
90839

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

TABLE 4. Comparative analysis of the proposed approach performance measures against other tested approaches.

TABLE 5. Comparative analysis of the proposed approach performance error measures against other tested approaches.

On the other hand, a second implemented scenario considered using ontology combined with each of the word embeddings models for feature extraction (ontology + Word2vec,
ontology + BERT, ontology + XLNet). From the results
reported in Table 4, it is noticed that the proposed ontology +
XLNet approach outperforms the ontology + BERT model
for feature extraction by 1.3% because BERT applied feature
extraction using masking tokens, which leads to several shortcomings compared to XLNet. Also, The proposed approach
can capture dependencies based on propagating states across
segments as well as capturing the relationships between sentences and aspects. Also, for using ontology + Word2vec
model, it is observed that the proposed approach exceeds that
performance with almost 8% for F-measure and AUC, which
highlights the privilege of the proposed approach gained via
utilizing the XLNet model for extracting the context meaning based on bidirectional representations of unlabeled text,
which is achieved by co-conditioning both left and right
90840

context in all layers. However, the Word2vec model only
obtains statistical representations and does not support outof-vocabulary words. Finally, based on the obtained experimental results, it is generally concluded that the proposed
approach using hybrid feature extraction approach outperforms using single methods for feature extraction.
Furthermore, for Table 5 that illustrates a comparative
analysis of the performance error measures, it is noticed that
the proposed approach achieved an outstanding performance
ratio compared with the other tested approaches. For the
increased size of the training dataset, the proposed approach
shows a much lower MAE of 0.12, against the other models,
such as ontology + BERT and ontology + Word2vec. Based
on this result, it is again concluded that the proposed approach
outperforms other tested models for feature extraction and
sentiment classification tasks.
Figures 8, 9, 10, illustrate the ROC curves for the best features extracted using the Word2vec, BERT, and XLNet word
VOLUME 9, 2021

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

FIGURE 8. Area Under ROC curve for ranking randomly selected positive
and negative reviews using the Word2vec approach with 6 benchmark
datasets.

FIGURE 9. Area Under ROC curve for ranking randomly selected positive
and negative reviews using the BERT model with 6 benchmark datasets.

embeddings approaches, respectively, with the Bi-LSTM
classification model. As shown in Figure 8, the Word2vec
model receives AUC scores of 0.84, 0.83, 0.82, 0.8, 0.825,
and 0.836 for AskaPatient, WebMD, DrugBank, Twitter, n2c2
2018, and TAC 2017 datasets, respectively. It is woth to
mention that the Word2vec model gives a single vector for
a word in a whole sentence that affects the predicted relevant
words. Also, from Figure 9, it is noticed that the BERT
model receives AUC scores of 0.90, 0.89, 0.9, 0.88, 0.91,
and 0.897 for the same list of datasets, respectively. That
means the BERT model improves the correctly predicted
relevant words because BERT captures the context for both
the left and the right words rather than just the direct context.
However, considering Figure 10, one can observe that the
XLNet model receives more enhanced AUC scores of 0.92,
VOLUME 9, 2021

FIGURE 10. Area Under ROC curve for ranking randomly selected positive
and negative reviews using the XLNet approach with 6 benchmark
datasets.

0.912, 0.92, 0.90, 0.917, and 0.93 for the same list of datasets,
respectively. That means the XLNet model achieves more
improved performance by returning the best feature relevant
to the input case. The justification of that observation is
that the XLNet model captures the bidirectional context and
integrates interdependency between masked positions.
On the other hand, Figures 11 and 12 depict the ROC
curves for the best features extracted using the ontology + Word2vec and ontology + BERT approaches, respectively, with the Bi-LSTM classification model. As shown in
Figure 11, the ontology + Word2vec model achieves AUC
scores of 0.893, 0.84, 0.807, 0.797, 0.85, and 0.88 for the
AskaPatient, WebMD, DrugBank, Twitter, n2c2 2018 and
TAC 2017 datasets, respectively. In the ontology + Word2vec
model, combining the ontology technique with the Word2vec
word embeddings model improves the extraction of relations between words, but this enhanced performance is still
limited for only fixed-length representations. Whereas, from
Figure 12 it is observed that ontology + BERT model
received AUC scores of 0.94, 0.942, 0.92, 0.89, 0.95, and
0.93 for the same list of datasets, respectively. The enhancement in the obtained AUC scores is noticeable for some
datasets because of combining the context meaning (through
the BERT word embeddings model) with the semantic
relations between words (through the ontology). However,
the performance still affected in some cases by the problem,
faced by the ontology + BERT model, of ignoring the interdependency between masked positions.
Table 6 shows the performance of proposed approach,
using Bi-LSTM classifier against different ML and DL classification approaches, with the extracted features using the
hybrid ontology-XLNet technique. The investigated classifications algorithms are Support Vector Machines (SVM) [47],
Logistic regression [48], and Random Forest ML classifiers [49] as well as Convolutional Neural Networks
(CNN) [50] DL classification model.
90841

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

FIGURE 11. Area Under ROC curve for ranking randomly selected positive
and negative reviews using the ontology-Word2vec approach with
6 benchmark datasets.

FIGURE 13. Accuracy of the training curves per epoch for the proposed
approach using Bi-LSTM against other classification models.

against the performance of the same tested ML and DL classification algorithms reported in Table 6. The link function
uses a probability within a limited range. In this reasearch,
we used a model of multinomial Logistic regression in terms
of preparation (from 0 to 50 epochs). The resulted observations indicate that the ML algorithms can be successfully
trained after 10 training periods, thus requiring a suitable
number of training epochs. The CNN model is implemented
with a multi-layer neural network and a sigmoid activation
function using the TensorFlow model of the Keras Python
module [51], thus it is profitable in sentiment classification.
In general, the proposed approach usually obtained better
results compared to other classification methods, as shown
in Figure 13.
D. STATISTICAL SIGNIFICANCE TESTS
FIGURE 12. Area Under ROC curve for ranking randomly selected positive
and negative reviews using the ontology-BERT approach with
6 benchmark datasets.

As reported in Table 6, the best results for all the measured
performance metrics are obtained while using the extracted
hybrid features with the Bi-LSTM classifier that outperforms
the other tested classifiers. Based on the demonstrated results
in Table 6, the enhanced performance of the proposed system
with Bi-LSTM in ADRs text classification is a result of
the context memory function of the Bi-LSTM model. Thus,
it enables creating two-way textual patterns that influence the
decision to classify the sensibility feature polarity. Consequently, the results of the proposed system conducted that
combining the Bi-LSTM classification model supports the
functionality of the hybrid ontology + XLNet embeddings
model. However, traditional ML methods neglect the text
context, which leads to imprecise decisions regarding polar
classification.
In Figure 13, a comparison is depicted for the accuracy
obtained by the proposed approach using Bi-LSTM classifier
90842

In order to provide further supportive evaluation for the proposed approach effectiveness, two non-parametric statistical
significance tests are applied; namely, Friedman’s aligned
ranks [52], [53] and Nemenyi post-hoc [54] tests.
For more justification, the proposed approach used Friedman’s aligned ranks test through multiple comparisons to
determine any apparent discrepancies across all the ML and
DL tested algorithms and compute the statistical scores and pvalues, then accordingly conclude the resulted accept/reject
decisions for the null hypothesis, as show in equation (16),
where k is treatment
P number and n is number of blocks
(rows), and r̄·j = 1n ni=1 rij ·rij is the rank of data with a given
block of i.

k 
12n X
k +1 2
(16)
FM =
r̄·j −
k(k + 1)
2
j=1

As shown in Table 7 it is noticed that the Hybrid Feature +
SVM model obtains a statistical value of 2.23, which is the
highest among the values achieved while testing the combination of the Hybrid Feature model with Logistic regression,
Random Forest, or CNN classifiers. However, as the Hybrid
VOLUME 9, 2021

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

TABLE 6. Performance measures of the proposed approach using several ML and DL classifiers.

Feature + SVM model achieves a p-value of 0.07, which
exceeds the P significance level (0.05), the result of that
model presents an acceptance decision for the null hypothesis. It is accordingly concluded that there are equivalence
across all the tested ML methods.
On the other hand, the proposed Hybrid Feature +
Bi-LSTM model achieves a statistical value of 2.23, which
is almost the same as the value achieved while testing the
above mentioned Hybrid Feature + SVM model. Yet, the null
hypothesis is rejected for the proposed Hybrid Feature +
Bi-LSTM model. That is justified by the obtained p-value
of 0.04, which is less than the 0.05 P significance level,
while using the Bi-LSTM classifier. Thus, in this case, it is
concluded that there is an apparent discrepancy considering
the proposed approach against the other models.
Moreover, as the p-value is significant, a post-hoc multiple comparisons test is performed. Thus, in addition to
the non-parametric statistical test, the Nemenyi post-hoc test
is applied in order to determine the degree of rejection of
each hypothesis through the p-values, based on the accuracy.
The Nemenyi test [54] calculates the Critical Distance (CD)
between multiple classifiers as shown in equation (17). The
CD is used to see if there is any major variations between
any two algorithms. That is, through the p-values, it is possible to determine the degree of rejection of each hypothesis.
Accordingly, the p-value can be calculated and compared to
the significance level (p-value < 0.05).
As shown in Table 7, given that the null hypotheses are rejected with the significance p-levels < 0.05,
the Nemenyi post-hoc statistical test is performed at that
point to acquire critical contrasts between the proposed model
and other tested models. As shown in the critical difference diagram depicted in Figure 14, the proposed Hybrid
Feature+Bi-LSTM model outperforms other studied methods by attaining the least rank. Based on the presented average ranking comparison, the proposed approach achieved a
noticeably better performance by being significantly less than
the CD value.
r
k(k + 1)
(17)
CD = qα
6N
E. A CASE STUDY

In order to gain a better understanding of the methodology of the proposed approach, an example of testing ADRs
extraction from drug reviews is adopted as a case study. The
proposed approach picks some drug reviews from WebMD
VOLUME 9, 2021

TABLE 7. Friedman’s aligned ranks test results for the proposed
approach using several ML and DL classifiers.

FIGURE 14. Statistical significance critical difference diagram for
Nemenyi post-hoc statistical test with the average ranking comparison of
the proposed approach against other studied methods.

dataset to explore which word contributes the most sentiment
for a specific goal and which target word is most important. As illustrated in Figure 15, data creation is applied
through tokenization and conversion to lowercase, stemming
and lemmatization to ensure word consistency, then normalization during vocabulary creation and embedding. Afterwards, the proposed approach should figure out that the word
’suffer’ is the most significant target word in the ‘‘Hydroxychloroquine worked well for treating COVID-19, but I suffered from nausea’’ sentence, since the word ’worked’ does
not always imply positive sentiment polarity. Thus, the correct classification results show that the proposed approach
can judge sentiment polarity according to the semantics. On
the other hand, the proposed approach can correctly predict
through the target word ’suffer’ that the ‘‘Hydroxychloroquine’’ review is a side effect (ADR).
Moreover, another case in the same example that has an
indirect relation is the phrase ‘‘rash on the back of my neck’’,
where the proposed approach addresses it by using lexicalized
ontology. Furthermore, in another case with a conjunction of
multiple words ‘‘severely constipated’’, the feature extraction
for that case is employed using the multi-hidden attention layers in the XLNet model. Thus, according to the experimental
90843

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

FIGURE 15. Examples of extracted drug reviews.

results, the proposed approach moves information from the
analysis to sentence-level sentiment classification tasks.
Based on the obtained results, the proposed approach
achieves significant observations in both the discovery and
extraction of ADRs. This represents the ability of XLNet to
outperform other word embeddings models. Also, the combination of XLNet words and sentences with ontology enables
each word to be effectively classified in addition to the
enhanced ability of feature extraction based on the best
semantic meaning. Moreover, the proposed ontology-XLNet
approach achieves an improved aspect sentiment classification performance by 3.1% for the AUC score comparing to the
system previously mentioned in the related work section [33]
that uses the same WebMD dataset. That observation highlights the value of using XLNet model to overcome the BERT
drawbacks. Also, it is noticed that the proposed approach
outperforms the system provided by [37], which used the
n2c2 2018 and TAC 2017 datasets, by 3.5% and 11.2% for
the AUC score, respectively. In general, based on the observations concluded from the presented case study, the proposed
approach provides the main advantage in context information
extraction and indirect sentiment relations with an improved
performance against other surveyed system [33], [37].
V. CONCLUSION AND FUTURE WORK

This paper presents a novel approach for sentiment analysis,
which categorizes text content into predefined sentiment categories at a comprehensive linguistic level taking into account
aspects of the entity. Also, the proposed approach draws
attention to local features and global features to improve
feature extraction and enhance the relationship between
knowledge sets. Moreover, the proposed approach determines
the relationships between aspects and their word context
through employing the XLNet to produce a more comprehensive context and enhance the quality of feature extraction. Subsequently, a lexicalized domain ontology is used
to extract indirect relationships between entities and their
properties.
As mentioned before, the proposed approach intends to
extract the most useful insights from social data. Thus,
the significant research implication of the proposed approach
is supporting users to make decisions though utilizing
90844

detected knowledge from text to give meaning to the word
semantic. Also, it is noteworthy that the proposed approach
outperforms other state-of-the-art methods for sentiment
analysis and feature extraction by combining ontology with
XLNet modeling for word and sentence embeddings, which
accordingly improves sentiment classification. In addition,
the utilized XLNet model in the proposed approach is built
on several pre-training novelties, including data corruptionindependent, factorial permutations, segment recurrence
mechanism, and transformer re-factorization. Consequently,
that structure produces better results with limited data labels
with fine-tuning the pre-trained model. As well, lexicalized
ontology determines the polarity of drug features of an aspect
in conjunction with indirect relationships in reviews and
social posts.
Based on the obtained results, it is observed that the proposed approach performance increases when using ontology with XLNet for feature extraction and Bi-LSTM model
for classification. The proposed ontology-XLNet approach
also presents the feasibility of using XLNet word embeddings over other types of pre-trained or non-pre-trained
word embeddings models by comparing the results of
ADRs drug detection through using social data to extract
the context meaning with considering indirect relations in
semantic between the entire data. Moreover, the proposed
ontology-XLNet approach achieves an improved aspect sentiment classification performance by 2.6% for the F-measure
comparing to the system previously mentioned in the related
work section [33] that uses the same WebMD dataset. Furthermore, the proposed approach outperforms the system
provided by [37] that used n2c2 2018 dataset by 3.02% for
the F-measure. Conclusively, based on the results obtained,
it is observed that the proposed approach outperforms other
system. Although, the proposed approach achieves higher
accuracy in feature extraction and identification in social
media against other social data feature extraction and sentiment classification systems, it still faces several limitations.
The major observed limitation is that, while XLNet captures dependencies in longer sequences by propagating states
across segments compared to BERT model, the performance
rate of XLNet is particularly low when the memory caching
technique is disabled. The reason behind that observation
could be the long context, as giving that BERT could theoretically do long segments too, but at some point, the cost
and memory resources needed for handling long sequences
become restrictive.
For future research work, the stated limitations should be
addressed. Also, it is planned to develop multilingual models, in addition to work on investigating the semi-automated
methods for building ontology in the context of sentiment
analysis.
REFERENCES
[1] I. Korkontzelos, A. Nikfarjam, M. Shardlow, A. Sarker, S. Ananiadou, and
G. H. Gonzalez, ‘‘Analysis of the effect of sentiment analysis on extracting
adverse drug reactions from tweets and forum posts,’’ J. Biomed. Informat.,
vol. 62, pp. 148–158, Aug. 2016.
VOLUME 9, 2021

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

[2] L. Zhang, S. Wang, and B. Liu, ‘‘Deep learning for sentiment analysis:
A survey,’’ Wiley Interdiscipl. Reviews: Data Mining Knowl. Discovery,
vol. 8, no. 4, p. e1253, 2018.
[3] N. V. Babu and F. A. Rawther, ‘‘Multiclass sentiment analysis in text
and emoticons of Twitter data: A review,’’ in Proc. 2nd Int. Conf.
Netw. Adv. Comput. Technol. Thiruvananthapuram, India: Springer, 2021,
pp. 61–68.
[4] G. Lee, J. Jeong, S. Seo, C. Kim, and P. Kang, ‘‘Sentiment classification with word localization based on weakly supervised learning with a
convolutional neural network,’’ Knowl.-Based Syst., vol. 152, pp. 70–82,
Jul. 2018.
[5] X. Fang and J. Zhan, ‘‘Sentiment analysis using product review data,’’
J. Big Data, vol. 2, no. 1, pp. 1–14, Dec. 2015.
[6] V. Kharde and P. Sonawane, ‘‘Sentiment analysis of Twitter data: A survey
of techniques,’’ Int. J. Comput. Appl., vol. 975, p. 8887, Jan. 2016.
[7] M. S. Akhtar, D. Gupta, A. Ekbal, and P. Bhattacharyya, ‘‘Feature selection
and ensemble construction: A two-step method for aspect based sentiment
analysis,’’ Knowl.-Based Syst., vol. 125, pp. 116–135, Jun. 2017.
[8] B. Jang, M. Kim, G. Harerimana, S.-U. Kang, and J. W. Kim, ‘‘Bi-LSTM
model to increase accuracy in text classification: Combining Word2vec
CNN and attention mechanism,’’ Appl. Sci., vol. 10, no. 17, p. 5841,
Aug. 2020.
[9] J. Tao, L. Zhou, and C. Feeney, ‘‘I understand what you are saying: Leveraging deep learning techniques for aspect based sentiment analysis,’’ in
Proc. 52nd Hawaii Int. Conf. Syst. Sci., Maui, HI, USA, 2019, pp. 470–479.
[10] F. M. Plaza-del-Arco, M. D. Molina-González, L. A. Ureña-López, and
M. T. Martín-Valdivia, ‘‘Comparing pre-trained language models for spanish hate speech detection,’’ Expert Syst. Appl., vol. 166, Mar. 2021,
Art. no. 114120.
[11] S. Gupta, M. Gupta, V. Varma, S. Pawar, N. Ramrakhiyani, and
G. K. Palshikar, ‘‘Co-training for extraction of adverse drug reaction
mentions from tweets,’’ in Proc. Eur. Conf. Inf. Retr. (ECIR). Cologne,
Germany: Springer, Apr. 2018, pp. 556–562.
[12] S. Yu, J. Su, and D. Luo, ‘‘Improving BERT-based text classification
with auxiliary sentence and domain knowledge,’’ IEEE Access, vol. 7,
pp. 176600–176612, 2019.
[13] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‘‘BERT: Pre-training
of deep bidirectional transformers for language understanding,’’ in Proc.
Conf. North Amer. Chapter Assoc. Comput. Linguistics, Hum. Lang. Technol., Minneapolis, MI, USA, 2019, pp. 4171–4186.
[14] J. Howard and S. Ruder, ‘‘Universal language model fine-tuning for text
classification,’’ in Proc. 56th Annu. Meeting Assoc. Comput. Linguistics,
Melbourne, VIC, Australia, 2018, pp. 328–339.
[15] Z. Gao, A. Feng, X. Song, and X. Wu, ‘‘Target-dependent sentiment
classification with BERT,’’ IEEE Access, vol. 7, pp. 154290–154299,
2019.
[16] Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. R. Salakhutdinov, and Q. V. Le,
‘‘XLNet: Generalized autoregressive pretraining for language understanding,’’ in Proc. Adv. neural Inf. Process. Syst. (NeurIPS), Vancouver, BC,
Canada, Dec. 2019, pp. 5753–5763.
[17] J. Tao and X. Fang, ‘‘Toward multi-label sentiment analysis: A transfer
learning based approach,’’ J. Big Data, vol. 7, no. 1, pp. 1–26, Dec. 2020.
[18] O. Wallaart and F. Frasincar, ‘‘A hybrid approach for aspect-based sentiment analysis using a lexicalized domain ontology and attentional neural
models,’’ in Proc. Eur. Semantic Web Conf. Portoroz, Slovenia: Springer,
Jun. 2019, pp. 363–378.
[19] F. Ali, S. El-Sappagh, and D. Kwak, ‘‘Fuzzy ontology and LSTM-based
text mining: A transportation network monitoring system for assisting
travel,’’ Sensors, vol. 19, no. 2, p. 234, Jan. 2019.
[20] F. Ali, D. Kwak, P. Khan, S. El-Sappagh, A. Ali, S. Ullah, K. H. Kim,
and K.-S. Kwak, ‘‘Transportation sentiment analysis using word embedding and ontology-based topic modeling,’’ Knowl.-Based Syst., vol. 174,
pp. 27–42, Jun. 2019.
[21] F. Ali, A. Ali, M. Imran, R. A. Naqvi, M. H. Siddiqi, and K.-S. Kwak,
‘‘Traffic accident detection and condition analysis based on social networking data,’’ Accident Anal. Prevention, vol. 151, Mar. 2021, Art. no. 105973.
[22] M. E. Basiri, S. Nemati, M. Abdar, E. Cambria, and U. R. Acharya,
‘‘ABCDM: An attention-based bidirectional CNN-RNN deep model for
sentiment analysis,’’ Future Gener. Comput. Syst., vol. 115, pp. 279–294,
Feb. 2021.
[23] Y. Xiao and G. Zhou, ‘‘Syntactic edge-enhanced graph convolutional networks for aspect-level sentiment classification with interactive attention,’’
IEEE Access, vol. 8, pp. 157068–157080, 2020.
VOLUME 9, 2021

[24] F. Ali, S. El-Sappagh, S. M. R. Islam, A. Ali, M. Attique, M. Imran,
and K.-S. Kwak, ‘‘An intelligent healthcare monitoring framework using
wearable sensors and social networking data,’’ Future Gener. Comput.
Syst., vol. 114, pp. 23–43, Jan. 2021.
[25] S. Liu and I. Lee, ‘‘Extracting features with medical sentiment lexicon and
position encoding for drug reviews,’’ Health Inf. Sci. Syst., vol. 7, no. 1,
p. 11, Dec. 2019.
[26] M. Zhang and G. Geng, ‘‘Adverse drug event detection using a weakly
supervised convolutional neural network and recurrent neural network
model,’’ Information, vol. 10, no. 9, p. 276, Sep. 2019.
[27] B. He, Y. Guan, and R. Dai, ‘‘Classifying medical relations in clinical text
via convolutional neural networks,’’ Artif. Intell. Med., vol. 93, pp. 43–49,
Jan. 2019.
[28] R. Zhao and K. Mao, ‘‘Fuzzy bag-of-words model for document representation,’’ IEEE Trans. Fuzzy Syst., vol. 26, no. 2, pp. 794–804,
Apr. 2018.
[29] A. Cocos, A. G. Fiks, and A. J. Masino, ‘‘Deep learning for pharmacovigilance: Recurrent neural network architectures for labeling adverse drug
reactions in Twitter posts,’’ J. Amer. Med. Inform. Assoc., vol. 24, no. 4,
pp. 813–821, Jul. 2017.
[30] K. Lee, A. Qadir, S. A. Hasan, V. Datla, A. Prakash, J. Liu, and O. Farri,
‘‘Adverse drug event detection in tweets with semi-supervised convolutional neural networks,’’ in Proc. 26th Int. Conf. World Wide Web,
Melbourne, QLD, Australia, Apr. 2017, pp. 705–714.
[31] S. Santiso, A. Pérez, and A. Casillas, ‘‘Exploring joint AB-LSTM with
embedded lemmas for adverse drug reaction discovery,’’ IEEE J. Biomed.
Health Informat., vol. 23, no. 5, pp. 2148–2155, Sep. 2019.
[32] B. Dandala, V. Joopudi, and M. Devarakonda, ‘‘Adverse drug events
detection in clinical notes by jointly modeling entities and relations using neural networks,’’ Drug Saf., vol. 42, no. 1, pp. 135–146,
Jan. 2019.
[33] B. Fan, W. Fan, C. Smith, and H. S. Garner, ‘‘Adverse drug event detection
and extraction from open data: A deep learning approach,’’ Inf. Process.
Manage., vol. 57, no. 1, Jan. 2020, Art. no. 102131.
[34] T. Chen, M. Wu, and H. Li, ‘‘A general approach for improving deep
learning-based medical relation extraction using a pre-trained model
and fine-tuning,’’ Database, vol. 2019, Jan. 2019, Art. no. baz116, doi:
10.1093/database/baz116.
[35] D. Meškelė and F. Frasincar, ‘‘ALDONAr: A hybrid solution for sentencelevel aspect-based sentiment analysis using a lexicalized domain ontology
and a regularized neural attention model,’’ Inf. Process. Manage., vol. 57,
no. 3, May 2020, Art. no. 102211.
[36] L. Chen, Y. Gu, X. Ji, Z. Sun, H. Li, Y. Gao, and Y. Huang, ‘‘Extracting
medications and associated adverse drug events using a natural language
processing system combining knowledge base and deep learning,’’ J. Amer.
Med. Inform. Assoc., vol. 27, no. 1, pp. 56–64, Jan. 2020.
[37] E.-D. El-allaly, M. Sarrouti, N. En-Nahnahi, and S. O. E. Alaoui, ‘‘MTTLADE: A multi-task transfer learning-based method for adverse drug
events extraction,’’ Inf. Process. Manage., vol. 58, no. 3, May 2021,
Art. no. 102473.
[38] M. Schiessl and M. Bräscher, ‘‘Ontology lexicalization: Relationship
between content and meaning in the context of information retrieval,’’
Transinformação, vol. 29, no. 1, pp. 57–72, Apr. 2017.
[39] Y. Wang, M. Huang, X. Zhu, and L. Zhao, ‘‘Attention-based LSTM for
aspect-level sentiment classification,’’ in Proc. Conf. Empirical Methods
Natural Lang. Process. Austin, TX, USA: Association for Computational
Linguistics, 2016, pp. 606–615.
[40] S. Xu, S. E, and Y. Xiang, ‘‘Enhanced attentive convolutional neural networks for sentence pair modeling,’’ Expert Syst. Appl., vol. 151, Aug. 2020,
Art. no. 113384.
[41] A. from. [Online]. Available: https www AskaPatient com (10 Nov. 2018),
‘‘A website for research drugs and health care topics,’’
[42] A Website for Health Care Social Media Topics. Accessed: Oct. 2019.
[Online]. Available: https://www.webmd.com
[43] A Website for Drug Description. Accessed: Oct. 2019. [Online]. Available:
https://www.drug.com
[44] A. Sarker and G. Gonzalez, ‘‘A corpus for mining drug-related knowledge
from Twitter chatter: Language models and their utilities,’’ Data Brief,
vol. 10, pp. 122–131, Feb. 2017.
[45] S. Henry, K. Buchan, M. Filannino, A. Stubbs, and O. Uzuner, ‘‘2018 n2c2
shared task on adverse drug events and medication extraction in electronic
health records,’’ J. Amer. Med. Inform. Assoc., vol. 27, no. 1, pp. 3–12,
Jan. 2020.
90845

A. H. Sweidan et al.: Sentence-Level Aspect-Based Sentiment Analysis for Classifying ADRs

[46] D. Demner-Fushman, S. Shooshan, L. Rodriguez, A. Aronson, F. Lang,
W. Rogers, K. Roberts, and J. Tonning, ‘‘A dataset of 200 structured
product labels annotated for adverse drug reactions,’’ Sci. Data, vol. 5,
no. 1, pp. 1–8, 2018.
[47] F. Ali, K.-S. Kwak, and Y.-G. Kim, ‘‘Opinion mining based on fuzzy
domain ontology and support vector machine: A proposal to automate
online review classification,’’ Appl. Soft Comput., vol. 47, pp. 235–250,
Oct. 2016.
[48] M. A. Saif, A. N. Medvedev, M. A. Medvedev, and T. Atanasova, ‘‘Classification of online toxic comments using the logistic regression and
neural networks models,’’ in Proc. 44th Int. Conf. Appl. Math. Eng.
Econ. (AMEE), vol. 2048, no. 1. Sozopol, Bulgaria: American Institute of
Physics, Jun. 2018, pp. 060011-1–060011-6.
[49] L. Breiman, ‘‘Random forests,’’ Mach. Learn., vol. 45, no. 1, pp. 5–32,
2001.
[50] S. Poria, E. Cambria, and A. Gelbukh, ‘‘Aspect extraction for opinion
mining with a deep convolutional neural network,’’ Knowl.-Based Syst.,
vol. 108, pp. 42–49, Sep. 2016.
[51] F. Z. R. Saraiva, T. L. C. da Silva, and J. A. F. de Macêdo, ‘‘Aspect term
extraction using deep learning model with minimal feature engineering,’’
in Proc. Int. Conf. Adv. Inf. Syst. Eng. (CAiSE). Grenoble, France: Springer,
Jun. 2020, pp. 185–198.
[52] T. M. Beasley and B. D. Zumbo, ‘‘Comparison of aligned friedman rank
and parametric methods for testing interactions in split-plot designs,’’
Comput. Statist. Data Anal., vol. 42, no. 4, pp. 569–593, Apr. 2003.
[53] S. García, A. Fernández, J. Luengo, and F. Herrera, ‘‘Advanced nonparametric tests for multiple comparisons in the design of experiments
in computational intelligence and data mining: Experimental analysis of
power,’’ Inf. Sci., vol. 180, no. 10, pp. 2044–2064, May 2010.
[54] J. Demšar, ‘‘Statistical comparisons of classifiers over multiple data sets,’’
J. Mach. Learn. Res., vol. 7, pp. 1–30, Jan. 2006.

ASMAA HASHEM SWEIDAN received the
M.Sc. degree (Hons.) from the Faculty of Computers and Information, Information System Department, Cairo University, in 2016. Her Ph.D. topic
is about knowledge discovery approach based on
opinion mining and sentiment analysis. She is
currently a Lecturer Assistant with the Faculty
of Computers and Information, Fayoum University. She has authored many articles published
in indexed international journals and conference
papers. Her research interests include machine learning and NLP.

90846

NASHWA EL-BENDARY (Senior Member, IEEE)
received the Ph.D. degree in information technology from the Faculty of Computers and Artificial Intelligence, Cairo University, Egypt, in 2008.
She is currently a Full Professor with the College of Computing and Information Technology,
Arab Academy for Science, Technology and Maritime Transport (AASTMT), Egypt. Her publication history spans more than 80 publications in
reputed international journal articles, conference
papers, and book chapters, and several international research projects and
numerous plenary talks at flagship venues. Her research interests include
machine learning and deep learning, NLP, and image processing. She has
received several recognitions, including the UNESCO-ALECSO Award for
creativity and technical innovation for young researchers, in 2014, and the
L’Oréal-UNESCO for women in science fellowship, in 2015. She currently
serves as an Editorial Board Member for the Applied Soft Computing journal
(Elsevier).

HAYTHAM AL-FEEL received the B.Sc. degree
from the Faculty of Engineering, Qatar University,
and the Ph.D. degree from the College of Electronic Engineering, Menoufia University, Egypt.
He worked as a Full Professor with the Faculty of
Computers and Information, Fayoum University,
Egypt, the CIO and the Project Manager with Fayoum University, and the Vice Dean of the Students
and Academic Affairs, Faculty of Computers and
Information, Fayoum University. He also worked
with the Corporate Semantic Web Research Group, Freie University Berlin,
Germany. He is currently a Professor with Imam Abdulrahman Bin Faisal
University, Saudi Arabia. He has authored many articles published in indexed
international journals and conference papers. His research interests include
Semantic Web, ontology engineering, the Internet of Things, linked data, and
medical computing. He has received several international awards.

VOLUME 9, 2021

