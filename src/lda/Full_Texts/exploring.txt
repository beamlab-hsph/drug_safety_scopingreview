Exploring Possible Adverse Drug Reactions
by Clustering Event Sequences!
Hongxing He1 , Graham Williams1 , Jie Chen1 ,
Simon Hawkins1 , and Chris Kelman2
1

Data Mining Research, CSIRO Math and Information Sciences
GPO Box 664, Canberra, ACT 2601, Australia
Firstname.Lastname@csiro.au
2
Commonwealth Department of Health and Ageing, Australia
Christopher.Kelman@health.gov.au

Abstract. Historically the identification of adverse drug reactions relies
on manual processes whereby doctors and hospitals report incidences to
a central agency. In this paper we suggest a data mining approach using
administrative pharmaceutical usage data linked with hospital admissions data. Patients, represented by temporal sequences of drug usage,
are clustered using unsupervised learning techniques. Such techniques
rely on a distance measure, and we propose in this paper such a distance
measure for comparing drug usage sequences based on an event-type
hierarchy, based around the hierarchical drug classification system. Although developed for a specific domain, we indicate that it is applicable
in other applications involving data where event types form a hierarchical structure, such as is found in telecommunications applications. The
approach modifies the Uniform Kernel K-Nearest Neighbour Clustering
algorithm to constrain the merging of clusters to those clusters within a
specified distance. The approach avoids losing clusters that are less dense
yet far apart, as would occur without such a modification, but is typical
of the types of applications we are interested in (where outliers are important). We demonstrate the algorithm through a successful application
exploring for possible adverse drug events, in particular exploring hospital admissions for severe angioedema resulting from the usage of certain
drugs and drug combinations. The interesting clusters thus identified
have given clues to medical researchers for further investigations.

1

Introduction

Systematic monitoring of adverse drug reactions is important for both financial
and social reasons. In general, the early detection of unexpected adverse reactions
relies on a local voluntary reporting system and collated statistics from overseas
agencies. The availability of a population-based prescribing data set, such as
the Pharmaceutical Benefits Scheme (PBS) data in Australia, when linked to
!

The authors acknowledge the Commonwealth Department of Health and Ageing,
and the Queensland Department of Health for providing data for this research.

Y. Kambayashi et al. (Eds.): DaWaK 2004, LNCS 3181, pp. 199–208, 2004.
c Springer-Verlag Berlin Heidelberg 2004
!

200

Hongxing He et al.

hospital admissions data, provides a unique opportunity to detect common and
rare adverse reactions as the data becomes available and at a much earlier stage
before too many patients are affected. In studying possible adverse drug reactions
from administrative data, like PBS, the entities of interest are patients contain
of all of a patients interactions with the health care system, as temporal event
sequences. Each event, for our purposes, records the dispensing of a prescribed
drug to a patient at a particular time. We can formally represent a temporal event
sequence as s =< (e1 , t1 ), (e2 , t2 ), . . . , (ei , ti ), . . . , (em , tm ) >. For each (ei , ti ),
ei indicates an event type and ti is a timestamp for the event. Traditionally,
temporal event sequences have been transformed, as part of the feature extraction
stage, into a few static features describing some of the characteristics of the
sequences [1, 3]. Inevitably, information is lost in converting the original temporal
sequences into a static feature set.
When clustering patients represented by event sequences, we need to determine a “distance” between sequences. It is well known that distance determination between sequences is very complex, usually involving complicated procedures such as dynamic programming [7]. In this paper, we present a method for
determining the distance between temporal event sequences as might be found in
many application areas, including health. The method takes into account similarity of event-types, dealing with similarity at a number of levels within an
event-type hierarchy using an international drug classification system to identify
similarity between drug types. We introduce an event-type hierarchy to support
the distance measure (Section 3.2). Patients, represented by their drug usage
event sequences, are clustered using the Uniform Kernel KNN Clustering algorithm [11]. We refine the algorithm with a user specified distance constraint to
avoid distant clusters being otherwise merged (Section 4.2).
Section 2 reviews related work. Section 3 introduces our distance measure,
with our clustering method presented in Section 4. Experimental data and results
are given in Section 5. Conclusions and discussion follow in Section 6.

2

Related Work

Similarity of temporal sequences is a key problem in clustering temporal sequence
data. A number of different approaches have been developed for computing the
similarity between two temporal sequences and searching similar patterns using Edit Distances [4, 8, 7] or conditional probability [13]. Edit Distances use
dynamic programming to identify the minimum editing operations needed to
transform one sequence into another, and thereby measure distance based on
the number of operations required. In contrast to the common distance measure, we introduce a computationally inexpensive method using an event-type
hierarchy in this study.
Similar to clustering event sequences, but given in attribute-value representation, COBWEB [2] can produce a classification scheme on observed objects.
In [9] the authors implement the idea of agglomerative hierarchical clustering
and use frequently occurring subsequences as features describing data sequences.

Exploring Possible Adverse Drug Reactions

201

However the similarity measure defined in this paper takes into account not only
general similarity but also the similarity based on an event-type hierarchy. Traditional K-Means clustering, and related methods [5], can not be applied directly
to cluster temporal event sequences since they rely on identifying a mean as
the centroid of the cluster. For temporal event sequences, there is no concept
of a centroid. An alternative clustering method which requires only a distance
measure is K-Medoids [5]. Uniform Kernel KNN is another clustering algorithm
that only requires knowledge of the distances between all pairs of data points.

3

Distance Measure of Event Sequences

The calculation of a distance between two event sequences of different length is
rather difficult if detailed differences are all taken into account. In considering
the drug usage sequences from administrative data, the detailed differences are
not important. The PBS dataset records the date of purchase of the prescribed
drugs. For the purpose of identifying possible adverse drug reactions, the date of
usage is more relevant. Therefore with the dataset available, the best we can do is
to use the date of purchase as the approximation to the date of usage. This causes
significant inaccuracy in the time of occurrence of an event. Consequently we can
only identify what kind of drugs or drugs combinations are used during certain
periods of time with any certainty. In considering the distance between such
temporal event sequences, we might consider only two scenarios: the temporal
event sequences are similar or they are different.
Temporal event sequences might be found to be similar when we ignore
time and frequency, as in the following event sequences:< abc >, < bca >, <
aabbc >, < acbbba >. The sequences here have the same combination of events
but have different order and different frequency. The temporal event sequences
< ab >, < bcad >, < aabef >, < acmnnb > different, even though they have
some common events. In computing the distance between such event sequences,
we take into account both their similarities and their differences. We develop a
similarity measure base on event-type hierarchy to quantify the differences.
3.1

Dissimilarity of Event Sequences

We do not need to consider the difference between event sequences in detail due
to the limitations of the drug usage event sequences data. We only consider the
following three levels of dissimilarity of event sequences:
Identical Sequences. Sometime we choose not to consider the time of occurrences of events within a fixed time window. In this case, two sequences s and
s" are considered identical if they differ only in the time of occurrences. The
distance between them is zero.
Same Combination of Event Types. If two sequences consist of same event
types, then the distance between two sequences is β. The β is an adjustable
parameter.
Different Combination of Event Types. If two sequences are neither identical nor composed of same event type combination, then we consider if they have

202

Hongxing He et al.

common event types or similar event types defined by event-type hierarchy in
Section 3.2. The distance is therefore defined as follows:
distance(s, s" ) = 1.0 − sim(s, s" ),

(1)

where sim(s, s" ) is defined in Section 3.2
3.2

Event-Type Hierarchy

Consider the example of drug prescriptions where two drugs are essentially the
same but have different manufacturer and/or labels. At one level, they are clearly
identical. We introduce an event-type hierarchy to assist in this situation. The
event-type hierarchy identifies a number of levels of aggregation whereby events
might be identified as being the same at some level.
Consider drug prescriptions where drugs are identified using their ATC code 1 .
Figure 1 illustrates a small portion of the defined hierarchy. There are, for example, 14 alternatives at level 1 in the hierarchy (from drugs associated with
Alimentary tract and metabolism to drugs associated with Sensory organs).
Pharmaceuticals

Whocode
Alimentary (A)

...

A

01

AB

06

1

2

3

4

Sensory (S)
...

Stomatological (01)
...

...

Other (16)
...

Level

Fig. 2. Sample WHO Code

Fig. 1. WHO Code Hierarchy

The codes used to identify drugs within the ATC system encapsulate the
hierarchy in seven characters. Drugs can be identified as A03AA01, A02BA06,
A03F A01 and C09AA01. The first character denotes the level 1 ATC code and
can be one of: A,B,C,D,G,H,J,L,M,N,P,R,S and V. The next two characters are
digits and form the level 2 ATC code. The fourth and fifth letters define the
level 3 ATC code and the final two digits identify the level 4 ATC code. Figure 2
illustrates the ATC code for a specific drug (Domiphen). This drug belongs to
alimentary tract and metabolism (A) at level 1, stomatological preparations (A01)
at level 2, and anti-infectives for local/oral treatment (A01AB) at level 3.
We identify events e1 and e2 as being the same at level i with respect to
a user supplied hierarchy, such as above, if they fall within the same node at
level i. For convenience, we identify the maximum level at which they share a
1

Anatomical Therapeutic Chemical (ATC) classification system:
http://www.whocc.no/atcddd/atcsystem.html

Exploring Possible Adverse Drug Reactions

203

node as the level at which they are the same. Thus we identify that the two
drugs A03AA07 and A03AA01 as being the same at level 3 and the two drugs
A13BD08 and A03AA07 the same at level 1.
We introduce a similarity measure with each level i = 1, 2, . . . , nl , where nl
is the number of levels in the hierarchy. We count the number of events (e.g.,
drugs) which are the same at level i and denote it as ci .
For each level we then identify the proportion of “same events” in each sequence (ci /|s| and ci /|s" |) and use the average as the contribution toward similarity at that level. We also introduce a boost factor as the parameter θ (0 ≤ θ ≤ 1)
to boost the similarity measure from 0. This is particularly useful for long sequences.
At a specific level i we thus measure the similarity between two sequences
as:
!
0
if ci = 0
ci
c
(2)
simi (s, s" ) = θ+(1−θ) 12 ( |s|
+ |si! | )
otherwise.
nl
We now sum the similarities at each level, recognising that comparisons at
each level have different contributions (weighted by the adjustable parameters
γi ). The total similarity between two sequences can then be expressed as:
sim(s, s ) =
"

nl
"

γi simi (s, s" ).

(3)

i=1

3.3

Distance Measure

For a pair of sequences, s and s" , we now have a distance measure based on
either their dissimilarity or, if the event sequences do not consist of the same
event type combination, a similarity measure based on the event-type hierarchy.
The final distance between the two sequences, can be expressed as Equation 4

identical sequences
 0.0
"
β
same combination of event types
distance(s, s ) =

"
1.0 − sim(s, s ) otherwise.
(4)
"
The distance so defined will take values 0 ≤ distance(s, s ) ≤ 1 if the following constraints are satisfied: 0 ≤ β ≤ 1 and 0 ≤ γi ≤ 1 for i = 1, 2, . . . , nl .

4

UNKNN and Its Modifications

A distance measure can be used to cluster entities. Representing entities (e.g.,
patients) by their temporal event sequences we now describe an algorithm, and
our modification to the algorithm, to cluster the entities. After presenting the
clustering algorithm we discuss how to measure the quality of the resulting
clusters.

204

4.1

Hongxing He et al.

Uniform Kernel KNN Clustering

dist=2

dist=5

0.05

s1

Density

dist=2

0.00

dist=3

0.15

s2

0.10

s3

0.20

Uniform Kernel KNN Clustering [11] has been used by [6] for clustering sequences. Uniform Kernel KNN Clustering begins by considering each sequence
as a cluster and then merging clusters based on the notion of density. We measure the density around a temporal event sequence si (si ∈ S, S is the set of all
sequences) as the number of sequences, n, within a specific region determined
by some distance d of si . d is the distance to the furthest sequence among those
sequences which are within the set of the n-nearest neighbours. The k shortest
distinct distances from si to other sequences corresponds to n sequences. Note
that n ≥ k since a number of sequences may be the same distance from si .
Figure 3 illustrates this for s1 with k = 3. Here, s2 and s3 are the same distance
from s1 , hence n = 4 and d = 5.

s4

0.0

0.2

s5

Fig. 3. k-nearest distances

0.4

0.6

0.8

1.0

Distance

Fig. 4. Distance distribution

The density of a sequence is then calculated as:
n
.
density(si ) =
|S|d

(5)

The algorithm considers the n nearest neighbours as candidates to merge into
the cluster containing si . A cluster is merged if it has higher density than si and
there is no other closer cluster in the n neighbours having higher density than
si . The density of the new combined cluster is the maximum of the densities of
the two constituent clusters.
For all clusters that have no nearest neighbour with density greater than
itself, we merge into the cluster any other cluster containing nearest neighbours
and having equal density. This step merges “plateau neighbour regions”.
4.2

Distance Constraint

Only the density of the nearest neighbours is used in the algorithm to decide
whether clusters should be merged. For outliers, the nearest neighbours can be
sequences that are actually quite far away, leading to outliers being merged, inappropriately, into its “nearest neighbour”, potentially losing what otherwise may
be important, distinct clusters. We introduce a new constraint to limit the merging of clusters to just those clusters within a specified distance δ, so that the cluster containing sj is merged into the cluster containing si if distance(si , sj ) < δ.

Exploring Possible Adverse Drug Reactions

205

The value of δ should reflect the data being clustered. We can use a simple formula to calculate δ as the global mean distance between all sequences, multiplied
by an adjustable parameter α. The effect of introducing this distance constraint
is demonstrated in Section 4.4.
4.3

Quality of Clusters

The aim of clustering is to partition objects into a number of good, non-overlapping clusters. A good cluster has objects in the same cluster being close to each
other and objects in different clusters being further apart. We can measure the
quality of clustering by introducing the following concepts based on [5].
– We identify the medoid of a cluster of temporal event sequences as that
sequence in the cluster having the minimum mean distance to all other sequences in the cluster, which is defined as the mean inner medoid distance.
The mean inner medoid distance over all clusters is defined as overall mean
inner medoid distance.
– The mean inner cluster distance of a cluster is the overall mean distance
between each pair of sequences in the cluster. The overall mean inner cluster
distance is the mean of the inner cluster distance means over all clusters.
– The mean inter cluster distance between two clusters is the mean pairwise
distance between sequences in each cluster. The overall mean inter cluster
distance is the mean of the inter cluster distance means over all clusters
pairs.
– The overall mean inter medoid distance is the average medoid to medoid
distance over all possible pairs of clusters.
We employ the following two ratios to evaluate the quality of our clusters:
– The Inner-Inter Cluster Ratio is the ratio of the overall mean inner cluster
distance to the overall mean inter cluster distance.
– The Inner-Inter Medoid Ratio is the ratio of the overall mean inner medoid
distance to the overall mean inter medoid distance.
For a given set of clusters, smaller Inner-Inter ratios are certainly desirable.
The Inner-Inter Cluster Ratio is more accurate as a quality measure, since it
considers distance between all pairs, but is computationally more expensive.
4.4

Effect of Distance Constraint

The constrained Uniform Kernel KNN Clustering algorithm can be compared to
the unconstrained algorithm using the quality of cluster measures outlined above.
We use the sequence of drugs used by a patient over a six month period prior
to a hospitalisation for angioedema as our temporal event sequences. Table 1
compares the results with and without the distance constraint.
The additional distance constraint successfully separates a number of outliers. The resulting Inner-Inter Cluster and Medoid Ratios are almost halved.
The minimum distance δ is calculated from the global mean distance between
sequences, as discussed in Section 4.2. Here we use α = 0.9.

206

Hongxing He et al.

Table 1. Comparison of clustering with and
without constraints
Additional distance constraint: Without With
Number of clusters
10
42
Inner-Inter Cluster Ratio
0.64 0.34
Inner-Inter Medoid Ratio
0.48 0.25
Outliers
3
26

5
5.1

Table 2. Distance parameters
Parameter
β
γ1
γ2
γ3
γ4
θ

Description
Value
Same combination 0.1
Hierarchy level 1
0.1
Hierarchy level 2
0.2
Hierarchy level 3
0.3
Hierarchy level 4
0.4
Boost factor
0.3

Experimental Data and Results
Data Description

The Queensland Linked Data Set [12] links hospital admissions data from
Queensland Health with the Commonwealth Department of Health and Ageing’s
pharmaceutical prescription data. In the context of discovering relationships
between drug prescriptions leading to hospitalisations, we construct temporal
event sequences based on six months of prescriptions prior to a hospitalisation
for a particular disease (angioedema). Angioedema was chosen on the basis of
professional advice from Australia’s regulating agency (the Therapeutic Goods
Administration), because it represented a small population of just 222 patients,
useful for experimentation.
Angioedema is a swelling (large welts or weals), where the swelling is beneath
the skin rather than on the surface. It is associated with the release of histamine
and other chemicals into the bloodstream, and is part of the allergic response.
The swelling may occur in the face, neck, and in severe cases may compromise
breathing.
5.2

Distance Measure

The dataset was clustered using the distance measure for temporal event sequences described in Section 3. The parameter values used for the distance measure are listed in Table 2.
The distribution of pairwise distances over the 222 patients is shown in Figure 4 where it is clear that the distance measure is primarily above 0.8.
5.3

Clustering

We apply the Constrained Uniform Kernel KNN Clustering with k = 3 (the
number of nearest neighbours) and α = 0.9 (distance constraint parameter).
The algorithm identified 42 clusters (see Table 3). Twenty six of these were
outliers containing just one member and are not included in the Table. The
overall inner cluster distance is small and the overall inter cluster distance is
large, giving a good Inner-Inter Cluster Ratio of 0.34. Similarly, the Inner-Inter
Medoid Ratio is 0.25.
Below we identify some of the interesting clusters and their characteristics.
We only list a few interesting clusters, where the patients in the same cluster

Exploring Possible Adverse Drug Reactions

207

Table 3. Clusters details(outliers not included)
Cluster Index Cluster Size Mean Inner Medoid Dist Mean Inner Cluster Dist
0
4
0.58
0.78
5
71
0.83
0.90
8
8
0.72
0.84
11
31
0.83
0.88
12
2
0.40
0.81
14
2
0.41
0.82
16
5
0.66
0.84
18
6
0.70
0.86
19
2
0.41
0.82
23
4
0.61
0.84
25
9
0.73
0.85
26
23
0.71
0.89
35
2
0.39
0.78
36
3
0.55
0.83
38
19
0.80
0.88
41
5
0.65
0.89
Overall
0.24
0.32

share many common characteristics and the characteristics may be interesting
to the medical researchers.
– Cluster 11 has 31 patients of which 94% have used cardiovascular system
drugs. 84% of patients have used ACE inhibitors. Subsequent investigation
has identified that ACE inhibitor usage is associated with an increased risk
of hospitalisation for angioedema, a clear adverse reaction. Most patients in
this cluster have used ACE inhibitors during the six month prior to their angioedema hospitalisation. There are a number of case series in the literature
demonstrating that ACE inhibitor-related angioedema is responsible for as
many as 40% of angioedema episodes [10].
– Cluster 26 has 23 patients of which 82% has taken antibacterials for systemic
use. In particular, 78% of the patients have used the amoxicillin, and it may
be of value to further investigate the relationship between this class of drugs
and angioedema.
– Cluster 16 is a small cluster with only 5 patients, all having used a combination of the following four drug groups: cardiovascular system, musculoskeletal system, genito urinary and sex hormones, and general anti-infectives.
Since adverse drug reactions are usually rare events, a small group of patients
sharing such a pattern may be worthy of further investigation.

6

Conclusion and Discussion

This paper develops an effective method for comparing drug usage temporal
event sequences, through general dissimilarity and a similarity measure based on
event-type hierarchy. The Uniform Kernel KNN Clustering algorithm is modified
to cluster the temporal event sequences based on the proposed distance measure.
The modified algorithm ensures that outliers are retained.
The method is applied to real world drug usage sequence. The clusters produced were shown to identify significant areas for further clinical study in the
area of hospitalisation resulting from adverse drug reactions. The results revealed

208

Hongxing He et al.

well known adverse drug reaction of angioedema caused by a popular blood pressure lowering drug i.e. ACE inhibitor. Some possible unknown adverse reactions
of severe angioedema caused by usage of drugs such as anti-bacterials, amoxicillin or usage of combinations of wide range of drugs may be of some values for
further investigations. Although the method has been applied to only adverse
drug reactions of severe angioedema, it can be easily applied to a wide range of
adverse effects of various medical conditions.
The initial methodology, as presented, provides many opportunities for extension and further development. For example, the current experimentation has
not included patient demographics such as gender and age, or other static features like co-morbidity and levels of sickness. The further study may take these
static features into considerations in clustering patients in exploring possible adverse drug reactions. Moreover, it is definitely interesting to study the problem
of adjusting the parameters used in the method automatically.

References
1. R. A. Baxter, G. J. Williams, and H. He. Feature selection for temporal health
records. Lecture Notes in Computer Science, 2035:198–209, 2001.
2. D. H. Fisher. Knowledge acquisition via incremental conceptual clustering. Machine Learning, (2):139–172, 1987.
3. V. Guralnik and G. Karypis. A scalable algorithm for clustering sequential data.
In Proceedings of the 1st IEEE International Conference on Data Mining (ICDM),
pages 179–186, 2001.
4. D. Gusfield. Algorithms on Strings, Trees, and Sequences. Cambridge University
Press, 1997.
5. L. Kaufman and P. Pousseeuw. Finding Groups in Data: An Introduction to Cluster
Analysis. John Wiley and Sons, New York, 1990.
6. H. Kum, J. Pei, W. Wang, and D. Duncan. ApproxMAP: Approximate mining
of consensus sequential patterns. In Proceedings of the 3rd SIAM International
Conference on Data Mining (SDM), pages 311–315, 2003.
7. H. Mannila and P. Ronkainen. Similarity of event sequences. In Proceedings of 4th
International Workshop on Temporal Representation and Reasoning (TIME 1997),
pages 136–139, 1997.
8. P. Moen. Attribute,Event Sequence,and Event Type Similarity Notions for Data
Mining. PhD thesis, University of Helsinki Finland, Jan. 2000.
9. T. Morzy, M. Wojciechowski, and M. Zakrzewicz. Scalable hierarchical clustering
method for sequences of categorical values. In Proceedings of 5th Pacific-Asia International Conference on Knowledge Discovery and Data Mining (PAKDD), pages
282–293, 2001.
10. M. Reid, B. Euerle, and M. Bollinger. Angioedema.
In URL: http://www.emedicine.com/med/topic135.htm, 2002.
11. SAS. Proc Modeclust. In SAS online documentation, 2000.
12. G. Williams, D. Vickers, R. Baxter, S. Hawkins, C. Kelman, R. Solon, H. He, and
L. Gu. The Queensland Linked Data Set. Technical Report CMIS 02/21, CSIRO
Mathematical and Information Sciences, Canberra, 2002.
13. J. Yang and W. Wang. CLUSEQ: Efficient and effective sequence clustering. In
Proceedings of the International Conference on Data Engineering (ICDE03), pages
101–112, 2003.

