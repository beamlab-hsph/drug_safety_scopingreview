ISSN 0361-7688, Programming and Computer Software, 2019, Vol. 45, No. 8, pp. 439–447. © Pleiades Publishing, Ltd., 2019.

Entity-Level Classification of Adverse Drug Reaction:
A Comparative Analysis of Neural Network Models
I. S. Alimovaa,* and E. V. Tutubalinaa,**
a

Kazan Federal University, Kazan, 420008 Russia
*e-mail: alimovailseyar@gmail.com
**e-mail: tutubalinaev@gmail.com

Received February 15, 2019; revised February 15, 2019; accepted March 29, 2019

Abstract—An experimental work on the analysis of effectiveness of neural network models applied to the classification of adverse drug reactions at the entity level is described. Aspect-level sentiment analysis, which aims
to determine the sentimental class of a specific aspect conveyed in user opinions, has been actively studied for
more than 10 years. A number of neural network architectures have been proposed. Even though the models
based on these architectures have much in common, they differ in certain components. In this paper, the
applicability of the neural network models developed for the aspect-level sentiment analysis to the problem
of the classification of adverse drug reactions is studied. Extensive experiments on English language texts of
biomedical topic, including health records, scientific literature, and social media have been conducted.
The proposed models mentioned above are compared with one of the best model based on the support vector
machine method and a large set of features.
DOI: 10.1134/S0361768819080024

1. INTRODUCTION
Due to the rapid development of the Internet and
electronic collections of scientific publications, there
is a vast amount of unstructured data represented in
natural languages. Among the rapidly developing
directions of natural language processing is medical
text processing including texts in pharmacology and
personalized medicine. The automatic processing of
medical texts with the aim of extracting structured
data that can be then used for searching information
about adverse drug reactions (ADR), poor patient
compliance, determining drug effects, and detecting
new relations between medicines and symptoms for
making conjectures about drug repurposing is gaining
popularity.
To reveal the new adverse drug reactions not specified in the summary of product characteristics, the
approach based on analyzing medicine related texts,
such as electronic health records, scientific literature,
patients’ comments in social networks and forums
gains popularity. Such a big amount of data cannot be
processed by hand; for this reason, natural language
processing methods are intensively used [1–5].
The classification of ADR can be considered at two
levels—(i) at the level of message and (ii) at the level of
entity. In the first case, we must find out if ADR is
mentioned in a fragment of the text, e.g., in a sentence
or in a tweet. This type of classification is needed to
clear the text collection from irrelevant documents.

In the second case, classification is applied to the
results produced by algorithms of extracting named
entities. In this paper, we focus on the second problem.
A version of the problem of entity-level classification is aspect-based sentiment analysis. The aim of
aspect-based sentiment analysis is to determine the
user’s opinion not only about an object as a whole but
also about its parts or aspects. In earlier works, a number of neural network architectures based on long
short-term memory (LSTM) have been successfully
used. In this paper, we adapt and apply these methods
for the classification of ADR.
We began our study from simple models that use
only LSTM, and then the architectures were extended
by attention mechanisms and additional memory.
As models, we used the following network architectures:
i. The network with LSTM is the basic model; it
uses the entire sentence represented by word embedding vectors as its input.
ii. The model with target-dependent LSTM (TDLSTM) [6] uses two layers of LSTM for modeling the
contexts to the left and to the right of the entity.
iii. The interactive attention network (IAN) [7],
which consists of two LSTM layers for the representation of the sentence and the target entity and of layers
with cross attention the combined outputs of which

439

440

ALIMOVA, TUTUBALINA

are passed to a layer with the softmax function for
making the classification decision.
iv. The deep memory network (MemNet) [8],
which repeatedly applies the attention mechanism to
the input layer of word embeddings, and the output of
the last attention layer is passed to the layer with the
softmax function for making the classification decision.
v. The network with recurrent attention memory
(RAM) [9] extends the model MemNet by additional
LSTM layers and multiple application of the attention
mechanism to the outputs of these layers.
These models were used for the classification of
users' opinions about restaurants and notebooks;
however, we are not aware of their application for the
classification of ADR at the entity level in pharmacovigilance texts. In this study, we conducted extensive experiments on five benchmark data sets consisting of abstracts of biomedical papers, electronic health
records, and social media texts. We compare the effectiveness of these neural networks and the method
based on support vector machines (SVM) in terms of
the standard classification performance measures.
2. REVIEW OF EXISTING APPROACHES
In the available literature, various approaches to
detecting ADR in texts have been described. The most
widespread approach is based on using lexicons [10–15].
Lexicons consist of lists of adverse drug reactions
names extracted from instruction for medical use,
results of clinical investigations, and comments in
social networks. The first works could deal with only
limited number of drugs and target adverse reactions
due to a limited number of terms in the lexicons. To
overcome this limitation, rule-based methods were
invented [16, 17]. The main idea underlying these
methods is to detect the most widespread structures of
sentences that can indicate a description of an adverse
reaction. However, the development of rules is a long
and complicated procedure, and it requires the
involvement of an expert in the subject domain; furthermore, this approach is not scalable to new collections of documents.
The majority of papers describe studies based on
machine learning methods. For example, in [18–23],
SVM is used; [16, 24] use the conditional random
fields (CRF) method; and [25] uses random forests.
At the input, machine learning algorithms use such
features as n-grams, parts of speech, membership in
semantic types from the unified medical language system (UMLS), the number of words with negation,
membership of the term under examination in the lexicon of adverse reactions, presence of a drug name in
the text, word embeddings, and clustering vectors.
In 2016 and 2017, a competition on detecting messages about ADR in Twitter [26, 27] were held. The

competition included classification problems at the
level of the entire tweet and at the entity level. The
winners of the first competition used a combination of
nine classifiers based on the random forest model [27]
with the following set of features: 1, 2, 3-grams, concurrent mention of a drug and an ADR, presence of
words or phrases with negative meaning, and sentiment evaluation. At the input of each classifier, all
positive examples and the same number of randomly
chosen examples were fed; this allowed the participants to resolve the problem of imbalance of the
classes. The winner achieved the F-measure of
41.95%. In the 2017 competition, the winner in the
tweet-level classification was a system based on the
SVM model [28]. However, in contrast to the preceding year, the set of features was larger. The winner
achieved the F-measure of 43.5%, and thus the result
of the preceding competition was improved by 1.55%.
In the entity-level classification problem, the winner
system used an ensemble of convolutional neural networks [29]. The result of this system was the F-measure of 69.3%.
In 2016, the first studies using neural networks and
devoted to the classification of texts mentioning ADR
were published. In [30], a convolutional neural network and attention convolutional network were used.
The experiments were conducted on two dataset—the
tweets used in the 2016 competition mentioned above
[26] and reports in the system MEDLINE [31]. The
convolutional recurrent neural network achieved the
F-measure of 51% on the corpus consisting of tweets
and of 87% on the corpus MEDLINE. The attention
model achieved the F-measure of 49% and 83%,
respectively. Thus, the increase by 7.5% compared
with the competition result was achieved.
Sentiment analysis methods are widely applied to
medical and other texts [32–35]. In the field of aspectbased sentiment analysis, neural networks are widely
used [36]. Tang et al. [6] described a target dependent
LTSM (TD_LSTM) neural network architecture and
a network with memory MemNet (Deep Memory
Network) for the aspect-level classification [8]. The
proposed models demonstrate the performance comparable with other existing methods. Chen et al. [9]
used the recurrent attention memory (RAM). Their
model repeatedly applies the attention mechanism to
cover the sentiment features that are far from each
other. RAM outperformed the results of earlier
described models on four corpora from different subject domains. Ma et al. proposed an interactive attention network (IAN), which generates separate representations for the context and the aspect and applies
the cross attention mechanism to them [7]. This
model proved to be more effective than various modifications of LSTM neural network.
Based on the analysis of the literature, we conclude
that there are relatively few studies devoted to the use

PROGRAMMING AND COMPUTER SOFTWARE

Vol. 45

No. 8

2019

ENTITY-LEVEL CLASSIFICATION

441

Table 1. Summary statistics of corpora
Corpus

Source

Number of
documents

Number of
ADR

Number of
non-ADR

Maximal
sentence
length

Average
sentence
length

CADEC [41]
MADE [43]
TwiMed-Pubmed [44]
TwiMed-Twitter [44]
Twitter [42]

Comments on forum
Electronic health records
Abstracts of papers
Twitter
Twitter

1231
876
1000
637
645

5770
1506
264
329
569

550
37077
983
308
76

236
173
150
42
37

28
21
39
27
22

of neural networks for ADR classification. The majority of studies use machine learning methods, which are
based on linear models and in which the optimal features must be found by hand [2, 12, 18, 21, 25, 27, 37,
38]. In addition, the majority of methods extract features directly from the entity to be classified paying little attention to the context or using only a small context (four or five words to the left and to the right of the
entity) [21, 25, 39, 40]. We also note that the majority
of studies used only one corpus of data.
3. CORPORA
Experiments of the effectiveness of classification
methods were conducted on four English language
corpora CADEC, Twitter, MADE, and Twimed. The
statistical data for all these corpora are presented in
Table 1. The class ADR in this table denotes the class
with an adverse response, and the class non-ADR
denotes the absence of the adverse response. It is seen
that CADEC and MADE include more annotations
than the other corpora.
3.1. CADEC
The corpus CADEC consists of annotated user
comments about drugs from the forum askapatient.com [41]. In this corpus, five types of annotations
are used: drug, adverse, disease, symptom, and other
medical terms not included in the first four (finding).
The annotation drug marks all names of drugs mentioned in the text. The annotation disease marks indications for the drug application. Symptom marks the
concomitant symptoms of the disease. The annotations disease and symptom were joined to the annotations denoting other medical terms into one group.
3.2. Twitter
The corpus Twitter consists of health related tweets
[42]. In each tweet, adverse reactions or disease entities are marked. The Twitter policy does not allow to
store and distribute tweets in the public domain. The
corpus creators provide only the user identifier and the
tweet identifier, using which the original text can be
loaded. For this reason, some tweets could not be
PROGRAMMING AND COMPUTER SOFTWARE

loaded. The texts were preprocessed to remove all references, user names, and retweets.
3.3. MADE
The corpus MADE consists of depersonalized electronic health records of cancer patients. This corpus was
created for the competition in natural language processing; the aim was to extract medical terms, mentions of
adverse reactions, and relations between them [43]. The
entities with SSLIF and Indication annotations were
joined into the class non-ADR.
3.4. Twimed
The corpus Twimed consists of two parts: user
tweets and texts of papers taken from PubMed [44].
This corpus contains annotations disease, symptom,
and drug. If the relationship between a drug and a disease was annotated as negative, then the disease was
marked as an adverse reaction.
4. ARCHITECTURES
OF NEURAL NETWORKS
In this section, we describe architectures of neural
networks under comparison.
4.1. LSTM
A classical neural network that is a version of recurrent neural networks was described in [45]. This network consists of three layers: input layer, LSTM layer,
and output layer. In the first layer (Embedding), the
input text is encoded into the vector representation
(word embedding), which is passed to the LSTM layer.
This layer reads the input sentence word by word and
stores hidden states. After the entire sentence has been
read, the hidden states are passed to the output classifying layer with the function softmax as a feature.
4.2. TD_LSTM
This model was proposed in [6]; it is an extension
of the LSTM model. It consists of two parts; one part
processes the left-side context and the other part pro-

Vol. 45

No. 8

2019

442

ALIMOVA, TUTUBALINA
Word
Embeddings

Hidden
States

LSTM

Concatenate
hc1

Wc1

hc2

Wc2

...

...

Left
context

hcm

Wcm

Softmax

ha1

Wa1

ha2

Wa2

...

...

Right
context

Label

ham

Wam
LSTM

Concatenate

Fig. 1. The overall architecture of TD LSTM.

Word
Embeddings

Attention

hc1

Wc1
Context

Hidden
States

LSTM
hc2

Wc2

...

...

hcm

Wcm

Concatenate
Pool
Softmax

Label

Pool
ha1

Wa1

ham

Wam

...

...

Aspect

Concatenate

ha2

Wa2

LSTM

Attention

Fig. 2. The overall architecture of IAN.

cesses the right-side contexts. As in the LSTM model,
the input texts go to the layer of word embeddings, and
the outputs of this layer are passed to the LSTM layer.
The hidden state vectors of LSTM layers for the left
and the right contexts are concatenated into one vector. As in the LSTM model, this vector is processed by
the layer with the function softmax, and the class with
the greatest probability is found. An outline of the
architecture of this network is shown in Fig. 1.

4.3. IAN
The model with the interactive attention mechanism was proposed in [7]. The network consists of two
parts each of which constructs a representation of the
context and the entity to be classified using the word
embeddings and the LSTM layer. The resulting vectors are averaged and used to calculate the attention
vector. In the first attention layer, the context vector
and the averaged entity vectors are used; the second

PROGRAMMING AND COMPUTER SOFTWARE

Vol. 45

No. 8

2019

ENTITY-LEVEL CLASSIFICATION
LSTM
Wc1
Wc2

hc2

mc2

hcm

mcm

Attention

hc1

Wa1

Attention

Attention

hc2

Wa2
Wam

hcm

Softmax

...

...

Aspect

mc1

...

Wcn

Memory
hc1

...

...

Context

443

Dense

Dense

Dense

Label

Concatenate

Fig. 3. The overall architecture of RAM.

Word
Embeddings
Wcm

Wc1 Wc2

...

Context

Attention

Attention

Attention

Wa1
Wa2

mean

sum

sum

sum

Softmax

Label

...

Aspect

Wam
Mean

Dense

Dense

Concatenate

Fig. 4. The overall architecture of MemNet.

layer uses the entity vector and the averaged context
vector. The resulting vectors are concatenated and
passed to the layer with the activation function softmax for classification. An outline of the architecture of
this network is shown in Fig. 2.
4.4. RAM
The network with recurrent attention memory was
proposed in [9]. This network consists of three main
parts. The first part processes the context using the
bidirectional LSTM, and the resulting vectors are
saved to memory. The second part is responsible for
the representation of the entity to be classified, and it
also uses the bidirectional LSTM; at the output, it
produces the mean value of all vectors of hidden states
of the entity words. The third part applies attention
mechanisms to the output data of the second part and
the saved data produced by the first part. The output
attention vector is fed to the input of the layer with
PROGRAMMING AND COMPUTER SOFTWARE

controlled recurrent units (gated recurrent units,
GRU). At the next iteration, the output of GRU and
the vectors saved in memory are fed to the input of the
attention layer. This makes it possible to repeatedly
apply the attention mechanism to the data saved in
memory and thus extract more useful information for
classification. The vector obtained as a result of a
number of such iterations is passed to the completely
connected layer with a classifier. An outline of the
architecture of this network is shown in Fig. 3.
4.5. MemNet
The model MemNet was proposed in [8]. This
model consists of two main parts: the memory module, which keeps input data for the context in the form
of distributed representation of words, and the attention mechanism. The attention layer gets at its input an
entity in the form of word embeddings and the vectors
saved in memory. The output of the memory layer is

Vol. 45

No. 8

2019

444

ALIMOVA, TUTUBALINA

Table 2. Classification results of the compared methods for Twitter corpus
Class non-ADR

Class ADR

Macro

Model
SVM
IAN
RAM
MemNet
TD-LSTM
LSTM

P

R

F

P

R

F

P

R

F

0.602
0.654
0.779
0.559
0.606
0.388

0.520
0.627
0.653
0.667
0.547
0.427

0.554
0.634
0.705
0.590
0.570
0.392

0.602
0.951
0.955
0.954
0.940
0.920

0.520
0.957
0.973
0.918
0.952
0.889

0.554
0.954
0.964
0.935
0.946
0.903

0.769
0.802
0.867
0.757
0.773
0.618

0.736
0.792
0.813
0.792
0.749
0.621

0.749
0.794
0.834
0.763
0.758
0.613

summed with the vectors saved in memory and passed
to the next attention layer. An outline of the architecture of RAM is shown in Fig. 4.
5. EXPERIMENTS
In this section, we compare the effectiveness of the
neural networks described above with the SVM model
that uses a large set of features; this comparison is used
to answer the key questions formulated in the Introduction.
5.1. SVM Based Method
We compared the approaches described above with
the classifier proposed in [37]. This classifier is based
on an SVM with a linear kernel. The experiments
showed that the features based on 1-grams, 2-grams,
parts of speech, sentiment, cluster vectors, and
semantic types taken from the UMLS lexicon are most
effective for the classification of ADR. The feature
based on parts of speech consists of the number of
nouns, verbs, adverbs, and adjectives. For the sentiment feature, the lexicons SentiWordNet [46], MPQA
Subjectivity Lexicon [45], and Bing Liu’s [47] were
used. The feature based on the cluster representation
used the clusters from [38] obtained using Brown’s
hierarchical clustering algorithm. The last feature is
the number of tokens from each semantic type in the
UMLS lexicon.
The effectiveness of this method proved to be
higher than the effectiveness of previous approaches
based on machine learning methods and the convolutional neural network.
5.2. Parameters of the Models
We used the vector representation of words trained
on messages taken from social media [38]. This representation was obtained using the model word2vec
trained on an unlabeled corpus consisting of 2.5 million English language user comments about drugs.
The length of vectors is 200. The coverage of the corpora by words from the word embeddings model is as
follows: 93.5% for CADEC, 80.4% for Twitter, 62.5%

for MADE, 81.2% for TwiMed-Twitter, and 76.4% for
TwiMed-Pubmed. For the words out of vocabulary, a
vector of normally distributed random numbers is
generated the values of which are within the values of
the embedding vectors. We used 15 epochs to learn
each model on each corpus; the size of the input block
was 128 for the corpora CADEC and MADE and 32
for the other corpora; the number of hidden states was
300, the learning rate was 0.01, and the l2 regularization was 0.001. In our experiments, the model with this
set of parameters demonstrated the best result. In the
implementation of the model, we used the publicly
available code1.
5.3. Results
All the models were evaluated using the 5-fold
cross validation and the standard classification performance metrics—precision (P), recall (R), and F-measure, which is the harmonic mean of precision and
recall. The results of experiments are presented in
Tables 2–6. The class ADR in these tables denotes the
class with adverse response, and the class non-ADR
denotes the absence of adverse response.
It is seen from these results that the model IAN was
the best in terms of the macro F-measure. The most
significant increase in performance compared with
other models was obtained on the corpora TwimedTwitter and Twitter-Pubmed, where the model IAN
showed 81.9% and 87.4% of macro F-measure,
respectively. On the corpus Twitter, the best result was
shown by the model RAM with the macro F-measure
of 83.4%.
Based on these results, we may conclude that the
partition of the input sentence into the left and the
right context relative to the entity under examination
can improve the classification quality for the corpora
consisting of tweets. This follows from the fact that the
model TD_LSTM with the macro F-measure of
75.8% and 70.3% on the corpora Twitter and TwimedTwitter, respectively, outperformed LSTM with the
macro F-measure of 61.3% and 70%. For the other
corpora, the context partition did not improve the
1 https://github.com/songyouwei/ABSA-PyTorch

PROGRAMMING AND COMPUTER SOFTWARE

Vol. 45

No. 8

2019

ENTITY-LEVEL CLASSIFICATION

445

Table 3. Classification results of the compared methods for CADEC corpus
Class non-ADR

Class ADR

Macro

Model
P

R

F

P

R

F

P

R

F

SVM

0.659

0.620

0.638

0.964

0.969

0.967

0.811

0.795

0.802

IAN

0.699

0.637

0.662

0.966

0.972

0.969

0.832

0.805

0.815

RAM

0.696

0.406

0.506

0.946

0.981

0.963

0.821

0.694

0.734

MemNet

0.575

0.570

0.559

0.960

0.955

0.957

0.767

0.762

0.758

TD-LSTM

0.630

0.557

0.582

0.958

0.967

0.962

0.794

0.762

0.772

LSTM

0.664

0.554

0.602

0.958

0.973

0.966

0.811

0.764

0.784

Table 4. Classification results of the compared methods for MADE corpus
Class non-ADR

Class ADR

Macro

Model
P

R

F

P

R

F

P

R

F

SVM

0.984

0.981

0.982

0.551

0.582

0.562

0.767

0.782

0.772

IAN

0.982

0.991

0.986

0.740

0.524

0.585

0.861

0.758

0.786

RAM

0.980

0.989

0.985

0.615

0.486

0.538

0.798

0.737

0.761

MemNet

0.979

0.991

0.985

0.684

0.447

0.535

0.832

0.719

0.760

TD-LSTM

0.980

0.988

0.984

0.606

0.470

0.515

0.793

0.729

0.750

LSTM

0.981

0.989

0.985

0.636

0.510

0.557

0.809

0.749

0.771

results. On the corpus Twimed-Pubmed, LSTM outperformed TD_LSTM by 7% in terms of the F-measure. On the other corpora, the results are comparable—they differ only by 2%.
The comparison of the results obtained by the
models RAM and MemNet shows that the use of the
LSTM layer before the memory layer was effective
only for the corpus Twitter, on which RAM gave significantly better results in terms of the F-measure
(83.4%) compared with MemNet (76.3%).
The superiority of IAN over RAM and MemNet on
four of the five corpora also shows that the use of additional memory is rarely effective.

6. CONCLUSIONS
The applicability of widespread architectures of
neural networks for aspect-based sentiment analysis in
the problem of classification of adverse drug reactions
was investigated. To evaluate the effectiveness of these
models, extensive experiments on five publicly available text corpora were performed. The results show
that on four of the five corpora the best results were
produced by the model IAN; on one corpus, the best
results were obtained by RAM. Another conclusion is
that the basic architectures are as good as the method
based on SVM; the networks with additional memory
and attention mechanism perform even better, which

Table 5. Classification results of the compared methods for Twimed-Twitter corpus
Class non-ADR

Class ADR

Macro

Model
SVM
IAN
RAM
MemNet
TD-LSTM
LSTM

P

R

F

P

R

F

P

R

F

0.779
0.802
0.799
0.772
0.731
0.669

0.707
0.825
0.736
0.821
0.711
0.757

0.739
0.813
0.764
0.789
0.717
0.709

0.752
0.836
0.773
0.823
0.741
0.743

0.810
0.813
0.823
0.791
0.751
0.649

0.778
0.824
0.796
0.801
0.742
0.691

0.766
0.819
0.786
0.798
0.736
0.706

0.758
0.819
0.779
0.806
0.731
0.703

0.758
0.819
0.780
0.795
0.730
0.700

PROGRAMMING AND COMPUTER SOFTWARE

Vol. 45

No. 8

2019

446

ALIMOVA, TUTUBALINA

Table 6. Classification results of the compared methods for Twimed-Pubmed corpus
Class non-ADR

Class ADR

Macro

Model
SVM
IAN
RAM
MemNet
TD-LSTM
LSTM

P

R

0.925
0.936
0.917
0.929
0.495
0.929

0.955
0.977
0.916
0.912
0.493
0.949

F
00.939
0.956
0.916
0.917
0.487
0.939

P

R

F

P

R

F

0.799
0.878
0.675
0.736
0.932
0.786

0.681
0.738
0.669
0.748
0.930
0.707

0.728
0.792
0.662
0.705
0.931
0.740

0.862
0.907
0.796
0.833
0.714
0.858

0.818
0.858
0.792
0.830
0.712
0.828

0.834
0.874
0.789
0.811
0.709
0.839

proves that they can be used for the classification of
adverse drug reactions.
The future research can go in the following directions:
(1) evaluation of the influence of parameters of the
proposed neural network architectures on the quality
classification;
(2) adaptation of these models for message level
classification;
(3) application of these models for the classification of adverse drug reactions based on texts written in
other languages.
FUNDING
This work was supported by the Russian Science Foundation, project no. 18-11-00284.

REFERENCES
1. Murff, H.J., Patel, V.L., Hripcsak, G., and Bates, D.W.,
Detecting adverse events for patient safety research: A
review of current methodologies, J. Biomed. Inform.,
2003, vol. 36, nos. 1–2, pp. 131–143.
2. Sarker, A., Ginn, R., Nikfarjam, A., O’Connor, K.,
Smith, K., Jayaraman, S., et al., Utilizing social media
data for pharmacovigilance: A review, J. Biomed. Inform., 2015, vol. 54, pp. 202–212.
3. Lardon, J., Abdellaoui, R., Bellet, F., Asfari, H., Souvignet, J., Texier, N., et al., Adverse drug reaction identification and extraction in social media: A scoping review, J. Med. Internet Res., 2015, vol. 17, no. 7.
4. Harpaz, R., Callahan, A., Tamang, S., Low, Y.,
Odgers, D., Finlayson, S., et al., Text mining for adverse drug events: The promise, challenges, and state of
the art, Drug Safety, 2014, vol. 37, pp. 777–790.
5. Harpaz, R., DuMouchel, W., Shah, N.H., Madigan, D.,
Ryan, P., and Friedman, C., Novel data-mining methodologies for adverse drug event discovery and analysis,
Clinical Pharmacology Therapeutics, 2012, vol. 91,
no. 6, pp. 1010–1021.
6. Tang, D., Qin, B., Feng, X., and Liu, T. http://arxiv.org/abs/1512.01100, Cited November 15, 2008.
7. Ma, D., Li, S., Zhang, X., and Wang, H., Interactive
attention networks for aspect-level sentiment classification. arXiv preprint arXiv:1709 00893, 2017.

8. Tang, D., Qin, B., and Liu, T. Aspect level sentiment
classification with deep memory network. arXiv preprint arXiv:1605 08900, 2016.
9. Chen, P., Sun, Z., Bing, L., and Yang, W., Recurrent
attention network on memory for aspect sentiment
analysis, Proc. of the 2017 Conference on Empirical
Methods in Natural Language Processing, 2017, pp. 452–
461.
10. Benton, A., Ungar, L., Hill, S., Hennessy, S., Mao, J.,
Chung, A., et al., Identifying potential adverse effects
using the web: A new approach to medical hypothesis
generation, J. Biomed. Inform., 2011, vol. 44, pp. 989–
996.
11. Yang, C.C., Yang, H., Jiang, L., and Zhang, M., Social
media mining for drug safety signal detection, Proc. of
the 2012 International Workshop on Smart Health and
Wellbeing, 2012, pp. 33–40.
12. Liu, X. and Chen, H., AZDrugMiner: An information
extraction system for mining patient-reported adverse
drug events in online patient forums, Lect. Notes Comput. Sci., 2013, vol. 8040, pp. 134–150.
13. Yeleswarapu, S., Rao, A., Joseph, T., Saipradeep, V.G.,
and Srinivasan, R., A pipeline to extract drug-adverse
event pairs from multiple data sources, BMC Med. Inform. Decision Making, 2014, vol. 14, no. 13.
14. Freifeld, C.C., Brownstein, J.S., Menone, C.M., Bao,
W., Filice, R., Kass-Hout, T., et al., Digital drug safety
surveillance: Monitoring pharmaceutical products in
Twitter, Drug Safety, 2014, vol. 37, pp. 343–350.
15. O’Connor, K., Pimpalkhute, P., Nikfarjam, A., Ginn, R.,
Smith, K.L., and Gonzalez, G., Pharmacovigilance on
Twitter? Mining tweets for adverse drug reactions, Proc.
of the AMIA Annual Symposium, 2014, pp. 924–933.
16. Nikfarjam, A. and Gonzalez, G.H., Pattern mining for
extraction of mentions of adverse drug reactions from
user comments, Proc. of the AMIA Annual Symposium,
2011, pp. 1019–1026.
17. Na, J-C., Kyaing, W.Y.M., Khoo, C.S.G., Foo, S.,
Chang, Y-K., and Theng, Y-L., Sentiment classification of drug reviews using a rule-based linguistic approach, Lect. Notes Comput. Sci. 2012, vol. 7634,
pp. 189–198.
18. Yun Niu et al. Analysis of polarity information in medical text, Proc. of the AMIA Annual Symposium, 2005,
pp. 570–574.
19. Leaman, R. et al., Towards Internet-age pharmacovigilance: Extracting adverse drug reactions from user

PROGRAMMING AND COMPUTER SOFTWARE

Vol. 45

No. 8

2019

ENTITY-LEVEL CLASSIFICATION

20.
21.

22.

23.

24.
25.

26.
27.

28.

29.

30.

31.

32.
33.

34.

posts to health-related social networks, Proc. of the 2010
Workshop on Biomedical Natural Language Processing,
2010, pp. 117–125.
Yun, N. Xiaodan, Z., et al., Predicting adverse drug
events from personal health messages, Proc. of the
AMIA Annual Symposium, 2011, pp. 217–226.
Bian, J., Topaloglu, U., and Yu, F., Towards large-scale
twitter mining for drug-related adverse events, Proc. of
the 2012 International Workshop on Smart Health and
Wellbeing, 2012, pp. 25–32.
Yang, M., Wang, X., and Kiang, M.Y., Identification of
consumer adverse drug reaction messages on social media, Proc. of the Pacific Asia Conference on Information
Systems, 2013.
Sarker, A. and Gonzalez, G., Portable automatic text
classification for adverse drug reaction detection via
multi-corpus training, J. Biomed. Inform., 2015, vol. 53,
pp. 196–207.
Aramaki, E. et al., Extraction of adverse drug effects
from clinical records, Studies Health Technol. Inform.,
2010, vol. 160, no. 1, pp. 739-743.
Rastegar-Mojarad, M., Elayavilli, R.K., Yu, Y., and
Liu, H., Detecting signals in noisy data-can ensemble
classifiers help identify adverse drug reaction in tweets,
Proc. of the Social Media Mining Shared Task Workshop
at the Pacific Symposium on Biocomputing, 2016.
Sarker, A., Nikfarjam, A., and Gonzalez, G., Social
media mining shared task workshop, Proc. of the Pacific
Symposium on Biocomputing, 2016, pp. 581–592.
Sarker, A. and Gonzalez-Hernandez, G., Overview of
the second social media mining for health (SMM)
Shared Tasks at AMIA 2017, Proc. of the 2nd Social Media Mining for Health Research and Applications Workshop, 2017, pp. 43-48.
Kiritchenko, S., Mohammad, S.M., Morin, J., and de
Bruijn, B., NRC-Canada at SMM4H shared task:
Classifying tweets mentioning adverse drug reactions
and medication intake. arXiv:1805 04558. 2018.
Friedrichs, J., Mahata, D., and Gupta, S. InfyNLP at
SMM4H Task 2: Stacked ensemble of shallow convolutional neural networks for identifying personal medication intake from Twitter, 2018. arXiv preprint arXiv:1803 07718
Huynh, T., He, Y., Willis, A., and Ruger, S., Adverse
drug reaction classification with deep neural networks,
Proc. of the 26th International Conference on Computational Linguistics: Technical Papers, 2016, pp. 877–887.
Gurulingappa, H. Rajput, A.M., et al., Development of
a benchmark corpus to support the automatic extraction of drug-related adverse effects from medical
case reports, J. Biomed. Inform., 2012, vol. 45, pp. 885–
892.
Serrano-Guerrero, J. Olivas, J.A., et al., Sentiment
analysis: A review and comparative analysis of web services, Inform. Sci., 2015, vol. 311, pp. 18–38.
Rusnachenko, N. and Loukachevitch, N., Using convolutional neural networks for sentiment attitude extraction from analytical texts, Proc. of the Third Workshop on Computational Linguistics and Language Science, Proc. of the CEUR Workshop, 2018.
Ivanov, V., Tutubalina, E., Mingazov, N., and Alimova, I., Extracting aspects, sentiment and categories of
PROGRAMMING AND COMPUTER SOFTWARE

35.

36.

37.

38.

39.

40.

41.

42.

43.

44.

45.

46.

47.

Vol. 45

447

aspects in user reviews about restaurants and cars, Comput. Linguistics Intel. Technol. Papers from the Annual
International Conference “Dialogue,” 2015, vol. 2,
no. 14, pp. 22–34.
Solovyev, V. and Ivanov, V., Dictionary-based problem
phrase extraction from user reviews, Lect. Notes Comput. Sci., 2014, vol. 8655, pp. 225–232.
Zhang, L., Wang, S., and Liu, B., Deep learning for
sentiment analysis. A survey, Wiley Interdisciplinary
Reviews: Data Mining and Knowledge Discovery, 2018,
vol. 8, no. 4.
Alimova, I. and Tutubalina, E., Automated detection of
adverse drug reactions from social media posts with
machine learning, Lect. Notes Comput. Sci., 2017,
vol. 10716, pp. 3–15.
Miftahutdinov, Z.S., Tutubalina, E.V., and Tropsha, A.E.,
Identifying disease-related expressions in reviews using
conditional random fields, Comput. Linguistics Intel.
Technol. Papers from the Annual International Conference “Dialogue,” 2017, vol. 1, no. 16, pp 155–166.
Korkontzelos, I. Nikfarjam, A., et al., Analysis of the
effect of sentiment analysis on extracting adverse drug
reactions from tweets and forum posts, J. Biomed. Inform., 2016, vol. 62, pp. 148–158.
Dai, H.-J., Touray, M., Jonnagaddala, J., and SyedAbdul, S., Feature engineering for recognizing adverse
drug reactions from twitter posts, Information, 2016,
vol. 7, no. 27.
Karimi, S., Metke-Jimenez, A., Kemp, M., and Wang, C.,
Cadec: A corpus of adverse drug event annotations, J.
Biomed. Inform., 2015, vol. 55, pp. 73–81.
Nikfarjam, A., Sarker, A., et al., Pharmacovigilance
from social media: Mining adverse drug reaction mentions using sequence labeling with word embedding
cluster features, J.Amer. Med. Inform. Assoc., 2015,
vol. 22, no. 3, pp. 671–681.
NLP challenges for detecting medication and adverse
drug events from electronic health records (MADE 1.0),
2018, Massachusetts, Lowell, and Worcester, Amhers.
https://bio-nlp.org/index.php/projects/39-nlp-challenges. Cited November 15, 2008.
Alvaro, N., Miyao, Y., and Collier, N., Twimed: Twitter and pubmed comparable corpus of drugs, diseases,
symptoms, and their relations, JMIR Public Health and
Surveillance, 2017, vol. 3, no. 2.
Wilson, T., Wiebe, J., and Hoffmann, P., Recognizing
contextual polarity in phrase-level sentiment analysis,
Proc. of the Conference on Human Language Technology
and Empirical Methods in Natural Language Processing,
2005, pp. 347–354.
Baccianella, S., Esuli, A., and Sebastiani, F., Sentiwordnet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining, Proc. of the Seventh
conference on International Language Resources and
Evaluation, 2010, pp. 2200–2204.
Hu, M. and Liu, B., Mining and summarizing customer reviews, Proc, of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data
Mining, 2004, pp. 168–177.

Translated by A. Klimontovich
No. 8

2019

