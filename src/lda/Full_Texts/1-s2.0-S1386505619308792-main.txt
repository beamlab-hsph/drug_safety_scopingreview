International Journal of Medical Informatics 135 (2020) 104054

Contents lists available at ScienceDirect

International Journal of Medical Informatics
journal homepage: www.elsevier.com/locate/ijmedinf

Toward systems-centered analysis of patient safety events: Improving root
cause analysis by optimized incident classiﬁcation and information
presentation

T

Chen Lianga, Sicheng Zhoub,1, Bin Yaob,1, Donna Hoodc, Yang Gongb,*
a

Department of Health Services Policy and Management, Arnold School of Public Health, University of South Carolina, Columbia, SC, United States
School of Biomedical Informatics, University of Texas Health Science Center, Houston, TX, United States
c
Division of Nursing, Louisiana Tech University, Ruston, LA, United States
b

A R T I C LE I N FO

A B S T R A C T

Keywords:
Patient safety
Medical error
Root cause analysis
Machine learning
Text mining

Background: Systems-centered root cause analysis (RCA) of patient safety events presents unique advantages as
it aims to disclose vulnerabilities of healthcare systems. However, the increasing number of collected events
poses the problems of low eﬃciency and information overload for traditional RCA.
Objectives: This study aims to improve systems-centered RCA by developing optimized information extraction
and presentation.
Methods: We experimented supervised machine-learning methods to extract safety-related information from
3333 de-identiﬁed patient safety event reports from two independent sources. Based on the extracted information, we further evaluated how optimized information presentation could help facilitate the disclosure of
system vulnerabilities in traditional RCA.
Results: Multilabel text classiﬁcation is eﬀective in identifying safety-related information from the narrative
description of patient safety events. The Pruned Sets in conjunction with Naïve Bayes are the outperformed
algorithm in one dataset, with an overall F score of 60.0 % and the highest F score of 96.0 % for identifying
“Adverse Drug Reaction”. The Classiﬁer Chains in conjunction with Naïve Bayes are the outperformed algorithm
in another dataset, with an overall F score of 43.2 % and the highest F score of 64.0 % for identifying
“Medication”. During the RCA, human experts applied the optimized presentation of information which showed
advantages of identifying system vulnerabilities.
Conclusion: Our study demonstrated the feasibility of using multilabel text classiﬁcation for identifying safetyrelated information from the narrative description of patient safety events. The extracted information when
grouped by safety-related information can better aid human experts to conduct systems-centered RCA and
disclose system vulnerabilities.

1. Introduction
Reporting and analyzing patient safety events have been a national
priority in the US since the National Academy of Medicine (NAM) report “To Err is Human” [1,2]. Over the past decade, patient safety event
reporting continued to evolve, reﬂected in the number of established
reporting systems and collected reports [3–7]. Nevertheless, the measurable outcomes of these eﬀorts are not as clear as expected [8].
Medical errors are the third leading cause of death in the US [9,10]. To
date, patient safety remains an imperative public health challenge that
requires pervasive responses and eﬀective solutions [11–13].

Incident root cause analysis (RCA) is crucial in revealing the causes
of incidents [10]. Because incidents are often results of combined
human errors and system failures, RCA can be explained in two approaches [14]. The person-centered approach accounts for the causes of
incidents by identifying human-related errors, such as wrong procedures, missed doses, miscommunication, etc. These errors are often
related to clinicians’ competency, fatigue, device related maloperations,
etc. Humans tend to make mistakes in reality, especially when clinicians work in extended hours in a complex health care system. The
systems-centered approach focuses on errors caused by healthcare
systems. Although human errors are inevitable, a good system design

⁎

Corresponding author.
E-mail address: yang.gong@uth.tmc.edu (Y. Gong).
1
Equally contributed.
https://doi.org/10.1016/j.ijmedinf.2019.104054
Received 13 August 2019; Received in revised form 18 October 2019; Accepted 11 December 2019
1386-5056/ Published by Elsevier B.V.

International Journal of Medical Informatics 135 (2020) 104054

C. Liang, et al.

Fig. 1. Workﬂow of the machine-learning experiment.

evaluated how events grouped by the same pattern of problematic
safety components can facilitate humans’ decision-making for identiﬁcation of system vulnerabilities.

ought to prevent near misses and unsafe conditions from escalating into
serious incidents [15]. The Swiss cheese model has been a well-known
paradigm to interpret how human errors and vulnerable safety components jointly progress to medical incidents [16]. Safety components
are viewed as slides of cheese and human errors are the holes. Light can
travel through only when the holes in many slides line up. The model
postulates that incidents can be prevented by a number of safety
components such as clinical procedures, administrative controls, and
health information technology (HIT). Each component may have its
own weakness but does not directly lead to a system failure. System
failures occur when multiple components simultaneously go wrong,
bringing hazards into patient harms. Therefore, identiﬁcation of system
vulnerabilities is a critical step of preventing system failure.
Building on the theory of RCA, the London Protocol is a well-established guideline for disclosing system vulnerabilities [17]. However,
it is challenged by the fast-growing collection of patient safety events
because the protocol is based on manual procedures. Despite unique
advantages of identifying progression of incidents and eﬀectiveness of
safety components, manual procedures are labor intensive since disclosing systems vulnerabilities requires identiﬁcation of all problematic
safety components and/or patterns that permit the co-occurrences of
problematic components through review of the events [18]. Notably,
these events contain a sizable portion of “event description” (i.e., free
text provided by clinicians before RCA) that makes it easy to retain an
original proﬁle of clinically important details of care, but is time consuming for manual process. Recent advances in medical informatics
have demonstrated the application of Natural Language Processing
(NLP) and machine learning in processing free text data from EHR and
patient safety events [19]. Yet, EHR-based studies focused on identiﬁcation of adverse events such as central venous catheters related events
[20] and adverse drug events [21]; studies using patient safety events
focused on automated classiﬁcation of events by incident types and
severity levels [22–24] rather than how identiﬁed information can aid
RCA.
To address these problems, we proposed two speciﬁc aims. (1) To
develop a semi-automated method of identifying the problematic safety
components. We developed supervised machine-learning classiﬁers to
identify multiple problematic safety components from the narrative
description of the patient safety events. The identiﬁed information is
critical for human identiﬁcation of system vulnerabilities during RCA.
(2) To evaluate an optimized presentation of extracted information to
facilitate the RCA. In an RCA performed by human experts, we

2. Materials and methods
2.1. Study 1: identifying problematic safety components
2.1.1. Materials
We used two independent datasets for enhanced generalizability.
One dataset, UHCS corpus, was obtained from a university health care
system in the US. It consists of 2919 deidentiﬁed patient safety events
collected in a one-year period. We used the “event description” of data
created by busy and multi-tasking clinicians in hospitals, which contain
typographical errors, acronyms, and synonyms. The narratives of
“event description” were not resulted from an RCA process. The other
dataset, WebM&M corpus, was obtained from the Mortality and
Morbidity Rounds on the Web (WebM&M), consisting of 414 deidentiﬁed cases and commentaries written in formal American English.
We used the case description in the WebM&M corpus. The narratives of
“case description” were phrased by senior clinicians without linguistic
issues.
2.1.2. Experimental design and procedures
As shown in Fig. 1, all of the events were annotated by three domain
experts (SZ, BY, CL) with a focus on the problematic safety components.
The annotations are semantic mentions or clues of safety components
where mistakes have occurred. The annotated events served as the gold
standard for machines to learn and for authors to assess the performance of machine learning.
We calculated label cardinality to provide a precise estimate of data
hierarchy [25].
N

LCard (C ) =

∑i = 1 |yi |
N

N denotes the number of reports in the corpus C . y is the number of
labels associated with an individual report. L denotes the total number
of labels. To avoid extreme label imbalance, minority labels with a
frequency below 50 were removed, resulting in 26 labels
(LCard = 2.62) in the UHCS corpus and 8 labels (LCard = 1.88) in the
WebM&M corpus. Most of the publicly accessible multi-labeled datasets
have a label cardinality ranging from 1 to almost 20 [26], such as the
2

International Journal of Medical Informatics 135 (2020) 104054

C. Liang, et al.

events were excluded to ensure the representativeness. As a result,
the UHCS corpus has 47 patterns (10–211 events per pattern). The
WebM&M corpus has 13 patterns (10–88 events per pattern).
(2) In each corpus, we selected two patterns that have the highest
counts of problematic safety components. A pattern was excluded if
it is a subclass of other patterns. Table 1 shows the selected patterns
that meet the criteria.
(3) We randomly selected ﬁve events from a pattern to form an experimental group. A control group was selected correspondingly.
Finally, it resulted in two experimental groups and two control
groups from each corpus.

Medical dataset (LCard = 1.25) [27] and OHSUMED (LCard = 1.66)
[28]. The UHCS and WebM&M corpora have a higher label cardinality,
proved to be suitable for multi-label classiﬁcation algorithms.
Next, a 10-fold cross-validation with stratiﬁed randomization per
label was used for experiment infrastructure and evaluation of machine-learning performance. F measure, precision, and recall were used
to measure the accurateness of machine judgments. Out of 10 iterations, in each iteration the dataset is randomly splitted into 10 % of
training set and 90 % of testing set. With the help of human annotation,
machines learned how to annotate the events using the training set
followed by an assessment of learning performance using testing set.
In terms of the algorithms to solve the multi-label classiﬁcation, we
adopted the problem transformation approach which requires a problem transformation algorithm used in conjunction with a single-label
algorithm [25]. We employed Classiﬁer Chains [29] and Pruned Sets
[30] to transfer the multi-label problems into single label problems.
Naïve Bayes [31] and Support Vector Machine (SVM) [32] were employed as two base classiﬁers for single label problems. The selection of
these algorithms took into account of two recent studies that used
multi-label classiﬁcation to categorize patient safety event reports
[22,24].
Following the default protocol for text classiﬁcation, the corpora
were transformed from free text into term-document matrices following: (1) word stemming by Snowball [33], (2) stop words removing
by the Rainbow list [34], (3) alphabetic tokenizing, (4) lower cases
transformation, (5) TF-IDF (term frequency-inverse document frequency) transformation with a threshold of 2000 terms, resulting in
2064 terms from the UHCS corpus and 2037 terms from the WebM&M
corpus [35].

2.2.3. Experimental design and procedures
Each participant independently completed the experiment. First,
participants were required to complete the questionnaire of patient
safety competency self-evaluation prior to the experiment. The patient
safety competency is measured by a published questionnaire consisting
of 45 items that measure participants’ knowledge, skill, and attitude
about patient safety [36,37].
Second, participants were asked to perform the RCA upon reviewing
the provided events. Fig. 2 shows the diagram of the experimental
design. Each participant independently reviewed two experimental
groups of reports (n = 5 × 2) and two control groups (n = 5 × 2) in a
randomized order. Each participant answered ﬁve questions after reviewing each group of events. The questions are revised from the
London Protocol (see Table 2). According to our research question, we
expected that participants would have high concensus identifying
system problems or vulnerabilities (question 3). Detailed instructions
were provided for each question prior to the RCA. All participants
completed the RCA within 2 h. All responses were collected and used
for further analysis.

2.2. Study 2: optimized information presentation in root cause analysis
2.2.1. Participants
We assembled four patient safety experts (diﬀerent from who performed annotation) who are registered nurses (RN) with an average of
23 years of practice and extensive experience of patient safety event
reporting and analysis. A small panel as such is typical in RCA for a
consensus agreement. The use of human subjects was approved and
supervised by the institutional review boards (IRB) at Louisiana Tech
University and the University of Texas Health Science Center in
Houston.

3. Results
3.1. Results of study 1
For the UHCS corpus, the most eﬀective algorithm combination is
Pruned Sets (1, 0) in conjunction with Naïve Bayes. The overall performance has reached 60.0 % on F measure, 64.0 % on Precision, and
56.3 % on Recall. The results showed diverse performance in identifying individual labels. For example, a superior performance is observed when identifying “Adverse Drug Reaction” (F = 96.0 %), “Fall”
(F = 92.6 %), “Medication” (F = 85.1 %), and “Intravenous
Medication” (F = 83.1 %). The performance is considerably poor when
identifying labels such as “Suﬀering” (F = 26.7 %), “Communication
Factor” (F = 33.1 %), “Unavailable” (F = 34.0 %), “Missing/
Unavailable Document” (F = 37.9 %), and “Clinical Administration”
(F = 38.7 %) which largely impedes the overall performance.
For the WebM&M corpus, Classiﬁer Chains in conjunction with
Naïve Bayes outperformed other algorithm combinations (F = 43.2 %,
Precision = 41.9 %, Recall = 44.6 %). Performance per individual labels showed that the identiﬁcation of “Medication” (F = 64.0 %) is
most accurate. The identiﬁcation of “Communication Factor” (F = 35.0
%) and “Wrong Progress/Treatment/Procedure” (F = 39.3 %) is least
accurate. See Table 3 for the complete results.

2.2.2. Materials
The patient safety events annotated with a single or multiple problematic safety components from UHCS and WebM&M corpora were
used in the RCA. For each corpus, we selected two experimental groups
of events paired with two control groups. Events in an experimental
group have the same pattern of annotated safety components. Reports
in control groups were randomly selected. We hypothesized that the
presentation of experimental groups of events would improve the disclosure of system vulnerabilities during RCA.
The procedures for selecting experimental groups are as follows. For
each corpus:
(1) We grouped the events by the patterns of problematic safety components. See examples in Table 1. Patterns that cover fewer than 10
Table 1
Selected Patterns for the Experimental Groups.
Patterns used in experimental groups

Problematic safety components in the patterns

UHCS pattern #1 (38 reports)
UHCS pattern #2 (10 reports)

“clinical administration”, “medication/IV”, “wrong drug”, “wrong process, treatment, or procedure”, and “performance factor”
“documentation”, “procedure, test, or treatment”, “documentation missing or unavailable”, “wrong process, treatment, or procedure”,
and “performance factor”
“procedure, test, or treatment”, “wrong process, treatment, or procedure”, “suﬀering”, and “performance factor”
“behavior”, “medication”, and “behavioral factor”

WebM&M pattern #1 (14 reports)
WebM&M pattern #2 (10 reports)

3

International Journal of Medical Informatics 135 (2020) 104054

C. Liang, et al.

Fig. 2. Experimental design. A: Diagram of within-group design. Red and black dots represent experimental groups of events and control, respectively. Each
participant reviewed all groups of events. B: Workﬂow in reviewing each group of events. Each participant was instructed to review a group of events before taking
RCA questions. This procedure repeated for each of the four groups of events. (For interpretation of the references to colour in this ﬁgure legend, the reader is referred
to the web version of this article).

3.2. Results of study 2

Table 2
Questions in the Root Cause Analysis.

The participants have obtained high competency scores of patient
safety knowledge (mean = 4.42, SD = 0.73), skills (mean = 4.71,
SD = 0.46), and attitude (mean = 5, SD = 0).
We extracted the conceptual knowledge from the participants’ responses through the coding method guided by the Grounded Theory
[38]. Table 4 shows the extracted concepts. The downstream analysis of
these concepts revealed salient ﬁndings as follows.
First, the participants discovered a handful of common errors and
contributing factors across all groups of events. Human errors generally
occur such as a failure to follow the protocols and care standards. This
ﬁnding is consistent with the statement that human errors are a major
cause of patient safety events [1]. Communication is a contributing
factor found in all groups of events. Incompetency is also a common

Questions
(1)
(2)
(3)
(4)

What are the common errors during health delivery?
What are the common contributing factors?
What are the system problems or vulnerabilities?
What are the suggestions or actionable plans to mitigate the system problems or
vulnerabilities?
(5) Is there any additional information needed to generate a better narrative of the
incident?

Table 3
Best classiﬁcation performance.
UHCS
f
Overall
Incident Types
Behavior
Clinical Administration
Device
Documentation
Fall
Medication
Intravenous Medication (IV)
Procedure/Test/Treatment
Error Types
Adverse Drug Reaction
Dislodgement/Misconnection/Removal
Missing/Unavailable Document
Failure/Malfunction
Fall at Bed
Noncompliant/Uncooperative/Obstructive
Not Performed When Indicated
Omitted Medicine Dose
Unavailable
Wrong Dose
Wrong Drug
Wrong Patient
Wrong Process/Treatment/Procedure
Severity
Injury
Suﬀering
Contributing Factors
Behavioral Factor
Communication Factor
Performance Factor

WebM&M
Precision

Recall

F

64.0

56.3

60.0

170
253
317
160
359
237
796
861

37.7
52.6
52.9
42.2
84.0
86.8
78.4
67.2

42.4
24.1
53.9
26.9
88.0
74.7
75.6
58.5

58.7
38.7
68.3
42.2
92.6
85.1
83.1
70.3

258
96
98
105
110
98
393
90
66
204
95
89
401

96.4
74.6
37.1
37.7
35.4
27.8
55.2
31.1
37.3
44.6
43.6
37.9
43.4

92.6
55.2
23.5
43.8
36.4
37.8
50.4
41.1
20.5
49.0
43.2
28.1
35.4

123
233

58.4
38.7

169
256
1513

40.6
39.8
80.9

Precision

Recall

F

41.9

44.6

43.2

64
–
–
–
–
94
–
140

39.0
–
–
–
–
57.3
–
42.9

35.9
–
–
–
–
50.0
–
55.7

51.3
–
–
–
–
64.0
–
58.7

96.0
71.0
37.9
60.4
53.0
54.3
65.5
57.8
34.0
64.8
60.0
43.7
51.2

–
–
–
–
–
–
–
–
–
–
–
–
67

–
–
–
–
–
–
–
–
–
–
–
–
27.9

–
–
–
–
–
–
–
–
–
–
–
–
25.4

–
–
–
–
–
–
–
–
–
–
–
–
39.3

36.6
15.5

53.4
26.7

–
102

–
40.0

–
41.2

–
54.3

38.5
20.0
75.7

55.0
33.1
78.2

93
55
167

44.7
22.2
45.1

45.2
21.8
52.7

58.7
35.0
54.6

4

f

- (1) Patient factor

- (2) Human error: failure to act, monitor

5

- (3) Human error: failure to act, incorrect
decision
- (2) Communication: miscommunication

- (3) Human error: failure to assess, act,
observe, monitor, incorrect decision
- (2) Communication: miscommunication

WebM&M #4
(control)

- (1) Medication administration

- (4) Human error: failure to observe, act,
incorrect decisions

- (1) Human error: failure to act, help,
monitor
- (3) Human error: failure to act, observe,
monitor
- (1) Communication: failure

- (1) Medication error

WebM&M #3
(control)

WebM&M #2

WebM&M #1

UHCS #4 (control)

- (1) Communication: miscommunication
- (1) Documentation: missing

- (1) Communication: poor communication

UHCS #3 (control)

None

- (2) Incompetence
- (2) Work environment: workload
- (1) Clinical protocol deﬁciency
- (4) Communication: failure
- (1) Work environment
- (1) HIT design deﬁciency

None

- (1) Communication: failure between primary care
and specialists

- (2) Incompetence
- (4) Communication

- (3) Communication: failure

- (1) HIT design deﬁciency

- (1) HIT: lack of HIT
- (1) Communication: poor communication
- (2) Medication administration deﬁciency:
medication labels

- (3) Medication administration deﬁciency: medication
labels

- (2) Clinical protocol deﬁciency

- (1) HIT design deﬁciency: EHR design

- (1) Documentation: missing documentation in EHR

- (3) Incompetency: lack of knowledge

- (2) Incompetence: failure to follow
protocol; lack of knowledge
- (1) Communication: poor communication

- (1) Incompetence

- (1) Documentation

- (3) Clinical protocol deﬁciency: oxygen
administration should require provider’s order

- (2) Communication: poor communication

- (3) Care deviation: no order for oxygen
supplement
- (3) Human error: failure to act, incorrect
decisions
- (1) Communication: not seeking proper
help
- (1) Documentation: missing

UHCS #2

- (1) Communication: team work; between
departments
- (4) Clinical protocol deﬁciency: not following Joint
Commission standards; not identifying patient ID
before specimens

Q3 (system problems)

- (2) Communication: poor communication
- (2) Incompetence: lack of knowledge

- (4) Care deviation: no armband or
wristband
- (4) Human error: failure to observe

Q2 (contributing factors)

UHCS #1

Q1 (errors)

Table 4
Coded responses by the participants during the Root Cause Analysis.

- (1) Enhance education

- (1) Improve communication

- (2) Enhance education

- (1) Enhance education
- (1) Improve communication
- (2) Improve medication
administration: pharmacy revisions,
CPOE
- (1) Improve clinical protocol: cross
check

- (1) Improve clinical protocol

- (2) Improve medication
administration
- (1) Enhance education

- (1) Improve documentation

- (1) Improve clinical protocol: use
double check

- (1) Enhance HIT: EHR to incorporate
bedside ID scanning
- (2) Enhance education: nursing
safety, clinical orders
- (1) Improve communication: to seek
proper help
- (1) Improve documentation: add
nursing notes
- (2) Enhance HIT: add alerts

- (3) Enhance education: avoid human
mistakes
- (2) Improve clinical protocol: check
patient ID in all departments

Q4 (suggestions)

- (1) Clinical protocol and
process

- (1) Clinical protocol and
process

- (1) Medication dispense
system

- (1) Vacancy report

- (1) Clinical protocol and
process
- (1) Patient assessment

- (1) Clinical protocol and
process

- (1) Incident reports:
contextual information
- (1) Patient assessment

- (1) Clinical orders
information

- (1) DNR information

Q5 (additional
information)

C. Liang, et al.

International Journal of Medical Informatics 135 (2020) 104054

International Journal of Medical Informatics 135 (2020) 104054

C. Liang, et al.

reporting formats used in the US, favor generic and rare types of individual incidents rather than the continuum of healthcare and the
intricate safety components across multiple events [39]. To bridge this
gap, our study demonstrated the value of the free-text portion of events.
Besides, understanding the narratives of events can in return provide
insights on improving standards for structured reporting.
Second, despite the advanteges of manual RCA, the fast-growing
body of reported events would make the process extremely time-consuming. As a supplement for RCA, our approach can reduce human
labor without disregarding the unique advantages of RCA. The major
portion of human eﬀorts in our approach is annotating a training set of
events to create classiﬁers. In reality, the size of this training set ranges
between hundreds to thousands of events. – The more components, the
larger the training set is needed. Once the classiﬁers are trained with an
acceptable accuracy level, they can be used to process new events with
minimal supervision.

contributing factor found in six groups of events (was not found in
UHCS#3 and WebM&M#4). Clinical protocol deﬁciency was founded
as a contributing factor (2/4 votes) in WebM&M#3, which was then
submitted as a major system problem (3/4 votes).
Second, the participants discovered more system problems or vulnerabilities, with higher consilience, in the experimental groups of
events as compared to control groups. Clinical protocol deﬁciency was
voted a major system problem in UHCS#1 (4/4 votes), UHCS#2 (3/4
votes), and WebM&M #1(2/4 votes). Design deﬁciency was voted a
major system problem in WebM&M#2 (3/4 votes). Participants did not
either reach a consensus or ﬁnd any system problem in control groups.
Third, there was no observable discrepancy for “suggestions” and
“additional information” between groups. “Enhancing patient safety
education” and “improving clinicians’ competency” were generally
suggested in all groups of events. “Leveraging HIT components”, e.g.,
error detection and alerting, was also suggested to help reduce errors.
In the experimental groups of events, corresponding suggestions, e.g.,
how to ﬁx the problematic clinical protocols, were submitted to address
the system problems. A few participants indicated that information
from additional clinical information systems could help the RCA.

4.3. Limitations and future directions
As compared to many text classiﬁcation tasks using clinical data, the
performance of our classiﬁers is not superior. One obvious reason is that
the narratives of patient safety events are highly unstructured. In addition, as a multi-label classiﬁcation task where label imbalance is inevitable, the overall performance is heavily inﬂuenced by the outstanding performance of speciﬁc labels. This ﬁnding is consistent with a
recent study on multi-label classiﬁcation using reports from the
Advanced Incident Management System (AIMS) in Australia [22]. Besides, due to the small sample size, the generally deﬁned labels may not
capture details of safety components. In the future, we will make improvement on (1) text processing tailored for patient safety events and
(2) expanding the size of the dataset to remediate the problems of label
imbalance.

4. Discussion
4.1. Principal ﬁndings
Our study demonstrated the feasibility of identifying problematic
safety components from the narrative description of patient safety
events. Although this work is traditionally performed by human experts
during RCA, our ﬁndings suggest the eﬃciency of machine learning
with the potential for clinical implementation. Speciﬁcally, Naïve Bayes
was identiﬁed the most eﬀective binary classiﬁcation algorithm when
used in conjunction with Pruned Sets (1, 0) for UHCS corpus and
Classiﬁer Chains for the WebM&M corpus, respectively. Depending on
the dataset, the algorithms could be adjusted. The overall performance
for the UHCS corpus was beyond moderate and was heavily inﬂuenced
by the inferior performance associated with individual safety components that may be too broad to show identiﬁable facts, such as “Clinical
Administration” (F = 38.7 %), “Unavailable” (F = 34.0 %), and
“Communication Factor” (F = 33.1 %) are generic labels with limited
details of the errors. It could also be associated with annotated components that are less objective, such as “Suﬀering” (F = 26.7 %). The
overall performance for the WebM&M corpus was comparatively less
accurate for two possible reasons: (1) small corpus size and (2) loss of
semantic features due to the rephrased description of events.
Our study demonstrated a potential strategy for incorporating the
machine-annotated patient safety events in human-performed RCA.
Reports grouped by the same patterns of problematic safety components can help human experts identify system vulnerabilities. This
ﬁnding is consistent with the theory of the Swiss cheese model and the
London Protocol. Identifying system vulnerabilities is of high value to
patient safety enhancement in a healthcare system. Our experiment
suggested that “clinical protocol deﬁciency” or “protocol not followed”
is a major system problem but often ignored during the traditional RCA.
Other types of system failure exist in reality [14] but were not discovered in this study.

5. Conclusions
We suggest that (1) inter-connected problematic safety components
can be identiﬁed from the narratives of patient safety events; (2) these
components are important clues for disclosing vulnerabilities of
healthcare systems during RCA. Our study demonstrated the feasibility
and eﬃciency of text classiﬁcation for identiﬁcation of problematic
safety components before RCA. We further demonstrated how identiﬁed information can help a better disclosure of system vulnerabilities
during RCA.
Authors’ contributions
CL and YG led the conception and design of the study and the
preparation of the manuscript. CL led the design and implementation of
the experiments, data acquisition, analysis, and interpretation. SZ, BY,
DH, and YG contributed to data acquisition and analysis. All authors
contributed to the revision and ﬁnal approval of the manuscript.
Declaration of Competing Interest
None declared.
Summary table
What was already known on the topic?

4.2. Policy implications

• Patient safety remains a crucial public health concern.
• The nation-wide patient safety event reporting in the US provides
data sources for patient safety study.
• In clinical practice, root cause analysis is eﬀective in analyzing pa-

As an integral part of the patient safety event analysis, systemscentered RCA needs robust evidence from empirical studies and applicable strategies for clinical implementation. Our study could help
bridge two major gaps as follows:
First, the current development of patient safety event reporting is on
the way to supplying suﬃcient information for systems-centered analysis. For example, the common deﬁnitions and reporting formats
(a.k.a., the Common Formats 2.0) for incident reporting, which are

tient safety events and generating actionable knowledge for improved patient safety.
What this study added to our knowledge.

6

International Journal of Medical Informatics 135 (2020) 104054

C. Liang, et al.

• Systems-centered root cause analysis is advanced in disclosing vul•
•

vulnerabilities.

nerabilities of health systems if problematic safety components can
be extracted from patient safety events and presented to domain
experts eﬀectively.
Semi-automated machine-learning methods can be used to identify
problematic safety components from the event description of reports.
The information presentation in systems-centered root cause analysis can be optimized to facilitate the disclosure of system

;1;
Acknowledgment
This work was supported by the Agency for Healthcare Research
and Quality [1R01HS022895], the University of Texas System
[#156374], and a seed grant from University of South Carolina.

Appendix A
1) UHCS

Overall
Incident Types
Behavior
Clinical Administration
Device
Documentation
Fall
Medication
Intravenous Medication (IV)
Procedure/Test/Treatment
Error Types
Adverse Drug Reaction
Dislodgement/Misconnection/Removal
Missing/Unavailable Document
Failure/Malfunction
Fall at Bed
Noncompliant/Uncooperative/Obstructive
Not Performed When Indicated
Omitted Medicine Dose
Unavailable
Wrong Dose
Wrong Drug
Wrong Patient
Wrong Process/Treatment/Procedure
Severity
Injury
Suﬀering
Contributing Factors
Behavioral Factor
Communication Factor
Performance Factor

PS + NB
Precision
64.0

Recall
56.3

F
60.0

PS + SVM
Precision
62.5

Recall
52.1

F
56.8

CC + NB
Precision
38.5

Recall
70.8

F
50.0

CC + SVM
Precision
55.0

Recall
54.7

F
54.9

37.7
52.6
52.9
42.2
84.0
86.8
78.4
67.2

42.4
24.1
53.9
26.9
88.0
74.7
75.6
58.5

58.7
38.7
68.3
42.2
92.6
85.1
83.1
70.3

38.9
51.9
50.4
46.2
77.5
83.0
74.0
61.1

16.5
21.7
39.4
26.3
85.5
74.3
73.0
57.7

28.2
35.6
55.8
41.4
90.7
84.7
80.8
68.6

17.4
22.4
42.6
21.8
80.4
73.3
77.3
59.0

68.8
53.8
60.9
45.6
87.7
77.6
74.1
69.7

73.7
65.1
72.6
60.7
92.1
86.4
82.0
74.4

27.7
33.6
42.8
35.0
84.3
76.2
71.6
59.5

30.0
36.8
42.3
35.6
85.0
68.8
73.4
61.3

45.6
52.7
58.1
52.0
90.9
80.9
80.5
70.4

96.4
74.6
37.1
37.7
35.4
27.8
55.2
31.1
37.3
44.6
43.6
37.9
43.4

92.6
55.2
23.5
43.8
36.4
37.8
50.4
41.1
20.5
49.0
43.2
28.1
35.4

96.0
71.0
37.9
60.4
53.0
54.3
65.5
57.8
34.0
64.8
60.0
43.7
51.2

97.0
75.4
42.4
39.0
30.1
39.6
50.0
23.6
29.0
41.3
41.1
31.8
39.5

88.8
54.2
28.6
15.2
30.9
19.4
51.9
28.9
11.9
41.7
38.9
23.6
37.4

93.9
70.1
44.3
26.4
46.9
32.4
66.3
44.5
21.3
58.0
55.8
38.1
53.0

92.5
41.9
13.8
21.0
27.4
12.1
36.5
19.0
19.0
30.0
24.8
19.0
30.5

91.5
81.3
44.9
63.8
87.3
74.5
66.4
71.1
60.3
77.0
54.7
49.4
49.1

95.2
88.1
60.0
75.0
89.1
77.7
73.4
79.6
70.9
81.5
69.3
64.6
61.5

95.9
59.3
35.1
31.8
28.9
25.0
44.8
16.8
15.4
39.8
40.4
43.8
36.1

90.3
50.0
33.7
20.0
30.0
19.4
45.5
18.9
14.6
41.2
44.2
36.0
40.9

94.7
66.4
50.1
33.2
45.8
32.4
60.8
31.6
25.3
57.5
60.9
52.7
55.9

58.4
38.7

36.6
15.5

53.4
26.7

69.2
39.0

29.3
10.0

45.2
17.9

19.9
17.1

72.4
66.5

79.1
69.2

46.7
24.3

35.0
23.6

51.6
37.7

40.6
39.8
80.9

38.5
20.0
75.7

55.0
33.1
78.2

49.1
39.1
74.9

16.0
9.8
75.1

27.5
17.8
74.0

17.2
21.6
80.3

68.6
72.3
79.0

73.7
73.5
79.1

40.0
23.1
74.3

29.6
23.8
74.6

45.4
37.9
73.4

2) WebM&M

Overall Performance
Incident Types
Behavior
Medication
Procedure/Test/Treatment
Error Types
Wrong Process/Treatment/Procedure
Severity
Suﬀering
Contributing Factors
Behavioral Factor
Communication Factor
Performance Factor

PS + NB
Precision
48.9

Recall
14.7

F
22.6

PS + SVM
Precision
55.6

Recall
7.0

F
12.5

CC + NB
Precision
41.9

Recall
44.6

F
43.2

CC + SVM
Precision
49.5

Recall
27.7

F
35.6

44.8
72.7
43.2

20.3
8.5
13.6

33.5
15.7
23.6

44.8
72.7
43.2

20.3
8.5
13.6

33.5
15.7
23.6

39.0
57.3
42.9

35.9
50.0
55.7

51.3
64.0
58.7

45.0
60.9
51.0

14.1
41.5
35.0

24.6
57.2
49.2

25.0

6.0

11.2

25.0

6.0

11.2

27.9

25.4

39.3

50.0

19.4

32.3

85.7

5.9

11.1

85.7

5.9

11.1

40.0

41.2

54.3

43.8

20.6

33.6

52.5
0
49.5

17.2
0
29.3

29.2
0
42.9

55.2
0
49.5

17.2
0
29.3

29.2
0
42.9

44.7
22.2
45.1

45.2
21.8
52.7

58.7
35.0
54.6

38.0
54.5
49.6

20.4
10.9
36.5

33.3
19.6
49.1

New Standard for Care, National Academies Press, 2004.
[3] A. Ruperto, J. Mannion, E. Flink, et al., Lessons learned from the evolution of
mandatory adverse event reporting systems, Adv. Patient Saf. 3 (2005) 135–152
doi:10.1.1.117.7766.
[4] W.J. Rudman, J.H. Bailey, C. Hope, et al., The impact of a web-based reporting
system on the collection of medication error occurrence data, Adv. Patient Saf. 3

References
[1] L.T. Kohn, J.M. Corrigan, M.S. Donaldson, To Err Is human: Building a Safer Health
System, National Academies Press, 2000.
[2] P. Aspden, J.M. Corrigan, J. Wolcott, et al., Reading: Patient Safety: Achieving a

7

International Journal of Medical Informatics 135 (2020) 104054

C. Liang, et al.

Inform. Decis. Mak. 17 (2017) 84.
[23] C. Liang, Y. Gong, Predicting harm scores from patient safety event reports, Studies
in Health Technology and Informatics, (2017), pp. 1075–1079, https://doi.org/10.
3233/978-1-61499-830-3-1075.
[24] C. Liang, Y. Gong, Automated classiﬁcation of multi-labeled patient safety reports: a
shift from quantity to quality measure, Stud. Health Technol. Inform. 245 (2017)
1070–1074, https://doi.org/10.3233/978-1-61499-830-3-1070.
[25] A.S. Malik, B.J. Cory, Multi-label classiﬁcation: an overview, Electr. Power Syst.
Res. 51 (1999) 123–130, https://doi.org/10.1016/S0378-7796(98)00143-6.
[26] J. Read, Scalable Multi-Label Classiﬁcation (Thesis) 1994 (2010), p. 200
doi:10289/4645.
[27] J.P. Pestian, C. Brew, P. Matykiewicz, et al., A shared task involving multi-label
classiﬁcation of clinical free text, Proceedings of the Workshop on BioNLP 2007
Biological, Translational, and Clinical Language Processing - BioNLP’ 07 (2007) 97,
https://doi.org/10.3115/1572392.1572411.
[28] W. Hersh, C. Buckley, T. Leone, et al., OHSUMED: an interactive retrieval evaluation and New large text collection for research, Proceedings of the ACM
International Conference on Research and Development in Information Retrieval
(SIGIR). (1994) 192–201.
[29] Jesse Read, Bernhard Pfahringer, Geoﬀ Holmes, EF, Classiﬁer chains for multi-label
classiﬁcation, Mach. Learn. 85 (2011) 333–359.
[30] J. Read, B. Pfahringer, G. Holmes, Multi-label classiﬁcation using ensembles of
pruned sets, Proceedings - IEEE International Conference on Data Mining, ICDM
(2008) 995–1000, https://doi.org/10.1109/ICDM.2008.74.
[31] G.H. John, P. Langley, Estimating continuous distributions in Bayesian classiﬁers,
Proceedings of the Eleventh Conference on Uncertainty in Artiﬁcial Intelligence
(2013) 338–345 doi:10.1.1.8.3257.
[32] C. Chang, C. Lin, T. Tieleman, LIBSVM : a library for support vector machines, ACM
Trans. Intell. Syst. Technol. 307 (2008) 1–39, https://doi.org/10.1145/1961189.
1961199.
[33] M.F. Porter, Snowball: a language for stemming algorithms, English. (2001) 1–15,
https://doi.org/10.1093/ije/dyv063.
[34] F. Report, Rainbow project. Stroke, (2006) (accessed 10 Feb 2016), http://www.cs.
cmu.edu/-mccallum/bow/rainbow/.
[35] G. Salton, C. Buckley, Term-weighting approaches in automatic text retrieval, Inf.
Process. Manage. 24 (1988) 513–523.
[36] N. Lee, H. Jang, Development of questionnaires to measure baccalaureate nursing
students’ patient safety competencies, NI 2012 2012 (2012) (2012) 1.
[37] N.J. Lee, J.Y. An, T.M. Song, et al., Psychometric evaluation of a patient safety
competency self-evaluation tool for nursing students, J. Nurs. Educ. 53 (2014)
550–562, https://doi.org/10.3928/01484834-20140922-01.
[38] A.L. Strauss, Qualitative Analysis for Social Scientists, Cambridge University Press,
1987, https://doi.org/10.1017/CBO9780511557842.
[39] N. Thompson-Moore, M.G. Liebl, Health care system vulnerabilities: understanding
the root causes of patient harm, Am. J. Health. Syst. Pharm. 69 (2012) 431–436.

(2005) 195–205.
[5] M.A. Davis, G.W. Rake, Implementation of a data-based medical event reporting
system in the U.S. Department of defense, Adv. Patient Saf. From Res. Implement 3
(Implement Issues) (2005).
[6] R. Desikan, M.J. Krauss, W.C. Dunagan, et al., Reporting of adverse drug events:
examination of a hospital incident reporting system, Adv. Patient Saf. From Res.
Implement 1 (2005) 145–160.
[7] C. Liang, Q. Miao, H. Kang, et al., Leveraging patient safety research: ﬁfteen-year
eﬀort since “to err is Human”, Stud. Health Technol. Inform. (2019).
[8] P.J. Pronovost, L.L. Morlock, J.B. Sexton, et al., Improving the value of patient
safety reporting systems Vol. 1 Advances in Patient Safety: New Directions and
Alternative Approaches, 2008, pp. 1–9. Assessment.
[9] J.T. Johns, A new, evidence-based estimate of patient harms, J. Patient Saf. 9
(2013) 122–128.
[10] M.A. Makary, M. Daniel, Medical–error the third leading cause of death in the US,
Bmj 353 (2016) i2139.
[11] D.R. Levinson, Adverse events in hospitals: national incidence among medicare
beneﬁciaries (OEI-06-09-00090; 11/10), Dep. Heal Hum. Serv. (2010) 34 doi:OEI06-09-00090.
[12] C.P. Landrigan, G.J. Parry, C.B. Bones, et al., Temporal trends in rates of patient
harm resulting from medical care, N. Engl. J. Med. 363 (2010) 2124–2134, https://
doi.org/10.1056/NEJMsa1004404.
[13] D.C. Classen, S.L. Pestotnik, R.S. Evans, et al., Computerized surveillance of adverse
drug events in hospital patients [published erratum appears in JAMA 1992 Apr
8;267(14):1922] [see comments], Jama 266 (1991) 2847–2851, https://doi.org/
10.1136/qshc.2002.002972/10.1136/qshc.2005.014522.
[14] M. Van Beuzekom, F. Boer, S. Akerboom, et al., Patient safety: latent risk factors, Br.
J. Anaesth. 105 (2010) 52–59, https://doi.org/10.1093/bja/aeq135.
[15] T.W. Nolan, System changes to improve patient safety, Bmj 320 (2000) 771–773,
https://doi.org/10.1136/bmj.320.7237.771.
[16] J. Reason, Human error: models and management, Bmj 320 (7237) (2000)
768–770, https://doi.org/10.1136/bmj.320.7237.768.
[17] S. Taylor-Adams, C. Vincent, Systems analysis of clinical incidents: the London
protocol, Clin. Risk 10 (2004) 211–220.
[18] C.A. Vincent, Analysis of clinical incidents: a window on the system not a search for
root causes, Qual Saf Heal Care 13 (2004) 242–243, https://doi.org/10.1136/qshc.
2004.010454.
[19] I.J.B. Young, S. Luz, N. Lone, A systematic review of Natural Language Processing
for classiﬁcation tasks in the ﬁeld of incident reporting and adverse event analysis,
Int. J. Med. Inform. (2019) 103971.
[20] J.F.E. Penz, A.B. Wilcox, J.F. Hurdle, Automated identiﬁcation of adverse events
related to central venous catheters, J. Biomed. Inform. 40 (2007) 174–182.
[21] Y. Luo, W.K. Thompson, T.M. Herr, et al., Natural language processing for EHRbased pharmacovigilance: a structured review, Drug Saf. 40 (2017) 1075–1089.
[22] Y. Wang, E. Coiera, W. Runciman, et al., Using multiclass classiﬁcation to automate
the identiﬁcation of patient safety incident reports by type and severity, BMC Med.

8

