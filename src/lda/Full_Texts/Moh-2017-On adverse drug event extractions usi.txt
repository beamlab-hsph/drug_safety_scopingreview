Netw Model Anal Health Inform Bioinforma (2017) 6:18
https://doi.org/10.1007/s13721-017-0159-4

ORIGINAL ARTICLE

On adverse drug event extractions using twitter sentiment
analysis
Melody Moh1

· Teng‑Sheng Moh1 · Yang Peng1 · Liang Wu1

Received: 13 February 2017 / Revised: 14 August 2017 / Accepted: 7 September 2017 / Published online: 18 September 2017
© Springer-Verlag GmbH Austria 2017

Abstract Extensive clinical trials are required before a
drug is placed on the market. It is, however, difficult to discover all the side effects, or adverse drug effects (ADE), for
any approved drugs due to the limited number of required
clinical trials before a drug is approved. The pervasive
online social networks, such as Twitter, can provide additional information on ADE. Concurrently, advancements in
social media technology have resulted in the booming of
massive public data; the availability of these huge datasets
offers numerous research opportunities for extracting ADEs.
Towards this purpose, in this paper two effective computation pipelines are proposed, which use drug-related classification and sentiment analysis to extract ADEs on Twitter.
The two pipelines are described in detail, and are implemented into automatic processes. Both pipelines are first
separately evaluated, and then compared in parallel. Based
on 25 days of Twitter data, the first pipeline has successfully
predicted 79.4% of drug-related tweets with user opinions.
The second pipeline, with its much simpler design, is able
to identify much more ADE, as well as discover more new
ADE. Based on 4 months of Twitter data collected, the second design is able to successfully capture 5 times more valid
ADE than the first design, with 12 times more new ADEs
discovered. We believe that these two proposed pipelines
are promising methods for extracting ADEs in social networks, and may be applied to additional areas such as food,

* Melody Moh
melody.moh@sjsu.edu
Teng‑Sheng Moh
teng.moh@sjsu.edu
1

Department of Computer Science, San Jose State University,
San Jose, CA, USA

beverages, and other daily consumer products for identifying
side effects and user opinions.
Keywords Adverse drug effects (ADEs) · Data mining ·
Machine learning · Nature language processing · Opinion
mining · Sentiment analysis

1 Introduction
Adverse drug events (ADEs) are injuries resulting from
drug-related medical events. Drugs can cure diseases and
save lives, yet, they may also cause different ADEs, and in
some serious cases, threaten people’s health. Many ADEs
are discovered during drug development. Pharmaceutical
companies, for example, traditionally rely on clinical trials
to establish the efficacy and side effects of drugs. However,
some side effects might not be revealed during this stage due
to the limited size of clinical trials. As a result, many ADEs
cannot be identified before market (Agency for Healthcare
Research and Quality 2001). ADEs are usually undesirable,
and sometimes even hurtful to patients. Severe ADE may
also lead to drug withdrawals from the market, resulting
in significant financial loss for pharmaceutical companies.
Hence, it is very important to monitor and predict ADEs.
ADEs can happen in any health care settings (U.S.
Department of Health and Human Services, Office of Disease Prevention and Health Promotion 2014). As discussed
above, many ADEs are found in post-marketing evaluation. The United States Food and Drug Administration
(FDA) monitors post-marketing of approved drugs. For
the post-marketing drug safety surveillance, FDA administers a database called the FDA Adverse Event Reporting System (FAERS). However, healthcare providers are
asked to limit reports to serious ADEs only. Patients can

13

Vol.:(0123456789)

18

Page 2 of 12

report undesired side effects to their healthcare provider
or directly to the FDA. However, many side effects might
remain unreported by these established means, yet they
often appear in social media postings.
The explosion of social media websites, such as Twitter, Facebook, and Google Circle, provides consumers
with an accessible vehicle to share their experiences with
drugs that they would not report to their healthcare provider or to the FDA. Furthermore, the advancement in
social network technology has resulted in the availability
of massive public datasets. In January 2016, for example,
there were about 303 million tweets published per day
on the popular micro-blogging platform Twitter (Edwards
2016). These datasets have offered research opportunities
for discovering ADEs (Bian et al. 2012; Wu et al. 2015;
Yu et al. 2016).
Accurate decision rules are needed to capture the actual
reactions of drug users, i.e. whether its writer’s own, firsthand experience or someone else’s second-hand experience,
and whether its an actual experience or opinion about the
drug (Jiang and Zheng 2013). Sentiment classification is a
binary classification task in machine learning, where linguistic and other context-related features are extracted from
texts and mapped to one of two classes (Go et al. 2009;
Barbosa and Feng 2010; Jiang et al. 2011; Liu et al. 2012;
Bravo-Marquez et al. 2013; Gonçalves et al. 2013; Torunoglu et al. 2013). Semi-supervised learning is a commonly
used method in sentiment analysis. It usually applies unsupervised learning sentiment analysis tools to extract the
polarity, emotion, sentiment strength and other features.
These features then become the dimensions in the supervised learning method. Several recent studies suggested
that hybrid and ensemble approaches that combine different sentiment analysis methods outperform methods using
a single sentiment analysis method (Bravo-Marquez et al.
2013; Gonçalves et al. 2013; Mohammad et al. 2013; Araújo
et al. 2014).
The paper consists of preliminary works from two published conference papers (Wu et al. 2015; Peng et al. 2016),
with the objective of introducing effective methods for
extracting ADEs from Twitter. In particular, two pipelines
have been proposed (referring to Figs. 1 and 2 in Sect. 3
and Fig. 3 in Sect. 4). The main contributions of the paper
include the following:
1. Proposed two architectures to provide simple, efficient
pipelines for retrieving ADEs from Twitter.
2. Implemented the two pipelines into automatic processes.
3. In the first proposed pipeline, sentimental analysis,
natural language processing (NLP), and machine learning are applied for predicting ADEs. Based on 25 days
of Twitter streams, it has achieved a precision rate of
79.4% on predicting drug-related tweets. Furthermore,

13

Netw Model Anal Health Inform Bioinforma (2017) 6:18

Fig. 1  Proposed pipeline 1 (original view)

Fig. 2  Pipeline 1 (simple view)

26 predicted tweets are manually examined, and 16 relevant side effects are confirmed.
4. The second proposed pipeline architecture has successfully extracted 1239 total ADEs, among them 22% are
new, based on 4 months of Twitter streams.
5. The second proposed pipeline has extracted 5 times of
total ADEs and 12 times of new ADEs, comparing with
those from the first pipeline one.

Page 3 of 12 18

Netw Model Anal Health Inform Bioinforma (2017) 6:18

2.1 Data preprocessing
Data preprocessing (also called data cleaning) is necessary
before classification and sentiment analysis can be carried out effectively. Many different tools and methods have
been used to perform data preprocessing. There are several approaches to simplify the format of texts, including
python natural language toolkit (NLTK) (NLTK Project
2015), Hive (The Apache Software Foundation 2014), and
R (The R Foundation 2015). In particular, NLTK has been
used to access raw data, deal with HTML tags, and process
texts using regular expressions. It also performs tokenization, stemming, and calculating text similarity. NLTK is
used in our project for data preprocessing.
Yu et al. (2016) performed data preprocessing using text
similarity to reduce the size of the dataset. More precisely,
by calculating text similarity, identical tweets and high
similarity tweets are eliminated, thus making the dataset
more meaningful. This approach is adopted in this work.
Bao et al. (2014) compared the performance of different data preprocessing approaches. The work explored the
impact preprocessing methods made on twitter sentiment
classification. The effects of URLs, negation, repeated letters, stemming, and lemmatization were evaluated.
2.2 Drug‑related classification
Fig. 3  Proposed Pipeline 2

The paper is organized as follows: Sect. 2 describes background and related study. Section 3 describes the first proposed pipeline and its experimental results, while Sect. 4,
follows the organization of Sect. 3 and presents the design
and experiment results of the second proposed pipeline.
Section 5 compares these two proposed designs and their
experimental results. Finally, Sect. 6 concludes the paper
with future remarks.

2 Background and related work
Extracting ADEs from the social media such as Twitter has
recently attracted research attentions (Bian et al. 2012; Wu
et al. 2015; Yu et al. 2016; Peng et al. 2016). In the following, background and main related work are presented.

Go et al. (2009) used emoticons for training data to automatically generate a large size of training dataset. By performing distant supervised learning, the results showed
that machine learning classifiers such as Naïve Bayes and
Support Vector Machine (SVM) have achieved higher
accuracy than other methods. Naïve Bayes and SVM are
adopted in this work.
Bian et al. (2012) built a classifier to identify drug
users. They extracted two group features: text features
(including the number of occurrences of drug names, pronouns, URLs, and negation words); and semantic features
(using concept unique identifiers) that were discovered by
MetaMap (Aronson 2001).
MetaMap is a highly configurable program developed
by Aronson (2001) at the National Library of Medicine. It
maps biomedical text to the UMLS (Unified Medical Language System) Metathesaurus or, equivalently, to discover
Metathesaurus concepts referred to in the text. MetaMap
uses a knowledge-intensive approach based on symbolic,
natural language processing (NLP), and computational linguistic techniques. MetaMap has been used in this work.
Jiang and Zheng (2013) applied a supervised machine
learning classifier to classify user experience tweets when
mining tweets for potential drug effects. In this work, we
used both drug-related classification and user experience

13

18

Page 4 of 12

Netw Model Anal Health Inform Bioinforma (2017) 6:18

classification in this step, with Natural Language Toolkit
(NLTK) (NLTK Project 2015) to extract pronouns and
sentiment.
2.3 Sentiment analysis
Torunoglu et al. (2013) applied Wikipedia-based semantic
smoothing approach. They applied Laplace Smoothing,
and found that analyzing sparsity improved the smoothing result. Furthermore, Naïve Bayes method performed
better than SVM in this application.
Note that, while sentiment analysis can be used to
identify the polarity of texts, cause–effect classification
has been used to find out why people take drugs or why
these effects happen (Yu et al. 2016). In particular, Yu
et al. (2016) used supervised machine learning methods
to identify cause–effect relationship in tweets that contain
drug names, and from that to extract drug effects. This
method, however, failed to catch many ADE tweets that
do not explicitly exhibit a cause–effect relationship.
2.4 ADE extraction
MetaMap (Aronson 2001) is used to extract ADEs. It can
map a (biomedical) text to a score to indicate the quantity
of mapping to UMLS metatheraurus. The higher the score,
the better the mapping of the tweet is to drug effects. At the
end, the related drug events that extracted from dataset are
compared with known drug events; the drug-event sources
are from the Medline Plus Drug Information (U.S. National
Library of Medicine 2015) and the health-specific social networking website (PatientsLikeMe 2015). The same approach
has been adopted in this work.

3.1 Proposed method: pipeline 1
The original proposed pipeline for extracting ADRs from
tweets is shown in Fig. 1. It consists of the following five
general steps: (1) capturing of real-time tweets, (2) preprocessing, (3) identifying drug-related and user experience
tweets, (4) sentimental analysis, and (5) extracting adverse
drug effects (ADE).
Figure 2 shows the block diagram of the simplified
view of Pipeline 1. Note that Step 3 consists of three substeps, while Step 4 has two sub-steps. These five steps are
described in the following five subsections:
3.1.1 Capturing real‑time tweets
Twitter provides streaming API to allow the users to retrieve
real-time data. Tweepy (2015), an easy-to-use Python library
for accessing the Twitter API, was used to crawl real-time
tweets. Before retrieving tweets, the drug names need to
be determined as the keywords in tracking. Two rules were
used. First, drugs should have been on the market for a number of years, so that sufficient tweets would exist for reporting their effects. Second, patients whose conditions kept
them from posting tweets regularly should not take these
drugs. As a use case for this work, five drugs were chosen
(Table 1).
The tweets in JSON format were stored in a database
(MongoDB), and PyMongo (MongoDB, Inc. 2015a, b)
was used to access the database. MongoDB natively supports JSON format, so the crawled tweets did not need to
be reformatted. Unlike SQL databases for which a table’s
schema has to be determined and declared before inserting data, MongoDB’s collections do not enforce document
structure (MongoDB, Inc. 2015a, b), thus, making it easy
to insert data.
3.1.2 Data preprocessing

3 Proposed architecture one
In this section, the first proposed architecture is presented
in detail, followed by its implementation description
and performance evaluation. Note that part of the work
described in this section was presented (Wu et al. 2015).
Table 1  Drugs used as use
cases

13

Twitter is a micro-text social networking site. A tweet usually contains Uniform Resource Locators (URLs), hashtags,
emoticons, misspelled words, Internet slang, and incorrect
grammar expressions. Python’s built-in regular expressions
were used to process the text. All non-English tweets and
retweets (tweets forwarded or reposted by another user)

#

Drug name

Brand Names

Prescribed for

Approval

1
2
3
4
5

Duloxetine
Gabapentin
Baclofen
Glatiramer
Pregabalin

Cymbalta, Duloxetine Hydrochloride
Gabapentin, Gralise, Horizant, Neurontin
Baclofen, Gablofen, Kemstro, Lioresal,
Copolymer 1, Cop-1, Copaxone
Pregabalin, Lyrica

Depression
Epilepsy Seizure
Muscle Spasms
Multiple Sclerosis
Neuropathic pain

2004
1993
1977
1996
2004

Page 5 of 12 18

Netw Model Anal Health Inform Bioinforma (2017) 6:18

were removed. Additionally, tweets that contained “ebook”
in the hashtag were removed. As some spam or advertisement accounts often link to medical documents, they usually
included “ebook” in the hashtag. Besides that, the following
measures were taken to de-noise the tweets:

3.1.4 Sentimental analysis with user‑experience tweets

Next, tokenization, stemming and part-of-speech (POS)
extraction were performed. Tokenization means breaking the
sentence into words. POS is extraction of lexical items that
have similar grammatical properties. Stemming refers to the
process for reducing inflected words to their root forms. For
example, “eating”, “ate”, “eaten” and “eats” can be stemmed
into “eat”. TextBlob (Loria 2015), a Python library for processing textual data, was used to perform these tasks.

This step includes two sub-steps: (a) subjectivity classification and (b) polarity classification-based sentimental analysis. Note that textual features were number of URLs in a
tweet, number of mentions (“@” symbol), and number of
pronouns. Syntactic features refer to question and negation
words. Finally, sentimental features were sentiment scores
computed for contrast and causal conjunction words, as well
as sentiment scores for nouns, verbs, adverbs, and adjectives near drug names. The sentiment scores were computed
using several sentiment lexicons, such as Bing Liu sentiment words (Hu and Liu 2004), Multi-Perspective Question Answering (MPQA) (Wiebe et al. 2005), SentiWordNet
(Sebastiani et al. 2010), and AFINN (Hansen et al. 2011).
Several classification algorithms available in the Weka
package (Witten et al. 2016) were tested. F-measure score
was used to identify the best performing classification algorithm and the combination of features.

3.1.3 Drug‑related classification

3.1.5 Extracting adverse drug events

This step includes three sub-steps: (a) rule-based NLP-combined classification, (b) drug-related classification, and (c)
user experience classification. Sub-step (a) uses the Natural
Language Toolkit (NLTK) (NLTK Project 2015). In addition, drug names are applied as key words to capture tweets
that are specific drug-related, while at the same time removing all the unrelated tweets. In particular, using drug names
as the “features set,” two popular supervised machine learning classifiers, Naïve Bayes and Support Vector Machine
(SVM), are applied for feature selection, thus perform drugrelated classification.
Not all the tweets mentioning drugs as keywords signal
ADRs. Tweets that describe the experiences and reactions to
the medications by the authors are the ones that are relevant
in this step. These tweets are called “user experience” tweets
(Table 2) (Jiang and Zheng 2013).
Several features, such as textual, syntactic, and sentimental, were used to build a classifier for drug-related and for
user experience tweets. The best combination of features
was determined by an automated feature selection procedure
implemented in the Weka software (Witten et al. 2016).

MetaMap mapping (Aronson 2001) was applied to extract
the ADEs. As discussed in Sect. 2, MetaMap maps biomedical text to the UMLS Metathesaurus, equivalently to discover Metathesaurus concepts referred to in the text. It is
an NLP tool for mapping Metathesaurus concepts to extract
Adverse Drug Events. At the time of writing, there were 133
semantic types in 15 semantic groups. MetaMap also computed a score from 0 to 1000 to indicate the confidence of
mapping: the scores for a perfect and inappropriate mapping
was 1000 and 0, respectively. A threshold for classification
was set to 850.
The tweets outputted by the pipeline were manually
examined and compared with the reported ADRs from two
sources: National Library of Medicine MedLine Plus Drug
Information site (U.S. National Library of Medicine 2015)
and social networking site (PatientsLikeMe 2015).

• Duplicate tweets were removed.
• Usernames and hashtags were replaced with a space.
• Extra newline (\n) and punctuation characters (except for

“!” and “?”) were removed.

Table 2  Examples of user
experience tweets

3.2 Experiment results and performance evaluation
In this subsection, we present the experimental results of the
computational pipeline 1. They are shown in Figs. 1 and 2.

Tweets

Drug

Effects

Watch the weight gain with pregabalin
Lyrica made me feel like my throat was swelling and I could not breathe
Another sleepless night due to duloxetine withdrawal and no clopixol as
promised to me BPD

Pregabalin
Lyrica
Duloxetine

Weight gain
Throat swelling
Sleeplessness

13

18

Page 6 of 12

Netw Model Anal Health Inform Bioinforma (2017) 6:18

3.2.1 Tools used in pipeline 1

Table 4  Details of labeled data for test case

This section briefly describes the tools used in the pipeline. In Step 1, Hive is used to extract, transform and
load data. After data is loaded into Hive, then tweets are
extracted using HiveQL sentences. All the tweets are then
merged into a file, which is then exported to the Step 2, data
preprocessing.
In Step 2, natural language toolkits and regex of Python
are used for data preprocessing. NLTKs are used to do text
preprocessing for sentiment analysis, spam filtering, plagiarism detection, document similarity calculation, phrase
extraction, text search and keyword frequency analysis.
NLTK provides some features such as word tokenization,
POS tagging, named entity recognition, text classification,
and many that also include corpora. MetaMap (Aronson
2001) described in Sect. 2 is also used here.
In Steps 3 and 4, drug-related classification and sentiment
analysis, Weka (Witten et al. 2016) is used. Weka is a data
mining software in Java; it contains a collection of machine
learning classifiers used to perform classification. As a powerful machine learning software, Weka contains functions
such as data visualization, attribute selection, classification,
prediction, and model evaluation.
3.2.2 Capturing tweets from twitter
Tweets had been continuously retrieved using either drug
names or their brand names (shown in Table 1) as tracking
keywords, in a period of 25 days (from January 29, 2015 to
February 22, 2015). A total of 8703 tweets were collected
for the use-case.
3.2.3 Data preprocessing
After 8703 tweets were collected for the use-case, tweets
were preprocessed and sentiment scores and MetaMap mappings were calculated. Data preprocessing was performed
sequentially, thus, reducing the size of the retrieved tweets
from 8703 to 3251; as shown in Table 3.
3.2.4 Drug‑related classification
To study the performance of classifiers, a test dataset was
constructed by manually labeling 486 tweets; shown in

Table 3  Data processing
outcome

Number
of tweets
Raw data
After data preprocessing

8703
3251

Category
Drug-related with
user experience
reported
Drug-related without
user experience
reported
Drug-unrelated

Positive
Neutral
Negative

Total amount

52
34
51

137

183
166

Table 4. Among these tweets, 137 tweets reported user experience, 183 tweets were not related to user experiences but
mentioned drug names, and 166 tweets were drug-unrelated.
The 137 user experience tweets were further subdivided into
34 neutral, 51 negative and 52 positive tweets.
To analyze the performance of the tweet classification,
we used the F-measure score in a tenfold cross-validation
of the manually labeled test dataset. In the cross-validation,
the test dataset was balanced by randomly picking the same
number of positive and negative tweets.
3.2.5 Sentiment analysis
The best performing classifier utilized subjectivity sentiments as features, such as number of negations, question
mark as well as scores computed with sentiment analysis
tools (Table 5). Note that F-measure is used to represent
accuracy. F-measure equals to 2 * Precision * Recall/(Precision + Recall). Precision is defined as the fraction of elements correctly classified as positive out of all the elements
the algorithm classified as positive, whereas Recall is the

Table 5  F-measure score of tenfold cross-validation of subjectivity
classification
Features

SVM

Naïve bayes

f1 + f2
0.658
0.658
f1 + f2 + f3
0.676
0.661
f1 + f2 + f4
0.675
0.704
f1 + f2 + f5
0.734
0.676
f1 + f2 + f6
0.632
0.676
f1 + f2 + f4 + f5
0.765
0.72
f1 + f2 + f5 + f6
0.779
0.691
f1 + f2 + f4 + f5 + f6
0.794
0.706
f5 + f6
0.571
0.644
f2 + f5 + f6
0.691
0.661
f1 + f5 + f6
0.588
0.644
f1 + f2 + f3 + f4 + f5 + f6
0.691
0.66
f1: Number of negations, f2: Question mark, f3: Bing Liu score,
f4: SentiWordNet score, f5: MPQA score, f6: AFINN score
Bold value indicates the best result

13

Amount

Page 7 of 12 18

Netw Model Anal Health Inform Bioinforma (2017) 6:18

fraction of elements correctly classified as positive out of all
the positive elements. The classifier was built using Support
Vector Machine (SVM) algorithm and achieved an F-measure score of 0.794.
3.2.6 Adverse drug event extraction
Of the 3,251 pre-processed tweets, 345 were classified as
potential signals of ADRs for the use case drugs. Interestingly, two drugs, pregabalin and gabapentin occurred in
tweets more frequently than other drugs (Table 6). Both
drugs are associated with treatment of pain, although for
different indications. No tweet contained the glatiramer, a
drug used to treat multiple sclerosis.
We also manually examined a subset of 26 tweets classified as signals of ADRs and confirmed 16 predicted side
effects; detailed results of these 26 tweet classifications were
reported in an earlier conference paper (Wu et al. 2015). Our
analyses showed that these tweets could indeed be mapped
to potential ADRs. Thus, the results showed that useful
information could be extracted from tweets by sentiment
analysis.

4 Proposed architecture two
In this section, the second proposed pipeline (Fig. 3) is
described in detail, followed by its experiments and results.
The section is organized similar to Sect. 3. Note that, part
of the work described in this section was presented (Peng
et al. 2016).
4.1 Proposed method
The proposed five-step pipeline is shown in Fig. 3. The subsequent subsections describe each of the five steps; organized the same way as Sect. 3.1.
4.1.1 Capturing tweets from twitter
As in Pipeline 1 (Sect. 3, Figs. 1 and 2), Tweepy (2015) was
used to stream data from Twitter. Tweepy is for accessing the
Twitter API. Note that, Twitter does not allow users to freely

Table 6  Distribution of rulebased NLP method extracted
tweets

Drug name

Number

pregabalin
baclofen
duloxetine
gabapentin
glatiramer

114
23
94
114
0

access data older than 2 weeks. To stream a large amount of
data we spent 4 months to collect data from Twitter.
Selecting proper drugs is critical in analyzing ADEs. A
good rule has been followed by existing works (Jiang and
Zheng 2013; Yu et al. 2016): Any selected drug should
have been in the market for more than 10 years. Following
this rule, the same five drugs that appeared in Sect. 3 were
selected for evaluating Pipeline 2; all of them have existed
for more than 10 years.
4.1.2 Data cleaning
As in Pipeline 1, data preprocessing is needed before classifications are carried out, first using regular expressing to
process the tweets, followed by tokenization, POS process,
and stemming. Furthermore, using text similarity method,
duplications and spams are filtered out (Python Software
Foundation 2013; Yu et al. 2016). Since Twitter offers the retweet function, users very often re-tweet other users’ tweets.
In this case, many retweets are almost identical to each other.
In addition, many drug companies or spam users repeatedly
post advertisements of the same drug. Levenshtein distance
(Python Software Foundation 2013) is used to calculate
the text similarity. A similarity threshold of 90% is used to
determine whether two tweets are similar. This threshold is
determined through experiments that use threshold values
ranging from 30 to 95%.
4.1.3 Drug‑related classification
As in Pipeline 1, the Natural Language Toolkit (NLTK)
(NLTK Project 2015) is used; Naïve Bayes and Support Vector Machine (SVM), are applied for feature selection. Note
that, to extract drug-related tweets, in Pipeline 1 we applied
user experience classification following feature selections.
In some later experiments we found that this extra classification is unnecessary as it significantly reduces the resulting dataset size (refer to Sect. 5). Furthermore, negative (a
user-experience) tweets would be extracted in the sentiment
analysis (Step 4 – to be described next).
4.1.4 Sentiment Analysis
ADEs will contain negative opinion of users, tweets that
express negative feelings are extracted in this step. In particular, polarity classification is applied to decide if a tweet
is positive or negative. Naïve Bayes and SVM classifier
are built to perform the sentiment analysis. This step also
includes the following:
Negation detection This is very important for text sentiment analysis, as a negative word can totally change the
sentiment. For example, “This drug makes me headache”
and “This drug doesn’t make me headache” have completely

13

18

Page 8 of 12

Netw Model Anal Health Inform Bioinforma (2017) 6:18

different meaning. Negation words such as “no”, “not”,
“don’t”, “none”, and “none of” are considered. The total
number of negation words is also counted. The result of
negation detection will be presented as numeric attribute in
our feature set and it can be 0, odd or even numbers.
Contrast and causal conjunction word detection These
words and their sentiment scores are also noted. For
example, “The Vitamin C helps my canker sore, but it
will attack my stomach acid.” The meaning and sentiment
of this sentence is changed by the conjunction word “but”
which shows how detecting contrast and causal conjunction words are useful.
Question detection It detects if a tweet contains a question. The question mark “?” will be identified during the
process, as well as those tweets with “Wh”. If one of these
cases is matched, the text will be labeled as a question
sentence. People sometimes post ADEs as questions to ask
if others experience the same ADE so detecting questions
is useful as well.

4.2.1 Tools used in pipeline 2

4.1.5 ADEs extraction

4.2.4 Drug‑related classification

MetaMap mapping is again applied to extract the ADEs.
Furthermore, in Pipeline 2, DISO group in MetaMap
semantic types and groups (MetaMap 2015) is used to
calculate the mapping score. DISO is the abbreviation of
Disorders (MetaMap 2013), which contains injury, poisoning, mental or behavioral dysfunction, cell or molecular
dysfunction, neoplastic process groups, etc.
After extracting ADEs, verification of valid ADEs is
necessary. This is done by comparing the newly extracted
ADEs with the validated drug event collection from
MedLine Plus Drug Information website (U.S. National
Library of Medicine 2015) and from the health-specific
social networking website (PatientsLikeMe 2015).

For classification purpose, data needs to be labeled for training a classifier. 3740 tweets are manually labeled; among
them 1870 are drug-related and another 1870 are not drugrelated, they together are used as the training dataset. Note
that, to balance the result, the same number of two categories of tweets is selected. Among the 1870 drug-related
tweets, 695 positive and 594 negative tweets are selected.
Table 8 shows the details of these labeled data.
tenfold cross-validation is then used to obtain the classification result, shown in Table 9. F-measure is again
used to represent accuracy. It is clear that SVM classifier

The tools used are similar to those in Pipeline 1, as described
in Sect. 3.2.1. They include Hive, NLTK, MetaMap, Weka,
etc.
4.2.2 Capturing Tweets from Twitter
Tweets had been retrieved using the five drug names (shown
in Table 1), as keywords or features. Tweets have been collected during the 4-month period between September 1st
2015 and January 1st 2016, with a total of 15241 tweets
retrieved; as shown in Table 7. The total data size is about
2 GB.
4.2.3 Data preprocessing
After data preprocessing, as described above, a total 5839
tweets are left; as shown in Table 7. These tweets are cleaned
data that can be used in the next step.

Table 8  Details of labeled data

4.2 Experiments and results

Category

Amount

Total amount

This subsection follows the organization of Sect. 3.2. The
tools used in the proposed five-step pipeline are first discussed. The subsequent subsections then present results
obtained from each of the five steps.

Drug-related
Positive
Neutral
Negative
Drug-unrelated

695

1870

Table 7  Data processing
outcome

13

Number of tweets
Raw data
After data
preprocessing

15,241
5839

Table 9  Drug-related
classification with tenfold crossvalidation

581
594

1870

Classifier

Accuracy
(F-measure)

SVM
Naïve bayes

0.869
0.808

Page 9 of 12 18

Netw Model Anal Health Inform Bioinforma (2017) 6:18

obtains a better accuracy and recall here This is mainly
because that Naïve Bayes assumes that all the attributes
are independent, which is usually an unreasonable assumption in practice.
4.2.5 Sentiment analysis

Table 11  ADE extraction results
Drug name

Total ADEs

New ADEs

New ADE %

Pregabalin
Baclofen
Duloxetine
Gabapentin
Glatiramer
Overall total

376
198
327
302
36
1239

71
34
65
96
3
269

19
17
20
32
8
22

In the sentiment classification, the input dataset is the output data from the last step. Note that 695 positive, 594
negative, and 581 neutral tweets, as shown in Table 10,
are used as training dataset in step part. As in the last step,
tenfold cross-validation is also used to obtain the classification result, shown in Table 10. One more time we see
that SVM has obtained slightly better accuracy than Naïve
Bayes. Comparing with Table 5 (the corresponding result
of Pipeline 1), the accuracy of Pipeline 2 is lower than that
of Pipeline 1. This will be investigated further in Sect. 5.

ADEs

Incorrectly identified as ADEs

False positive rate

1239

302

19.6%

4.2.6 Adverse drug event extraction

In this section, the two proposed pipelines are compared
and contrasted. First, the two systems are compared qualitatively, followed by an illustration of the experiment and
results from comparing the two pipelines.

The ADE extraction is based on the initial 1870 drugrelated tweets (shown in Table 8). For each of the five
drugs, ADEs are extracted and DISO mapping score is
used to determine a valid ADE. Each valid ADE is then
compared with validated drug event collection from
MedLine Plus Drug Information website (U.S. National
Library of Medicine 2015) and from the health-specific
social networking website (PatientsLikeMe 2015) to determine if it is an existing ADE or a new ADE.
The results are shown in Table 11. It is clear that the
proposed simple pipeline is able to extract a large number
(three digits) of ADEs, especially for the top four drugs.
Observed that a substantial amount of new ADEs have also
been identified, which is at approximately 22% of the total
ADEs captured (Table 12).
We also note that, while our proposed pipeline is able to
detect 1239 ADE, much more than that of the first pipeline,
to be discussed in the following subsection (Table 16), the
false positive rate remains low, as shown below. Note that,
false positive rate in this case is the percentage of incorrectly identified ADEs. Therefore, it is calculated as 302/
(1239 + 302) = 0.196.

Table 10  Sentiment
classifications with tenfold
cross-validation

Classifier

Accuracy
(F-measure)

SVM
Naïve Bayes

0.631
0.606

Table 12  False positive rate

5 Comparison of the two architectures

5.1 Qualitative comparison
For drug-related classification, the first pipeline used three
different classifications: rule-based NLP-combined classification, drug-related classification, and user experience
classification. As a result, its output of this step, drug-related
dataset, has a very small size. The second pipeline, on the
other hand, used only drug-related classification and has
resulted in a significantly larger drug-related dataset, allowing us to identify much more ADEs.
For sentimental analysis, the first pipeline performed both
subjectivity classification and polarity classification-based
sentiment analysis for this step, using Naïve Bayes and SVM
classifiers. Through later experiments we found that subjectivity classification filters out too many valid ADE tweets,
therefore, in the second pipeline only polarity classificationbased sentiment analysis is used.
Table 13 shows the comparison of the two pipelines. The
main differences are in Steps 3 and 4. For Step 3, drugrelated classification, the first pipeline uses three different
classifications whereas the proposed pipeline uses only one.
Then, for Step 4 sentiment analysis, the first pipeline uses
two classifications comparing with the proposed pipeline
using only one. The simplification has allowed the second
pipeline to extract much more ADE.
Table 13 also shows the pros and cons of the two pipelines. While Pipeline 1 achieves more accurate prediction
on drug-related data due to its complex pipeline, it captures
far less drug-related tweets. Pipeline 2, on the other hand,

13

18

Page 10 of 12

Netw Model Anal Health Inform Bioinforma (2017) 6:18

Table 13  Summary of two
pipelines

Step

Pipeline 1

Pipeline 2

1
2

Capturing real-time tweets from Twitter
Data preprocessing

3

a. Data preprocessing
b. Tweet similarity calculation
Drug-related classification

a. Rule-based NLP-combined classification
b. Drug-related classification
c. User experience classifications
4
a. Subjectivity classification
Polarity classification-based sentiment analysis
b. Polarity classification-based sentiment analysis
5
ADEs extraction using MetaMap and DISO group
Pros Accurate prediction on drug-related data
a. Much simpler pipeline
b. Able to extract a large amount of ADE
Cons a. More complicated pipeline
Slightly lower precision of drug-related and
b. Extracting only a very limited amount of ADE
sentiment analysis predictions

Table 14  Drug-related
classification result summary

Classifier

Drug-related Classification

Table 15  Sentiment analysis result summary
Classifier

Accuracy (F-measure)
Pipeline 2 Pipeline 1 Ratio (%)

Sentiment classification

SVM
0.631
Naïve bayes 0.606

0.656
0.624

96
97

SVM
Naïve Bayes

Accuracy (F-measure)
Pipeline 2

Pipeline 1

Ratio (%)

0.869
0.808

0.911
0.843

95
96

represents a far simpler design, and as a result, is able to
correctly predict much more drug-related tweets (average
of 5 times more, as shown in Table 16); the price to pay
is a slightly lower precision in drug-related classification
(4–5% lower, as shown in Table 14) and in sentiment analysis (3–4% lower, as shown in Table 15).
5.2 Exprimental result comparison

Table 16  ADEs extraction result comparison
Pipeline 2
Pregabalin
Total ADEs
New ADEs
Baclofen
Total ADEs
New ADEs
Duloxetin
Total ADEs
New ADEs
Gabapentin
Total ADEs
New ADEs
Glatiramer
Total ADEs
New ADEs
Overall total
Total ADEs
New ADEs

13

Pipeline 1

Ratio (%)

376
71

49
4

767
1775

198
34

12
3

1650
1133

327
65

45
4

726
1625

302
96

130
10

230
960

36
3

0
0

1239
269

236
21

Infinity
Infinity
525
1281

In this subsection, using the same raw data (shown in
Table 7), the results of both pipelines are presented. Table 14
summarizes the outcomes of Step 3, drug-related classification. Using three different classifications, the first pipeline
has achieved slightly better accuracy in identifying drugrelated tweets. Yet, using only one classifier, the second
pipeline has obtained an accuracy that is at 95% or more of
the first algorithm.
Table 15 compares the results of Step 4, sentiment analysis. Note that, the first pipeline used two classifiers whereas
the second pipeline used only one in this step. It is clear
that by simplifying the step, the second pipeline is able to
achieve accuracy results that are very close, at 96% or more
of the first method.
Finally, Table 16 compares the final outcome of two pipelines; i.e., the number of valid ADEs extracted. By simplifying the overall scheme, especially Steps 3 and 4, the second
pipeline is able to extract a large dataset that contains ADE
tweets. It has successfully extracted much more ADEs, an
overall of 525% total ADEs and 1281% new ADEs compared with those obtained by the first pipeline.

Netw Model Anal Health Inform Bioinforma (2017) 6:18

6 Conclusion
In the United States, monitoring of adverse drug reactions
is part of the mission of the government regulatory agency,
the FDA. The current reporting mechanism relies on submissions by the healthcare professionals and self-reporting
by the consumers. In this work, we hypothesized that social
media networks, such as Twitter, could be used to extract
ADRs in a complementary fashion, by identifying tweets
related to drugs and their side effects. Two computational
pipelines have been proposed to help identifying tweets
about drugs and user experiences with drugs. The first pipeline relies on the sentiment analysis as well as several other
textual, syntactic and semantic features. It has achieved high
accuracy in sentiment analysis for predicting drug-related
tweets with user opinions. With the goal of extracting more
ADEs, the second, more efficient pipeline has been designed.
It has enhanced data preprocessing while greatly simplified
the classification steps. As a result, an average of 5 times
of ADEs have been successfully extracted comparing with
first pipeline. Future work may include using more drugs as
keywords in the experiments, applying Apache Spark (The
Apache Software Foundation 2016) for processing large
amounts of Tweets (Hsu et al. 2017). In addition, a promising work would be to involve pharmaceutical experts to help
labeling tweets, so as to obtain more accurately labeled data
and to correctly identify new ADEs.
Acknowledgement The authors would like to thank Dr. Natasha
Khuri for helpful suggestions in the early stage of this work. This work
was supported in part by SJSU RSCA and by research Grants from
Nokia and from Datiphy, Inc.

References
Agency for Healthcare Research and Quality (2001) Reducing and preventing adverse drug events to decrease hospital costs: Research
in Action, Issue 1, March 2001. http://archive.ahrq.gov/research/
findings/factsheets/errors-safety/aderia/ade.html. Accessed 21
Mar 2015
Araújo M, Gonçalves P, Cha M, Benevenuto F (2014) iFeel: a system
that compares and combines sentiment analysis methods. Proceedings of the 23rd International Conference on World Wide Web,
Seoul, Korea, April 2014, pp 75–78
Aronson A. R. (2001) Effective mapping of biomedical text to the
UMLS Metathesaurus: the MetaMap program. Proceedings of
the AMIA Symposium, pp 17–21
Bao Y, Quan C, Wang L, Ren F (2014) The role of pre-processing in
Twitter sentiment analysis. In: Huang D-S, Jo K-H, Wang L (eds)
Intelligent computing methodologies. Springer International Publishing, Switzerland, pp 615–634
Barbosa L, Feng J (2010) Robust sentiment detection on twitter from
biased and noisy data. Proceedings of the 23rd International Conference on Computational Linguistics, Beijing, China, August
2010, pp 36–44

Page 11 of 12 18
Bian J, Topaloglu U, Yu F (2012) Towards large-scale twitter mining
for drug-related adverse events. Proc. of the 2012 ACM International Workshop on Smart Health and Wellbeing, Maui, HI,
October 2012, pp 25–32
Bravo-Marquez F, Mendoza M, Poblete B (2013) Combining strengths,
emotions and polarities for boosting Twitter sentiment analysis.
Proceedings of the Second International Workshop on Issues of
Sentiment Discovery and Opinion Mining, Chicago, IL, August
2013
Edwards J (2016) Leaked Twitter API data shows the number of tweets
is in serious decline. Business Insider. Twitter Usage Statistics.
http://www.businessinsider.com/tweets-on-twitter-is-in-seriousdecline-2016-2. Accessed 2 Feb 2016
Go A, Bhayani R, Huang L (2009) Twitter sentiment classification
using distant supervision, CS224 N Project Report, Stanford
University
Gonçalves P, Araújo M, Benevenuto F, Cha M (2013) Comparing and
combining sentiment analysis methods. Proceedings of the first
ACM conference on Online social networks, Boston, MA, October
2013, pp 27–38
Hansen LK, Arvidsson A, Nielsen FA, Colleoni E, Etter M (2011)
Good friends, bad news-affect and virality in twitter. In: Park JJ,
Yang LT, Lee C (eds) Future information technology. Springer,
Berlin, pp 34–43
Hsu D, Moh M, Moh T-S (2017) Mining frequency of drug side effects
over a large Twitter dataset using Apache Spark. Proceedings of
the 9th IEEE/ACM Int. Conf. on Advances in Social Networks
Analysis and Mining (ASONAM), Sidney, Australia, July 2017
Hu M, Liu B (2004) Mining and summarizing customer reviews. Proceedings of the tenth ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, Seattle, WA, August
2004, pp 168–177
Jiang K, Zheng Y (2013) Mining Twitter data for potential drug effects.
In: Motoda H et al (eds) Advanced data mining and applications.
Springer, Berlin, pp 434–443
Jiang L, Yu M, Zhou M, Liu X, Zhao T (2011) Target-dependent twitter
sentiment classification. Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics: Human Language Technologies, Portland, OR, June 2011, pp 151–160
Liu KL, Li WJ, Guo M (2012) Emoticon smoothed language models
for Twitter sentiment analysis. Proceedings of the Twenty-Sixth
AAAI Conference on Artificial Intelligence, Toronto, Ontario,
Canada, July 2012, pp 1678–1684
Loria S (2015) TextBlob: Simplified Text Processing. http://textblob.
readthedocs.org/en/dev/ Accessed 21 Mar 2015
MetaMap (2013) Semantic Group File. https://metamap.nlm.nih.gov/
Docs/SemGroups_2013.txt
MetaMap (2015) Semantic Types and Groups. https://metamap.nlm.
nih.gov/SemanticTypesAndGroups.shtml
Mohammad SM, Kiritchenko S, Zhu X (2013) NRC-Canada: building
the state-of-the-art in sentiment analysis of tweets. Proceedings
of the seventh International Workshop on Semantic Evaluation
Exercises (SemEval-2013), Atlanta, GA, June 2013
MongoDB, Inc. (2015) PyMongo 3.0 Documentation http://api.mongodb.org/python/current/ Accessed March 21, 2015
MongoDB, Inc. (2015) Data Modeling Introduction. http://docs.mongodb.org/manual/core/data-modeling-introduction/?_ga=1.17047
4338.315992412.1419057306 Accessed March 21, 2015
NLTK Project (2015) NLTK (Nature Language Toolkit). http://www.
nltk.org/. Accessed March 21, 2015
Patientslikeme (2015) https://www.patientslikeme.com/. Accessed
March 27, 2015
Peng Y., Moh M., Moh T.-S. (2016) Efficient adverse drug event extraction using Twitter sentiment analysis. Proceedings of the 8th
IEEE/ACM Int. Conf. on Advances in Social Networks Analysis

13

18

Page 12 of 12

and Mining (ASONAM), San Francisco, CA, August 2016, pp.
1101-1018
Python Software Foundation (2013) Distance 0.1.3. https://pypi.
python.org/pypi/Distance/. Accessed March 15, 2015
Sebastiani F et al (2010) SentiWordNet. http://sentiwordnet.isti.cnr.it/.
Accessed 25 Mar 2015
The Apache Software Foundation (2014) Apache Hive TM. https://
hive.apache.org/. Accessed 15 Mar 2015
The Apache Software Foundation (2016) Apache Spark. http://spark.
apache.org/
The R Foundation (2015) The R Project for Statistical Computing.
https://www.r-project.org/. Accessed 15 Mar 2015
Torunoglu D, Telseren G, Sagturk O, Ganiz M (2013) Wikipedia based
semantic smoothing for twitter sentiment classification. IEEE Int.
Symposium on Innovations in Intelligent Systems and Applications (INISTA), Albena, Bulgaria, June 2013, pp 1–5
Tweepy (2015) An easy-to-use Python library for accessing the Twitter
API. https://www.tweepy.org/. Accessed 15 Mar 2015

13

Netw Model Anal Health Inform Bioinforma (2017) 6:18
U.S. Department of Health and Human Services, Office of Disease
Prevention and Health Promotion (2014) National action plan for
adverse drug event prevention. https://health.gov/hcq/ade-actionplan.asp. Accessed 21 Mar 2015
U.S. National Library of Medicine (2015) MedlinePlus. https://www.
nlm.nih.gov. Accessed 27 Mar 2015
Wiebe J, Wilson T, Cardie C (2005) Annotating expressions of opinions
and emotions in language. Lang Resour Evaluat 39(2–3):165–210
Witten IH, Frank E, Hall MA, Pal CJ (2016) Data mining: practical
machine learning tools and techniques, 4th edn. Morgan Kaufmann, Cambridge
Wu L, Moh T-S, Khuri N (2015) Twitter opinion mining for adverse
drug reactions. IEEE International Conference on Big Data, Santa
Clara, CA, October 2015, pp 1570–1574
Yu F, Moh M, Moh T-S (2016) Towards extracting drug-effect relation from Twitter: a supervised learning approach. IEEE International Conference On Intelligent Data and Security, New York,
NY, April 2016, pp 339–344

