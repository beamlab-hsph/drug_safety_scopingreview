ISSN 0146-4116, Automatic Control and Computer Sciences, 2020, Vol. 54, No. 2, pp. 117–127. © Allerton Press, Inc., 2020.

Identification of Local Adverse Drug Reactions in Xinjiang Based
on Attention Mechanism and BiLSTM-CNN Hybrid Network
Xiaozhuo Wanga, *, Shengwei Tiana, **, Long Yub, and Qimeng Yanga
aSchool

of Software, Xinjiang University, Tianshan, Urumqi, Xinjiang, China
Network Center, Xinjiang University, Tianshan, Urumqi, Xinjiang, China
*e-mail: luxran0703@qq.com
**e-mail: tianshengwei@163.com

b

Received April 29, 2019; revised September 25, 2019; accepted September 30, 2019

Abstract—Adverse drug reactions (ADR) include adverse reactions which are caused by drug quality
problems or improper medication. In order to solve the issues which are triggered by the lack of
research on local adverse drug reactions in Xinjiang and the shortcomings of traditional models in
dealing with irregular sentences, this paper proposes a method for adverse drug identification in Xinjiang. The method is combined with BiLSTM-CNN hybrid network which is based on attention
mechanism. The method analyzes deeply on the network text context feature and the attention pooling
mechanism. These measures can reduce the information loss while acquiring the local convolution
feature. The integration of attention mechanism, the addition of weight information make it becomes
more sensitive to capture the importance of features which brings improvement of the ability to express
features. Finally, the experiment was carried out in the Xinjiang Adverse Drug Reaction Data Set. The
accuracy rate of this model in Xinjiang local drug adverse reaction identification was 87.27%, the recall
rate was 88.87%, and the F value was 87.65%. Compared with the common convolutional neural network and BiLSTM, it achieves better classification results, and has obvious advantages for irregular
grammar and long sentence recognition. Experiments showed that the ATT-BiLSTM-CNN model
can rapidly improve the recognition performance of local adverse drug reactions in Xinjiang.
Keywords: Adverse drug reaction, ATT-BILSTM-CNN, Attention mechanism, Xinjiang local drug,
text recognition
DOI: 10.3103/S014641162002008X

1. INTRODUCTION
Adverse Drug Reaction (ADR) refers to a reaction that is unrelated to a drug’s cure target due to the
interaction between drugs or drugs during the use of the drug. Especially for non-Western medicines, the
interaction of various herbs is very complicated. Due to the long drug development cycle, the cost of clinical trials is high, and the number of participants in the experiment is limited. Many potential adverse drug
reactions have not been discovered during clinical trials. At the same time, most local prescription drug
instructions do not give clear explanations of adverse reactions, and cannot play a role in guiding medication. The incidence of adverse reactions caused by ordinary people taking drugs at random has been
increasing year by year.
Xinjiang local medicine refers to drugs unique to Xinjiang, and is a medicine preparation composed of
animals and plants. From the perspective of the pharmaceutical industry, Xinjiang local medicine is still
in a state of slightly lower level. The research on the adverse reactions of Xinjiang local medicines can better develop the clinical drugs and provide patients with safer and more effective drugs. Improving the overall level of China’s medicine and promoting the rapid development of the region play a key role.
With the development of the network, various medical websites and blogs have sprouted. More and
more patients share their medication experiences online, and there are many useful information in
research comments about the adverse effects of research drugs. A large amount of text data from users'
medical health is more real-time than traditional clinical cases, and it is also a resource of high efficiency
and low cost.
Adverse drug reactions bring great harm to personal health and bring economic losses. Xinjiang local
medicine is an important part of the medical science of the motherland, and research on adverse reactions
117

118

XIAOZHUO WANG et al.

is very scarce. Most of the local drug specifications did not specify the adverse reactions, resulting in a
large number of adverse reactions in the process of not taking the doctor’s instructions for self-administration. Traditional adverse reactions clinical trials require a lot of manpower, material resources and time.
This article analyzes the medicine users’ comments on the network at low cost and quickly through the
network crawler, and quickly and easily finds adverse drug reactions. In the past tasks of feature extraction,
it is often difficult to identify irregular grammars and personalized expressions.
For Xinjiang local medicine, in order to achieve large-scale, high-efficiency, low-cost drug adverse
reaction recognition. This paper extracts corpus from online reviews to form a data set for adverse drug
reactions. Name recognition is a key step in information extraction. In particular, personalized and colloquial sentences in online reviews are highly subjective, and in many cases they must be in contact with
the context to make judgments. The construction of the corpus of Xinjiang local medicine is still not perfect. This paper extends the definition of a set of labeling rules for the annotation processing of corpus
based on the corpus of TCM terminology. The BILSTM-CNN hybrid neural network model is used to
obtain the context global features and local convolution features, and then the bidirectional memory
information of the fusion attention mechanism is used to highlight the effective features. In the end, you
can better capture the two-way semantic dependence. Achieve more accurate classification results. In this
paper, the user’s comments in the network identify the drug and its corresponding adverse reactions,
thereby identifying the potential adverse drug reactions.
2. RELATED WORK
The research status of adverse drug reactions of traditional Chinese medicine has not formed a system.
The incorporation of computer technology into medicine has not touched the relevant parts of adverse
reactions of traditional Chinese medicine. The research status of adverse reactions is still in the preliminary stage. Friedrich S and Dalianis H [1] proposed a method to detect adverse drug reactions in Swedish
electronic health records. The identification of adverse drug reactions was realized by filtering keywords
and phrases and classifying health records with supervisory machine learning algorithm. Trung Huyn
et al. [2] proposed a convolutional recurrent neural network (CRNN), which links convolutional neural
network with recurrent neural network, and classified decision experiments on social network data by
adding attention weight to the convolutional neural network (CNNA). Aroyehun and Gelbukh A [3] use
naive Bayesian support vector machines, deep learning models and long-term and short-term memory
networks. Drugs and adverse reactions are automatically identified on non-traditional communication
platforms such as Twitter and other social media platforms. Segura-Bedmar et al. [4] collected corpus
from Spanish health social media to detect drugs and identify adverse reactions, which is the first Spanish
corpus to annotate patients’comments on adverse drug events. It makes self-reported patient data an
important data source for adverse reaction extraction. Leaman R et al. [5] Mining the relationship
between self-reported drugs and adverse reactions from users’reviews on health-related websites, and
manually labeling user reviews for experiments. However, the analysis of corpus based on network comments has more influence on direct recognition. Naomi Sager [6], the earliest medical speech processing
research, provides semantic annotations by maintaining a dictionary of semantic descriptions. At the same
time, according to the World Health Organization, a glossary of adverse drug reactions (ADRs) in countries with adverse reactions (ADRs) has been translated, but this glossary is mainly based on Western medicine theory, which is quite different from the unique prescription theory in China.
Due to the particularity of Xinjiang local medicines, there is still a lack of computer technology
research on Xinjiang local medicines, and many potential adverse reactions cannot be instantly manifested in clinical application. Traditional recognition methods cannot meet the needs of network text recognition. In order to satisfy the timely analysis of adverse reactions, this paper uses the Internet crawler to
obtain a large number of users’Drug Reviews on the Internet at low cost and fast for analysis, so as to
quickly and conveniently identify adverse drug reactions. Especially for Xinjiang local medicines, corpus
construction is not perfect, and subsequent research is difficult to carry out. This paper obtains comments
on ADRs of Xinjiang local medicines from online reviews. After word segmentation, we extract features
that meet the requirements of the study, and combine two attention mechanisms to improve the accuracy
of classification.
Because of the automatic feature extraction of in-depth learning, it is widely used in various text recognition and feature extraction tasks [7, 8]. The RNN model proposed by Schmindhuber modeled the
whole sentence to capture long-distance dependency information. However, the research shows that
RNN can make the whole sentence more complex in some cases, which makes the model ignore the key
phrase information. CNN [9] model is the opposite, because the filter selection in this model is relatively
AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

IDENTIFICATION OF LOCAL ADVERSE DRUG REACTIONS

119

small. It cannot be used well in the relationship between long sentences and long distances, but is suitable
for short text processing. LSTM is proposed by Hochreiter et al. [10] to optimize and improve on the basis
of RNN. LSTM unit replaces RNN unit and sets three threshold structures, including memory gate,
learning gate and forgetting gate. Long-term memory can be preserved by solving long-distance dependence through memory and forgetting. However, LSTM still has a problem when describing corpus in a
fine-grained way, such as the interaction between words with different emotional degrees. It cannot be
well recognized. Especially, it is impossible to code the data from the back to the front. For the corpus
obtained in the network comments, it is not standard enough, colloquial, and the length of the text is not
the same. Traditional methods have some limitations on text recognition of online reviews.
For personalized, non-standard grammar online reviews. Establishing a reusable corpus for follow-up
research and how to design a reasonable and efficient text feature representation model to effectively identify adverse drug reactions of local drugs in Xinjiang is the focus of this paper.
3. METHODS
In this paper, we use a BILSTM-CNN hybrid network which combines attention to train text recognition. It can better capture the two-way semantic dependence and local features. The local attention
mechanism can also solve the problem of information loss in the pooling layer of CNN, and the global
attention mechanism can highlight more important features. Firstly, this paper collects experimental data
from medical forums, mainstream blogs and other websites, takes full account of the semantic and grammatical relationship of the text, and forms data sets through de-drying processing and feature extraction
and annotation. Then we use Word2vec architecture [11, 12] to clean and extract the features of the data
set according to the experimental needs, and generate distributed vectors. The word vectors are input into
BILSTM and CNN respectively, and the global and convolutional features of the bidirectional context are
obtained. Then the attention mechanism is fused, and the intermediate text learned by the model is used
to guide the weighting of convolutional features and highlight important features. The hybrid network
model can effectively improve the accuracy of the identification of adverse drug reactions of Xinjiang local
medicines. Next, the implementation process of the model is introduced in detail.
3.1. ATT-BILSTM-CNN Neural Network Model
User reviews in the network usually have strong colloquialism and personalization, and contain more
topic-independent information. There are many different degrees of commendatory and derogatory
words, the flexible use of neutral words, emotional words and degree words. So in order to make full use
of the information before and after the current moment, more local implicit information is mined. In this
paper, a BILSTM-CNN neural network model is proposed. Its network structure consists of two opposite
LSTM and a pooling mechanism CNN using attention method. It can provide complete context information to the output layer and identify more prominent local features. After linking the intermediate text
learned by the model, it can be used to guide the weighting of convolutional features, and provide weights
for each input vector, which can highlight some of the feature weighting information. It is very suitable for
flexible text recognition tasks. It can well accomplish the task of identifying ADRs of local drugs in Xinjiang. Figure 1 is the frame diagram of ATT-BILSTM-CNN model.
3.2. Text Preprocessing
Unlike English words, each word is separated by spaces. There is no space between Chinese words. So
we need to use word segmentation algorithm to complete word segmentation. The accuracy of text categorization can be greatly improved by using word segmenter to segment text and removing function words
and neutral words without actual meaning. Text preprocessing is usually the first step in the pipeline of
natural language processing system, and its final performance has potential impact [13]. We collect data
to get online reviews, which have many characters, long sentences and strong personalization. It seriously
affects the performance of classification, so it is necessary to clean the corpus, remove the non-Chinese
part of the data, remove the stop words, deal with the problem of Chinese text mining and coding, and tag
the part of speech for Chinese word segmentation. This paper makes Jieba participle [14].
3.3. Tagging Rules
In this study, reviews from the Internet are mainly extracted, so the indications and adverse reactions
of drugs should be distinguished. The tagging and standardization of corpus is an important link in the
AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

120

XIAOZHUO WANG et al.

Network output
results

Attention

Fully
connected
layer

CNN

BILSTM

BILSTM

CNN

Input Convolution ATTpooling

Text
preprocessing
Corpus
cleaning
Training
data

Chinese word
segmentation

Test data

Fig. 1. ATT-BILSTM-CNN model framework diagram.

realization of machine-readable primitive corpus because of the lack of corpus construction in Xinjiang
local medicine research. This paper defines a set of labeling rules based on the existing Chinese medicine
corpus and through discussion with drug experts, in order to extract better features and identify more acute
adverse drug reactions. It annotates from three aspects: part of speech, semantic category and named
entity annotation. Named entity labeling can be divided into: drugs, symptoms, disease location, disease
name, etiology.
3.4. Neural Network Model
3.4.1. CNN with attention pooling strategy. In this paper, CNN convolution neural network is used to
extract local convolution features. The input layer, convolution layer and pooling layer of convolution
neural network are included. The output of convolution layer is more accurate after further sampling of
the eigenvectors obtained by the pooling layer. Because of the irregular and highly spoken features of user
reviews in the network, and the traditional pooling strategy has the problem of information loss. How to
get more abundant information from online user reviews is the main work of this paper. So this paper uses
the convolutional neural network based on attention pooling strategy proposed by Yong et al. [15]. It can
not only reduce the loss of information in the pooling layer, but also obtain more important parts of the
corpus. Different from the traditional maximum and average pooling strategies, the attention-based
method retains more local feature information. The CNN of the attention pooling strategy is shown in
Fig. 2.
AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

IDENTIFICATION OF LOCAL ADVERSE DRUG REACTIONS

Input

Convolution

121

ATTpooling

Fig. 2. CNN of attention pooling strategy.

ht
Ct

Ct – 1
X
ft

X

it
δ

ht – 1

+

δ

Ct
tanh

Ot
Ot

X

δ

ht

Xt
Fig. 3. LSTM module structure diagram.

3.4.2. BILSTM neural network model. LSTM model [16] is similar to RNN model and is an extension
of RNN. The classical RNN model has many defects in dealing with long-term dependence due to its limited memory and storage capacity. The idea of LSTM is to add special neurons to the hidden layer of
LSTM. LSTM introduces memory gate units and threshold constraints. Three neural units are used to
update and discard information. LSTM neural network can reduce the problem of gradient disappearance
and alleviate the effect of gradient explosion. It can solve the problem of long-distance dependence to a
certain extent. The LSTM module structure is shown in Fig. 3.
At time t, given an input x, the calculation process of LSTM elements is as follows:

it = σ(W xi xt + Whi ht −1 + Wci ct −1 + bi ),

(1)

ft = σ(W xf xt + Whf ht −1 + Wcf ct −1 + b f ),

(2)

ot = σ(W xo xt + Who ht −1 + Wcoct −1 + bo ),

(3)

Ct = fCt −1 + it tanh(W xc xt + Whc ht −1 + bc ),

(4)

(5)
ht = ot tanh(Ct ).
In the above formula, W is the weight matrix connecting the two layers and b is the bias [17]. Expressing
Sigmoid Excitation Function. At t-time it , ft , ot , Ct , ht , they are the activation vectors of input layer, forgetting gate, output gate, memory unit and hidden layer. The result interval of the forgetting gate is 0–1,
and if it is reserved for 1, it is discarded. h is the output of the whole network.
Although LSTM solves the above problems, it can only affect the information before the current word,
can’t act on the information after the target word. To excavate deep hidden features, we need to rely on
context. BiLSTM model is a bidirectional expansion in time. It can use both the content above and the
→

content below, and can capture long-distance information in both directions at the same time; ht is the
AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

122

XIAOZHUO WANG et al.
←

output of forward-passing LSTM network at t-time, h t is the output of the backward-passing LSTM at
t-time. Extending to each moment, the two-way characteristics of each moment can be obtained. The
expression is obtained by stitching:

→ ← 
(6)
ht = ht , ht  .


Two-way LSTM can capture the dynamic information of time series, and also use the information of
current words to improve the accuracy of training. For colloquialism, irregular online reviews are very useful.
3.4.3. Attention mechanism. Attention mechanism was first proposed by the Google Mind team in its
paper [18] published in 2014, which solved the problem of how to allocate limited information processing
resources to important parts. Attention mechanism can simulate the attention characteristics of human
brain and focus on more important information. For the first time, the team introduced the attention
mechanism to process images on the recurrent neural network model. Subsequently, Alex et al. [19]
applied attention mechanism to machine translation of neural networks. ATT-BILSTM-CNN model
adopts attention mechanism, and the ordinary BILSTM-CNN model treats every sentence equally. By
fusing attention mechanism, the intermediate text learned by the model is used to guide the weighting of
convolution features, and the attention layer is added after combining the local features trained by CNN
with the global features of BILSTM. The calculation is as follows:
La

attention (Q,Date) =

a

⋅ value j .

j

(7)

j=1

Among them, La is Date long, a j is value j corresponding weight coefficients, a j . The calculation formula is as follows:
(sim j )

a j = soft max (sim j ) = Lae

e

(8)

.
simk

k=1

In this paper, H is defined as the output sum of BILSTM and CNN results after splicing.

M = tanh (H ),

(9)

α = soft max (wT M ),

(10)

γ = H αT .

(11)

Given the value of an element attention, the prominent weight information can be obtained, and then
the analysis can be more effective. In this experiment, we mainly focus on the symptoms of adverse reactions, which make the model more sensitive in dealing with the information related to adverse drug reactions. After the output value is obtained, the tanh function maps the result to [–1, 1]. For the data of this
area, the definition of [–1, 0] in the scenario adapted to this paper is not adverse drug reactions, (0, 1) is
adverse drug reactions.
4. EXPERIMENTS AND ANALYSIS
This section will introduce the performance comparison of different classifiers in adverse drug reaction
experiments. The validity of ATT-BILSTM-CNN model is proved. In this experiment, we use Word2vec’s
Skip-gram to represent vectors. The ATT-BILSTM-CNN classifier is optimized by adjusting the parameters. The following is the introduction of experimental data, evaluation criteria, experimental settings and
results analysis.
4.1. Experimental Data
Due to the adverse drug reactions (ADRs) of local medicines in Xinjiang, there is no open authoritative
data set in this field. In this paper, we use web crawlers to crawl patients’comments on adverse reactions
after taking medicine from more than a dozen different medical health websites, micro-blogs, post bars
and so on. The data set is formed by dedrying and labeling. In this paper, word vectors are trained using
AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

IDENTIFICATION OF LOCAL ADVERSE DRUG REACTIONS

123

Table 1. Parameter Settings
Super parameter

Adjustment value

Learning rate
Dropout
Gradient clipping
Embedding-dim
Optimizer
Batch-size
Hidden-dim
Epoch

0.001
0.5
5.0
300
Adadelta
500
300
500

skip-gram model of Word2vec. The final data set consisted of 27890 sentences of 46 drugs for the classification of adverse drug reactions. It is divided into training set and test set in the ratio of 8 : 2.
4.2. Model Parameter
In order to achieve the optimal performance of the classifier, the task of text categorization is better
solved. Arithmetic parameters need to be set. For the stability and representativeness of the experimental
results, 10-fold cross validation is chosen here. ATT-BILSTM-CNN parameters as shown in Table 1,
Dropout, learning rate, optimizer, iteration number of a series of parameters through a number of experimental comparisons.
4.3. Evaluation Criterion
In order to reflect the advantages of the model proposed in this paper, the evaluation criteria commonly used in natural language processing are adopted. Accuracy (P), recall (R), F value [20] were used
as evaluation criteria.
4.4. Experimental Results and Analysis
In order to study the different performance of ADR identification models of Xinjiang local drugs and
ATT-BILSTM-CNN models in different situations, the validity of the proposed model was verified.
Based on the word vectors extracted from network reviews, three experiments were designed for comparative study.
(1) The influence of training word vector dimension on the performance of ATT-BILSTM-CNN classification results. The comparative experiments were carried out in 10, 30, 60, 100 and 150 dimensions
respectively.
(2) Under the same characteristics, different models were used to compare the P, R and F values of
ADR recognition.
(3) The effectiveness of BILSTM-CNN hybrid model with attention mechanism to alleviate information loss in the pooling layer of convolutional neural networks is verified.
Experiment 1: ATT-BILSTM-CNN in different dimensions is shown in Table 2 and Fig. 4.
It can be seen in experiment 1. Usually, too small dimension settings will lead to poor results of underfitting. Although high dimension can better explore the implicit information in this paper for more indepth and accurate analysis, too high dimension can easily lead to weak generalization ability of the
model. In this experiment, we tried many dimensions, and found that the performance reached the best
when the dimension was 100, and then all the performance declined. Therefore, in the following model comparison experiments, all of them are set to 100 dimensions. In the process of training, the denominator will
accumulate more and more with the increase of the number of times. In order to solve this problem, Adadelta
[21] algorithm is used as an optimizer in order to solve the problem of reducing the learning rate.
Experiment 2: Using the same data set to experiment on the following models:
(1) CNN: Word2vec training words vector is used as input data to train convolution neural network
classification.
AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

124

XIAOZHUO WANG et al.

Table 2. The influence of different word vector dimensions on performance (%)
Dimension
10
30
60
100
150

P

R

F

81.21
84.52
85.45
87.74
86.53

84.32
84.62
84.21
88.47
84.52

83.73
84.36
85.92
88.32
85.78

Table 3. Comparing the performance of the task of identifying local adverse drug reactions in Xinjiang under different models (%)
Method
CNN
SVM
GBDT
LSTM
BILIST
ATT-BILSTM
ATT-BILSTM-CNN

P

R

F

73.58
75.63
79.21
77.37
83.78
85.32
87.25

63.43
78.57
78.63
69.56
82.35
85.44
88.87

71.23
77.07
78.92
74.37
83.06
85.67
87.65

(2) SVM: Word2vec training words vector is used as input data, and support vector machine is used for
classification.
(3) GBDT: Word2vec training word vector is used as input data and gradient lifting tree is used for classification.
(4) LSTM: Word2vec training words vector is used as input data to classify long-term and short-term
memory networks.
(5) BILIST: The improved two-way long-term and short-term memory network is trained by using
word 2vec training words vector as input data.
(6) ATT-BILSTM: Word2vec training word vectors are used as input data, and two-way long-term and
short-term networks with single attention are used for training.
(7) ATT-BILSTM-CNN: Word2vec training words vector is used as input data, and BILSTM-CNN
hybrid neural network with attention is used for text classification.
The experimental results are compared as shown in Table 3 and Fig. 5.
The results of Experiment 2 showed that the identification of ADRs of local medicines in Xinjiang was
very important. The ATT-BLISTM-CNN used in this experiment is superior to other models in accuracy,
recall and F value, and achieves the best performance in identifying adverse drug reactions. From the
experimental results, ATT-BLISTM-CNN has 8.73% more F value than GBDT, 13.28% more than
LSTM and 10.58% more than SVM. It fully illustrates that ATT-BLISTM-CNN has better performance
in spoken and irregular network comments. The advantages of ATT-BLISTM-CNN model compared
Word vector dimension comparison (%)
90
85
80
75
10

30
P

60
R

100
F

150

Fig. 4. The influence of different word vector dimensions on performance (%).
AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

IDENTIFICATION OF LOCAL ADVERSE DRUG REACTIONS
CNN

63.43

125

71.23
73.58
87.65
88.87
87.25

ATT-BILSTM-CNN

85.67
85.44
85.32

ATT-BILSTM

83.06
82.35
83.78

BILIST

74.37
69.56
77.37

LSTM
GBDT

78.92
78.63
79.21

SVM

77.07
78.57
75.63

0

20

40

60

80

100

F R P
Fig. 5. Performance comparison of Xinjiang local ADR identification tasks under different models (%).

with traditional model are proved. ATT-BILSTM integrates attention mechanism on the basis of BILSTM.
The experimental results show that the F value of ATT-BILSTM is 2.61% higher than that of BILSTM.
Compared with the single structure neural network model, the hybrid network model of CNN and BILSTM
performs better. Because the model integrates attention mechanism and provides weights for each input
vector, the features can highlight some of the features’weight information, and then can be more effective
for analysis, so that we can pay more attention to the target information we need and alleviate the problem
of information loss. It can be seen that the integrated learning algorithm enhances the anti-interference
ability of the model and effectively solves the limitation of the weak generalization ability compared with
the traditional machine learning algorithm. The advantages of ATT-BILSTM-CNN model are proved.
Experiment 3: This paper compares the effects of the attention mechanism pooling strategy and the
traditional pooling strategy hybrid network.
(1) AVG-BILSTM-CNN: Word2vec training word vector is used as input data, average pooling strategy is used to extract features of convolutional neural network, and two-way long-term and short-term
memory network training results are used to classify.
(2) MAX-BILSTM-CNN: Word2vec training word vector is used as input data, Max pooling strategy
is used to extract features of convolutional neural network, and two-way long-term and short-term memory network training results are used to classify.
(3) ATT-BILSTM-CNN: Word2vec training words vectors are used as input data, and convolutional
neural networks based on attention mechanism are used to extract features, which are combined with the
training results of bidirectional long-term and short-term memory networks for classification.
The experimental results are shown in Fig. 6.
The results of Experiment 3 show that the ATT-BILSTM-CNN network used in this experiment is
compared with the traditional pooling strategy. Pooling mechanism based on attention can obviously
show better experimental results. Fusion of attention mechanism can make features highlight some of the
feature weight information initially and alleviate the problem of information loss. The accuracy of ADR
identification task was improved.
5. CONCLUSIONS
Because of the backwardness of medical treatment level and poor consciousness of Self-Access to medical treatment, in recent years, more and more adverse drug reactions are caused by non-standard drug
use. Since most of the local drugs in Xinjiang do not indicate adverse drug reactions, most of the ordinary
patients use drugs independently, resulting in a large number of adverse reactions. In order to solve the
shortcomings of ADR research on local drugs in Xinjiang, this paper aims at the problem of high cost and
long cycle of ADR research on traditional drugs. The method of natural language processing was used to
identify the ADRs of Xinjiang local medicines based on online reviews with low cost and high efficiency.
The main contribution of this paper is to propose a text categorization algorithm based on BILSTM-CNN
AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

126

XIAOZHUO WANG et al.

Comparison of classiﬁcation accuracy
of different pooling strategies (%)
90
88
86
84
82
80
AVG-BILSTM-CNN MAX-BILSTM-CNN

P

R

ATT-BILSTM-CNN

F

Fig. 6. Performance comparison of different pooling strategies for task completion.

hybrid network, which combines the global and local features of the context obtained by BILSTM and
CNN, so that the ADR recognition of Xinjiang local drugs can get better results. Promote the safety of
drug use in patients, making drug use more accurate. Mining a large number of valuable ADR resources
from online reviews can continue to be used for follow-up research in this field. Word2vec model is used
to solve the high-dimensional problem of traditional vector space model. BILSTM solves the problem of
two-way semantic dependency and long sentences. This paper combines BILSTM-CNN with attention
mechanism to classify text more accurately. The accuracy, recall rate and F value are obviously better than
the traditional methods, and have a stable classification effect. It has significant effect in extracting
adverse drug reactions from Chinese texts.
FUNDING
This research is partially supported by The National Natural Science Foundation of China (nos. 61563051,
61662074, 61262064). The Key Project of National Natural Science Foundation of China (61331011). Xinjiang
Uygur Autonomous Region Scientific and Technological Personnel Training Project (QN2016YX0051). Xinjiang
Tianshan Youth Project (2017Q011).
CONFLICT OF INTEREST
The authors declare that they have no conflicts of interest.

REFERENCES
1. Friedrich, S. and Dalianis, H., Adverse drug event classification of health records using dictionary based preprocessing and machine learning, Proceedings of the Sixth International Workshop on Health Text Mining and Information Analysis, 2015, pp. 121–130.
2. Huynh, T., He, Y., Willis, A., and Rüger, S., Adverse drug reaction classification with deep neural networks,
Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers,
2016, pp. 877–887.
3. Aroyehun, S.T. and Gelbukh, A., Automatic identification of drugs and adverse drug reaction related tweets,
Proceedings of the 2018 EMNLP Workshop SMM4H: The 3rd Social Media Mining for Health Applications Workshop and Shared Task, 2018, pp. 54–55.
4. Segura-Bedmar, I., Revert, R., and Martínez, P., Detecting drugs and adverse events from Spanish social media
streams, Proceedings of the 5th International Workshop on Health Text Mining and Information Analysis (LOUHI),
2014, pp. 106–115.
5. Leaman, R., Wojtulewicz, L., Sullivan, R., Skariah, A., Yang, J., and Gonzalez, G., Towards internet-age pharmacovigilance: Extracting adverse drug reactions from user posts to health-related social networks, Proceedings
of the 2010 Workshop on Biomedical Natural Language Processing, 2010, pp. 117–125.
6. Sager, N., Lyman, M., Bucknall, C., Nhan, N., and Tick, L.J. Natural language processing and the representation of clinical data, J. Am. Med. Inf. Assoc., 1994, vol. 1, no. 2, pp. 142–160.
7. Tang, D., Qin, B., and Liu, T., Aspect level sentiment classification with deep memory network, arXiv preprint
arXiv:1605.08900, 2016.
AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

IDENTIFICATION OF LOCAL ADVERSE DRUG REACTIONS

127

8. Chen, Q., Zhu, X., Ling, Z., Wei, S., Jiang, H., and Inkpen, D., Enhanced LSTM for natural language inference, arXiv preprint arXiv:1609.06038, 2016.
9. Chua, L.O. and Roska, T., The CNN paradigm, IEEE Trans. Circuits Syst. I: Fundam. Theory Appl., 1993,
vol. 40, no. 3, pp. 147–156.
10. Hochreiter, S. and Schmidhuber, J., Long short-term memory, Neural Comput., 1997, vol. 9, no. 8, pp. 1735–
1780.
11. Mikolov, T., Kopecky, J., Burget, L., and Glembek, O., Neural network based language models for highly inflective languages, 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, 2009,
pp. 4725–4728.
12. Hinton, G.E., McClelland, J.L., and Rumelhart, D.E., Distributed Representations, Pittsburgh, PA: CarnegieMellon University, 1984, pp. 1–127.
13. Camacho-Collados, J. and Pilehvar, M.T., On the role of text preprocessing in neural network architectures: An
evaluation study on text categorization and sentiment analysis, arXiv preprint arXiv:1707.01780, 2017.
14. Sun, J., 'Jieba' Chinese word segmentation tool, 2012. https://github.com/fxsjy/jieba.
15. Er, M.J., Zhang, Y., Wang, N., and Pratama, M., Attention pooling-based convolutional neural network for
sentence modeling, Inf. Sci., 2016, vol. 373, pp. 388–403.
16. Hochreiter, S. and Schmidhuber, J., Long short-term memory, Neural Comput., 1997, vol. 9, no. 8, pp. 1735–
1780.
17. Mikolov, T., Sutskever, I., Chen, K., Corrado, G.S., and Dean, J., Distributed representations of words and
phrases and their compositionality, in Advances in Neural Information Processing Systems, 2013, pp. 3111–3119.
18. Mnih, V., Heess, N., and Graves, A., Recurrent models of visual attention, in Advances in Neural Information
Processing Systems, 2014, pp. 2204–2212.
19. Graves, A., Jaitly, N., and Mohamed, A.R., Hybrid speech recognition with deep bidirectional LSTM, 2013
IEEE Workshop on Automatic Speech Recognition and Understanding, 2013, pp. 273–278.
20. Lilleberg, J., Zhu, Y., and Zhang, Y., Support vector machines and word2vec for text classification with semantic features, 2015 IEEE 14th International Conference on Cognitive Informatics and Cognitive Computing (ICCI CC),
2015, pp. 136–140.
21. Kim, Y., Convolutional neural networks for sentence classification, arXiv preprint arXiv:1408.5882, 2014.

AUTOMATIC CONTROL AND COMPUTER SCIENCES

Vol. 54

No. 2

2020

