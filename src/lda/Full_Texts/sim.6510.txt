Research Article
Received 18 February 2014,

Accepted 28 March 2015

Published online 29 April 2015 in Wiley Online Library

(wileyonlinelibrary.com) DOI: 10.1002/sim.6510

Signal detection in FDA AERS database
using Dirichlet process
Na Hu,a Lan Huangb*† and Ram C. Tiwarib
In the recent two decades, data mining methods for signal detection have been developed for drug safety surveillance, using large post-market safety data. Several of these methods assume that the number of reports for each
drug–adverse event combination is a Poisson random variable with mean proportional to the unknown reporting
rate of the drug–adverse event pair. Here, a Bayesian method based on the Poisson–Dirichlet process (DP) model
is proposed for signal detection from large databases, such as the Food and Drug Administration’s Adverse Event
Reporting System (AERS) database. Instead of using a parametric distribution as a common prior for the reporting rates, as is the case with existing Bayesian or empirical Bayesian methods, a nonparametric prior, namely, the
DP, is used. The precision parameter and the baseline distribution of the DP, which characterize the process, are
modeled hierarchically. The performance of the Poisson–DP model is compared with some other models, through
an intensive simulation study using a Bayesian model selection and frequentist performance characteristics such
as type-I error, false discovery rate, sensitivity, and power. For illustration, the proposed model and its extension
to address a large amount of zero counts are used to analyze statin drugs for signals using the 2006–2011 AERS
data. Copyright © 2015 John Wiley & Sons, Ltd.
Keywords:

reporting rates; information component; false discovery rate; pseudo-maximum likelihood; pseudoBayes factor; zero-inflated Poisson model

1. Introduction
The US Food and Drug Administration (FDA) has established an Adverse Event Reporting System (AERS) computerized information database since 1968, for post-market drug safety surveillance
and for functioning as an early-warning system or signaling system for adverse events (AEs) that
have not been detected during the pre-market testing because of limitations of clinical trials with
respect to sample size, duration, and generalizability to regular medical practice. The AERS database
contains reports on the AEs associated with approved drugs on the market reported by pharmaceutical companies with mandatory obligations or voluntarily from patients and healthcare professionals,
such as physicians, pharmacists, nurses, and others. AEs from spontaneous reports are continually
reported to the FDA since 1968, although some are submitted as periodic reports. Since 2004, the
data in the AERS database are available online and are updated quarterly (http://www.fda.gov/Drugs/
GuidanceComplianceRegulatoryInformation/Surveillance/); and effective September 2012, the AERS
has migrated to FDA AERS (FARES).
Extensive literature has focused on statistical methods for identifying the signals of disproportionately
high reporting rates from the large safety databases, such as the AERS, using frequentist methods, such as
proportional reporting ratio (PRR), relative odds ratio (ROR), Yule’s test, chi-squared test and likelihood
ratio test (LRT) methods [1–7], and Bayesian methods, namely, Bayesian confidence propagating neural
network (BCPNN), multi-item gamma Poisson shrinker (MGPS), and simplified Bayes (sB) methods
[8–12]. More methods can be found in the Observational Medical Outcomes Partnership’s library listed at
http://omop.fnih.org/MethodsLibrary. Several articles [13–17] have been published comparing statistical
methods including PRR, ROR, Yule’s Q, chi-squared test, BCPNN, and MGPS. The main conclusion
a Department of Statistics, University of Missouri, Columbia, MO 65201,
b Office of Biostatistics, CDER, FDA, Silver Spring, MD 20993, U.S.A.

U.S.A.

to: Lan Huang, Office of Biostatistics, Center for Drug Evaluation and Research, Food and Drug Administration, Silver Spring, MD 20993, U.S.A.
† E-mail: lan.huang@fda.hhs.gov

Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

2725

*Correspondence

N. HU, L. HUANG AND R. C. TIWARI

of these studies was that the Bayesian methods BCPNN and MGPS perform better than the frequentist
methods, such as PRR. In addition, Huang et al. [6] analytically proved that the LRT method controls
both the type-I error and false discovery rate (FDR). They also performed a simulation study to compare
LRT with PRR and BCPNN. Huang et al. [12] showed that the sB method performs similarly to MGPS
in terms of the number of signals detected from the whole AERS data and that sB performs better than
PRR and BCPNN in terms of sensitivity (ST), FDR, and type-I error rate for evaluating signals within
drug classes.
Bayesian methods allow information sharing between the drug–event combinations by assigning a
common prior distribution to the reporting rates in order to smooth the reporting rates estimated from the
data. The common priors, in the available Bayesian or empirical Bayesian methods, are all specified in a
parametric form with unknown hyper-parameters; for example, in the MGPS method [10], it is a mixture
of two gamma distributions with hyper-parameters estimated from the data, and in the sB method, the
common prior is a single gamma with both the scale and shape parameters specified to be the same and
assumed to be between (0, 1). As the number of signals detected may be sensitive to the choice of the
parametric priors, it may be preferable to use a nonparametric prior distribution than a parametric one.
Here, we provide such a nonparametric (hierarchical) Bayesian model, in which the common prior, for
the reporting rates, is the Dirichlet process (DP). The characterizations of DP can be found in [18–23].
The DP model provides flexibility of modeling the reporting rates of all drug–event combinations without
any parametric assumption about the prior distribution.
The novelty of DP prior lies with its two basic properties: first, the clustering property due to discreteness of DP. This results into the clusters of relative reporting rate values drawn from DP. Thus, similar
relative reporting rates form clusters of AEs; and second, the small values of the concentration parameters of DP essentially make its baseline distribution to be a good prior guess of the nonparametric random
prior. The latter property can be used to model the DP prior close to any choice of baseline such as gamma
or lognormal or spike-and-slab distribution. The concentration parameter can be modeled by a (hierarchical) prior, thus making it to be determined by the data. This makes the implementation of the proposed
DP model fully data dependent (and less subjective).
In addition, we notice that there is a large number of zero-count cells in the post-market safety
databases. For example, the percentage of zero-count cells by drug for the 2006–2011 AERS data ranges
from 50% to 99.99% [24]. The regular Poisson model is not suitable for modeling the data with a large
number of zeros because some of the zeros are not from Poisson distribution but are true zeros (the cells
that will never have counts bigger than 0). To address this problem, a zero-inflated Poisson (ZIP) LRT
method [24] has been developed as a frequentist approach using the estimation–maximization (EM) algorithm. Here, we also propose ZIP-sB and ZIP-DP methods as Bayesian approaches for data with a large
proportion of zero counts. The advantage of the Bayesian method in this case is that the computation is
more straightforward and less time-consuming than the EM algorithm used in the ZIP-LRT. The details
of the formulation are included in the Appendix.
The remainder of this article is organized as follows. In Section 2, we introduce the AERS database,
and in Section 3, we briefly review the PRR, LRT, BCPNN, and sB methods. In Section 4, we present
the Bayesian method based on a DP prior. In Section 5, we evaluate the performance of the proposed
DP method through a simulation study using Bayesian model selection procedures and the frequentist
performance characteristics. In Section 6, we apply the methods on some selected drugs from the 2010
AERS database. Finally, we provide some concluding remarks in Section 7.

2. Adverse event reporting system database

2726

The AERS database consists of all available information related to each reported event. It includes patient
demographics like age, gender, and race; route of administration; drug/biologic information; Medical
Dictionary for Regulatory Activities (MedDRA) terms, medical history; treatment indication; therapy
start dates and end dates; and so on. There is a high percentage of missingness on some of these variables.
For signal detection, MedDRA terminology of Preferred Term is used to identify the AEs, and the generic
name of the drug is used, as one drug can have many verbatim names.
In order to identify the safety signals, we present the AERS safety data as a large frequency table (data
matrix) formed by two categorical variables: the row variable representing AEs and the column variable
representing drugs. We have a total of I AEs and J drugs. The count in the (i, j)th cell, nij , is the number
of reports for the ith AE and jth drug combination, i = 1, … , I, j = 1, … , J. The marginal row total, ni⋅ ,
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

N. HU, L. HUANG AND R. C. TIWARI

is the total number of reports for the ith AE, the marginal column total, n⋅j , is the total counts for the jth
drug, and n⋅⋅ is the grand total. Define Eij = ni⋅ × n⋅j ∕n⋅⋅ as the baseline count for cell (i, j). This is the
expected number of case reports assuming that there is no association between the ith AE and jth drug.

3. Preliminaries of proportional reporting ratio, likelihood ratio test, Bayesian
confidence propagating neural network, and simplified Bayes methods
Here, we present a brief summary of the simplest frequentist method PRR; the LRT method with controlled FDR; Bayesian parametric methods, namely, the BCPNN method; and the recently developed
sB method.
3.1. Proportional reporting ratio
The PRR method, for a fixed drug–event combination, is defined as the ratio of the proportion of the
number of reports of the AE to the corresponding proportion of reports of all other AEs for that fixed
drug. PRR, for the ith AE and jth drug, has the following expression:
PRRij =

nij ∕ni⋅
(n⋅j − nij )∕(n⋅⋅ − ni⋅ )

,

and its approximate 95% confidence interval is given by
{
exp

}

√
ln(PRRij ) ± 1.96

1
1
1
1
−
+
−
nij ni⋅ n⋅j − nij n⋅⋅ − ni⋅

.

Note that, for notational convenience, unless specified otherwise, we do not distinguish between a parameter and its estimate. In practice, based on how statistical significance is generally defined for relative
risks [25], if the lower bound of the 95% confidence interval (PRR025) is greater than 1, the drug–AE
pair (i, j) could be considered as a signal of disproportionate reporting (SDR).
3.2. Likelihood ratio test
For each fixed drug j∗ , there are I tables, each associated with an AE (i = 1, … , I). The LRT method [6]
assumed that nij∗ ∼ Poisson(ni⋅ pi ), where pi is the reporting rate of the j∗ th drug for the ith AE, and that
(n⋅j∗ −nij∗ ) ∼Poisson ((n⋅⋅ −ni⋅ )×qi ), where qi is the reporting rate of the j∗ th drug for other AEs combined
excluding the ith AE. Define the null hypothesis, H0 , as pi = qi for all i, and the alternative hypothesis,
Ha , as pi > qi for at least one i among the I AEs. The likelihood ratio for the ith AE and the fixed j∗ th
drug is obtained by the maximum likelihoods under both the null and two-sided alternative hypotheses,
as follows:
)
/( )n⋅j∗
( )nij∗ (
n⋅j∗ − nij∗ n⋅j∗ −nij∗
n⋅j∗
nij∗
LRij∗ =
, i = 1, … , I.
ni⋅
n⋅⋅ − ni⋅
n⋅⋅
The LRT statistic is the maximum likelihood ratio (MLR) = maxi (LRij∗ ), where the maximum is over
AEs, i = 1, … , I.
The distribution of MLR under H0 is not analytically tractable and is obtained using Monte Carlo
simulation. Under H0 , the joint distribution of (n1j∗ , … , nIj∗ ), conditioning on n⋅j∗ , and (n1⋅ , … , nI⋅ ) is
))
(
(
nI⋅
n1⋅
.
,…,
(n1j∗ , … , nIj∗ )|n⋅j∗ , (n1⋅ , … , nI⋅ ) ∼ multinomial n⋅j∗ ,
n⋅⋅
n⋅⋅

Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

2727

A total of 9999 datasets under H0 are simulated from the multinomial distribution, and 10,000 MLRs are
calculated. The null hypothesis H0 is rejected at the 𝛼 = 0.05 level if the value of MLR from the observed
dataset is greater than the 95th percentile of the 10,000 MLR values. The ith AE associated with the MLR
has high reporting rates compared with other AEs associated with the j∗ th drug and is a signal for the j∗ th
drug. The other AE signals associated with the j∗ th drug can be detected by using a step-down procedure
as described in [12, 26].

N. HU, L. HUANG AND R. C. TIWARI

3.3. Bayesian confidence propagating neural network
Bate et al. [8] introduced the BCPNN method for disproportionality analysis, based on a measure named
as the information component (IC), because of its derivation from the measure used in information theory
[27]. The method assumes that the cell report counts nij and the marginal row and column total report
counts ni⋅ and n⋅j are independent and follow binomial distributions with beta priors as follows:
(
)
nij |pij ∼ Binomial n⋅⋅ , pij

with

)
(
ni⋅ |pi⋅ ∼ Binomial n⋅⋅ , pi⋅
)
(
n⋅j |p⋅j ∼ Binomial n⋅⋅ , p⋅j

with
with

(
)
pij ∼ Beta 𝛼ij , 𝛽ij ,
)
(
pi⋅ ∼ Beta 𝛼i⋅ , 𝛽i⋅ ,
)
(
p⋅j ∼ Beta 𝛼⋅j , 𝛽⋅j ,

where pij , pi⋅ , and p⋅j are, respectively, the probabilities of the occurrence of the (i, j)th cell count and
1
ith row and jth column total counts; 𝛼ij = 𝛼i⋅ = 𝛽i⋅ = 𝛼⋅j = 𝛽⋅j = 1 and 𝛽ij = E(p |n )E(p
− 1;
i⋅ i⋅
⋅j |n⋅j )
that is, 𝛽ij is determined by solving the equation that the prior mean of pij is equal to the product of the
posterior means of pi⋅ and p⋅j . Thus, 𝛽ij is not pre-specified but is data dependent, and hence, the BCPNN
is an empirical Bayes approach. The IC for each drug–event combination (i, j) measures the strength of
pij
association between the ith AE and jth drug and is defined as ICij = log2 p ×p
. The estimates of the
i⋅
⋅j
posterior mean and the posterior variance of ICij , using the delta method, are given by
̂ ij ) ≈ log2
E(IC
̂
V(IC
ij ) ≈

(nij + 1)(n⋅⋅ + 2)2

(n⋅⋅ + 𝛾)(ni⋅ + 1)(n⋅j + 1)
[
n⋅⋅ − nij + 𝛾 − 1
1

,

(log 2)2 (nij + 1)(1 + n⋅⋅ + 𝛾)

+

]
n⋅⋅ − n⋅j + 1
n⋅⋅ − ni⋅ + 1
+
,
(ni⋅ + 1)(n⋅⋅ + 3) (n⋅j + 1)(n⋅⋅ + 3)

where 𝛾 = 𝛽̂ij . Let the lower bound of the 95% confidence limit of the IC be denoted by IC025. Under
̂
̂
the assumption that E(IC)
is asymptotic normal [8], IC025 is approximately calculated as E(IC)
− 1.96 ×
√
̂
V(IC).
If IC025 > 0, the drug–AE pair (i, j) is considered as an SDR.
3.4. Simplified Bayes
Huang et al. [12] introduced the sB method, which assumes 𝜆ij ’s are independent and identically distributed with the common prior as Gamma(𝛼, 𝛼); that is, 𝜆ij ∼iid Gamma(𝛼, 𝛼) with mean 1 and variance
1∕𝛼. In addition, a uniform hyper-prior for 𝛼 can be assigned; that is, 𝛼 ∼ U(0, 1). We call it a hierarchical sB (HsB) model. Here, we will use the sB method with fixed 𝛼(0 < 𝛼 < 1), as it is well related to the
new IC method [9], which will be explained later. It is also computationally much less intensive than the
HsB and MGPS methods. With fixed 𝛼, the posterior distribution of 𝜆ij is also a gamma distribution:
𝜆ij |nij , Eij ∼ Gamma(𝛼 + nij , 𝛼 + Eij ).
n +𝛼

n +𝛼

Thus, the posterior mean and posterior variance of 𝜆ij are given as E(sBij ) = Eij +𝛼 , Var(sBij ) = (E ij+𝛼)2 .
ij
ij
We find that the posterior mean of sBij , on the logarithm scale, with base 2, happens to be the shrinkage
n +𝛼
interaction measure in the new IC method [28]; that is, ICijnew = log2 Eij +𝛼 . The tuning parameter 𝛼 was
ij
selected to be 0.5, which corresponds to the mean of the Uniform(0, 1) prior in HsB, as it provides enough
shrinkage to avoid the highlighting of disproportional reporting based on just one or two reports. Given
the posterior mean of sBij , we can easily derive the variance of ICijnew using the delta method as
Var(ICijnew ) ≈

1
1
.
2
n
(log2) ij + 𝛼

2728

Noren et al. [28] suggested to use a lower limit of the 95% credible interval greater than 0 as an indication
of disproportional reporting.
In the sB method, the hyper-parameter 𝛼 is specified to be 0.5, same as the tuning parameter in the new
IC method. Thus, the prior variance of Gamma(𝛼, 𝛼) is 2, and the prior is non-informative. The criterion
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

N. HU, L. HUANG AND R. C. TIWARI

is that if the lower bound of an approximate 95% confidence interval for 𝜆, from the posterior distribution,
is greater than 2, the drug–AE pair (i, j) is an SDR.
Instead of sB with a single gamma prior, the MGPS method [10, 11], an empirical Bayes method, uses
a common prior distribution for 𝜆ij as a mixture of two gamma distributions with probability density
given as
(
)
(
)
𝜋(𝜆ij ) = P × g 𝜆ij ; 𝛼1 , 𝛽1 + (1 − P) × g 𝜆ij ; 𝛼2 , 𝛽2 ,
where P is the mixing probability. The estimates of the parameters (𝛼1 , 𝛽1 , 𝛼2 , 𝛽2 , and P) are derived,
using the entire I × J data matrix, in an empirical Bayes approach. The performance of the MGPS method
is data dependent because the prior parameter estimates and the degree of shrinkage vary by data. The
simulation would require generating the entire I × J matrix for the estimation of the prior parameters and
for the number of signals detected. It is difficult to generate the entire I × J matrix with fixed marginal
column totals and row totals for simulation study. Also, as mentioned earlier, an exploration of the 2010
AERS data showed that the signals detected by sB and MGPS methods are comparable. Therefore, we
will not focus on the MGPS method in the following sections.

4. Poisson–Dirichlet process method
The parametric priors for 𝜆ij ’s, such as a single gamma distribution in the sB method or a mixture of
two gamma distributions in the MGPS method, can be relaxed by a nonparametric prior, the DP prior,
described as follows:
iid

𝜆ij |G ∼ G,
where G is distributed as the DP(𝜌, G0 ); that is,
G|(𝜌, G0 ) ∼ DP(𝜌, G0 ),
with precision parameter 𝜌 and baseline distribution G0 . The baseline distribution, G0 = Gamma(𝛼, 𝛼),
is a gamma distribution with mean 1 and variance 1∕𝛼. Further assume that the hyper-priors for the
hyper-parameters 𝛼 and 𝜌 are
𝛼 ∼ Uniform(0, 1),
𝜌 ∼ Uniform(0.2, 10),

iid

𝜆ij |Gj ∼ Gj ,
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

2729

where the lower bound of 𝜌 is taken to be greater than 0, so that the marginal density of 𝜌 is integrable.
In the preceding Bayesian hierarchical model, the baseline distribution G0 is the prior guess of the
common unknown distribution, G, of the relative reporting rates 𝜆ij ’s, and the precision parameter 𝜌 is
the measure of the strength of this belief (probability that G0 is true G). A large value of 𝜌 indicates that
the prior guess G0 is very close to G, and a small value of 𝜌 allows G0 to deviate more from G; and thus,
𝜌 provides a definite information concerning the unknown prior distribution G [22]. Theoretically, it is
because a draw from DP(𝜌, G0 ), that is, from the (random) distribution G, always results in a discrete
distribution, where the distinct points, in the support of G, have the distribution G0 . Small values of 𝜌
cause more repetitions (i.e., ties) of the points in the support of G and yield fewer number of distinct
points in the support. When 𝜌 converges to 0, G converges to a random degenerate distribution 𝛿Y where
the single support point Y has distribution G0 [22].
The two main advantages of assuming the preceding formulation of 𝜆ij ’s are as follows. First, the
modeling of 𝜆ij ’s using the DP prior leads to more flexibility in the underlying distribution G to be nonparametric. That is, compared with the sB and HsB methods with a single gamma prior and the MGPS
method with a mixture of two gamma priors, the DP prior allows the availability of a much richer class
of distributions, and thereby, it better accommodates our lack of knowledge of the distributional structure
of the relative reporting rates, 𝜆ij ’s. Second, the draws from G are discrete values, resulting in possible
ties (clusters). In the AERS database, we believe that drugs from the same class share some common
AEs. Thus, the natural clustering property of the DP is helpful in ascertaining clusters of drug–event
combinations that have the same relative reporting rate.
Furthermore, it is reasonable to assume that the different drugs or drug classes share different
prior information, that is, different precision parameters and baseline distributions, which brings more
flexibility to our DP model. Thus, for a specific drug j, the DP prior can be described as follows:

N. HU, L. HUANG AND R. C. TIWARI

where Gj is distributed as the DP(𝜌j , G0j ); that is,
(
)
(
)
Gj | 𝜌j , G0j ∼ DP 𝜌j , G0j ,
with precision parameter 𝜌j and baseline distribution G0j . The baseline distribution is G0j = Gamma(𝛼j , 𝛼j ),
and the hyper-priors for the hyper-parameters 𝛼j and 𝜌j are
𝛼j ∼ Uniform(0, 1),
𝜌j ∼ Uniform(0.2, 10).
Computationally, this formulation allows the detection of signals of AEs by drug.
There are two ways to implement the DP prior. First, by using the Pólya urn representation of the DP
[19], the joint distribution of the 𝜆ij ’s, conditional on G0j ’s and 𝜌j ’s, is given by

𝜋(𝜆11 , 𝜆12 , … , 𝜆1J , 𝜆21 , … , 𝜆IJ ) =

J ⎡
I
⎤
∏
∏
∑
𝜌j
1
⎢
G(d𝜆ij ) +
𝛿𝜆 ′ ′ (d𝜆ij )⎥ .
⎥
⎢ 𝜌 + lij
𝜌j + lij − 1 l ′ ′ <l i j
i=1 j=1 ⎣ j
ij
⎦
i j

Here, we sort the list of {𝜆ij , i = 1, … , I, j = 1, … , J} as {𝜆11 , 𝜆12 , … , 𝜆1J , 𝜆21 , … , 𝜆IJ }. lij represents the
order number of 𝜆ij in the list of 𝜆’s, and li′ j′ < lij means 𝜆i′ j′ is before 𝜆ij . Because of the exchangeability
of the 𝜆ij ’s, we can write the conditional distributions of any 𝜆ij given the rest of other 𝜆’s, 𝜌j , and 𝛼j as

𝜆ij |{𝜆i′ j′ , i′ ≠ i

or j′ ≠ j, 𝛼j , 𝜌j } ∼

Lij

𝜌j
𝜌j + IJ − 1

G(d𝜆ij ) +

∑
1
𝛿∗
,
𝜌j + IJ − 1 l=1 𝜆ijl (d𝜆ij )

{
}
where 𝜆∗ijl , l = 1, … , Lij are the distinct atoms of {𝜆i′ j′ , (i′ , j′ ) ≠ (i, j)} and {pijl } are the multiplicities
of 𝜆∗ijl . For completeness, the conditional posteriors are given in Appendix A.
The second way to implement the DP prior is to use the constructive definition of the DP [22, 23], now
well known as a stick-breaking definition, to produce MCMC algorithms as follows:

Gj (⋅) =

∞
∑

wl 𝛿𝜃l ,

l=1

iid

𝜃l ∼ G0j (⋅),
w1 = v1 , wr = vr

r−1
∏
(

)
1 − vs , r ⩾ 2 and

(
)
iid
vs ∼ Beta 1, 𝜌j , s ⩾ 1,

s=1

2730

where 𝛿𝜃 denotes the degenerate distribution with all its mass at 𝜃. In practice, we can truncate the pre∑
usually taken to be the square
ceding mixture at some finite number L with wL = 1 − L−1
l=1 wl , where L is
∑
root of the sample size or the logarithm of the sample size. Hence, G = Ll=1 wl 𝛿𝜃l after the truncation.
The advantage of this finite truncation mixture representation of the DP model is that the MCMC samples can be generated using the standard MCMC procedures [29, 30]. One of the properties of the DP is
that even though the DP is discrete with probability 1, the number of its distinct values, namely, ‘atoms’,
is not large. As a result, the choice of the truncation in the finite representation of the DP is taken to be
small, usually of the order of log(n) or square root of n, where n represents the sample size (in our application, for a fixed column, it is the number of AEs). This finite truncation of the constructive definition
of the DP prior will be used to obtain the empirical posterior distribution of 𝜆ij ’s in both the simulation
study and the real-data analysis, in the next section. A drug–event combination (i, j) is detected as an
SDR if the 5th quartile of the sampled 𝜆ij is greater than a threshold value of 2.
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

N. HU, L. HUANG AND R. C. TIWARI

5. Simulation study
A series of simulation studies were carried out to assess the performance of the proposed DP method
compared with the PRR, BCPNN, sB, and LRT methods.
5.1. Simulation setup
5.1.1. Performance characteristics. The performance characteristic measures for comparison of the
PRR, BCPNN, sB and DP methods are power, type-I error rate, ST, and FDR. These measures are
estimated by Monte Carlo simulations. The power is defined as
# of times detecting at least one signal
.
N
We select N as 500 because the MCMC samples are drawn from conditional posteriors that are conjugate
with priors and a large choice of N does not make any substantial difference in the results.
Under the null hypothesis, that is, when data are simulated without any true signals, this becomes the
type-I error. The null hypothesis is rejected when it detects at least one signal. For each simulated dataset
s, the ST is the proportion of actual positive signals correctly detected:
STs =

# of true-positive signals in sth simulated data
,
total # of true signals in the sth simulated data

and the FDR is defined as
FDRs =

# of false-positive signals in the sth simulated data
.
total # of detected signals in the sth simulated data

̂ = 1 ∑N FDRs .
̂ = 1 ∑N STs and FDR
Therefore, ST
s=1
s=1
N
N
The ST and FDR are between 0 and 1. A high ST value and a low FDR value indicate a good performance of the method. If data are simulated without any signals, the FDR is equivalent to type-I error, and
the ST is not defined.
5.1.2. Data generation. We simulate datasets that reflect the marginal counts from FDA’s AERS dataset
from the first quarter of 2006 to the last quarter of 2011 (the most recent year when this study was
performed). In the simulation study, the interest is to identify the AEs with high reporting rates compared
with other AEs associated with the particular drug, docosanol. To avoid computation intensity, we only
consider 500 AEs, which are randomly selected from the total of 14,415 AEs in that whole dataset, with
their corresponding marginal counts n1⋅ , … , nI⋅ (I = 500).
We first consider the case where no AE is a signal. For the specified drug docosanol (j∗ ), n1j∗ , … , nIj∗
are independent Poisson random variables. Hence, the conditional distribution of (n1j , … , nIj ) given the
column total n⋅j is a multinomial distribution. Thus, the datasets are simulated as
(

n1j∗ , · · · , nIj∗

)

(

n
|n⋅j∗ ; n1⋅ , · · · , nI⋅ ∼ multinomial n⋅j∗ ; 1⋅ , · · · ,
n⋅⋅

(

nI⋅
n⋅⋅

))
,

Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

2731

∑I
with n⋅⋅ = i=1 ni⋅ as the total number of cases reported. Next, we consider the case where signals
exist among the 500 AEs with a high (>1) relative reporting rate. The datasets are simulated using
the following:
(
)
(
)
n1j∗ , … , nIj∗ |n⋅j∗ ; n1⋅ , … , nI⋅ ∼ multinomial n⋅j∗ , 𝐩 ,
(
)
n
n
where 𝐩 = rr1j∗ × r0 × n1⋅ , … , rrIj∗ × r0 × n1⋅ is a vector of probabilities with rr1j∗ , … , rrIj∗ as the relative
⋅⋅
⋅⋅
∑
n
n
reporting rates and with the constraints that 0 ⩽ rrij∗ ×r0 × ni⋅ ⩽ 1, i = 1, … , I, and Ii=1 rrij∗ ×r0 × ni⋅ = 1;
⋅⋅
⋅⋅
r0 can be considered as the baseline risk. The AEs selected as true signals are assigned with relative
reporting rates greater than 1, while other AEs are assigned with relative reporting rates equal to 1.
We evaluate the effect of three factors (the relative reporting rates (rr), the sample size (n⋅j∗ ), and the
number of signals present) on the performance of the methods. Three different levels of relative reporting

N. HU, L. HUANG AND R. C. TIWARI

Table I. Type-I error.
Dataset

Model

Type-I error

Large (n⋅j∗ = 5000)

DP
sB
BCPNN
PRR
LRT

0.000
0.045
1.000
0.960
0.045

Moderate (n⋅j∗ = 1500)

DP
sB
BCPNN
PRR
LRT

0.000
0.017
1.000
0.811
0.044

Small (n⋅j∗ = 600)

DP
sB
BCPNN
PRR
LRT

0.000
0.014
0.745
0.680
0.040

BCPNN, Bayesian confidence propagating neural network; DP, Dirichlet process; LRT, likelihood ratio test;
PRR, proportional reporting ratio; sB, simplified Bayes.

Table II. Summary of all statistics—large sample size—five true signals.
Dataset

rr

Model

No. of detected
signals

Sensitivity

FDR

Power

3

DP
sB
BCPNN
PRR
LRT

2.15
2.06
7.42
23.66
2.77

0.429
0.403
0.865
0.896
0.545

0.001
0.016
0.387
0.804
0.011

0.914
0.960
1.000
1.000
1.000

5

DP
sB
BCPNN
PRR
LRT

4.49
4.57
7.77
23.62
4.65

0.897
0.907
0.995
0.997
0.921

0.002
0.005
0.331
0.782
0.008

1.000
1.000
1.000
1.000
1.000

10

DP
sB
BCPNN
PRR
LRT

4.99
5.02
7.11
21.98
5.03

0.998
0.999
1.000
1.000
0.999

0.000
0.004
0.269
0.765
0.007

1.000
1.000
1.000
1.000
1.000

Large(n⋅j∗ =5000 )

BCPNN, Bayesian confidence propagating neural network; DP, Dirichlet process; FDR, false discovery
rate; LRT, likelihood ratio test; PRR, proportional reporting ratio; sB, simplified Bayes.

rates are used: rr = 3, 5, and 10; and the number of true signals are selected to be 1, 5, and 10. A wide
range of sample size are investigated (from n⋅j∗ = 200 to 5000). We simulate the dataset with a very small
sample size (e.g., 200) to generate many cells with zero counts, in order to understand the performance
of the methods in the extreme case of sparse data.
5.2. Simulation results

2732

Type-I error values are summarized in Table I. Both the BCPNN and PRR have type-I error rates equal
or close to 1, which indicates that many false alerts occurred, when there are actually no signals in the
datasets. The DP and sB methods have type-I error close to 0, for all the three categories of datasets.
The LRT method has type-I error close to the pre-specified alpha level of 0.05. Tables II–IV show the
results on simulated data with five true signals, with different sample sizes (n⋅j∗ ) and relative reporting
rate. All the performance statistics, including ST, FDR, and power, are summarized in Tables II–IV.
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

N. HU, L. HUANG AND R. C. TIWARI

Table III. Summary of all statistics—moderate sample size—five true signals.
Dataset

rr

Model

No. of detected signals

Sensitivity

FDR

Power

3

DP
sB
BCPNN
PRR
LRT

0.29
0.82
4.31
20.98
0.93

0.057
0.160
0.497
0.636
0.182

0.000
0.010
0.386
0.845
0.013

0.216
0.618
0.998
1.000
0.708

5

DP
sB
BCPNN
PRR
LRT

2.33
2.78
5.70
21.91
2.73

0.466
0.554
0.795
0.890
0.537

0.001
0.004
0.276
0.791
0.012

0.984
1.000
1.000
1.000
1.000

10

DP
sB
BCPNN
PRR
LRT

4.44
4.66
6.30
21.39
4.70

0.888
0.928
0.983
0.993
0.928

0.001
0.003
0.198
0.759
0.010

1.000
1.000
1.000
1.000
1.000

Moderate(n⋅j∗ =1500 )

BCPNN, Bayesian confidence propagating neural network; DP, Dirichlet process; FDR, false
discovery rate; LRT, likelihood ratio test; PRR, proportional reporting ratio; sB, simplified Bayes.

Table IV. Summary of all statistics—small sample size—five true signals.
Dataset

rr

Model

No. of detected
signals

Sensitivity

FDR

Power

3

DP
sB
BCPNN
PRR
LRT

0.02
0.30
2.50
16.26
0.25

0.003
0.056
0.256
0.459
0.041

0.000
0.017
0.432
0.855
0.038

0.014
0.264
0.952
1.000
0.224

5

DP
sB
BCPNN
PRR
LRT

0.67
1.38
3.63
17.36
1.24

0.133
0.273
0.504
0.537
0.243

0.002
0.009
0.270
0.786
0.014

0.490
0.874
0.998
1.000
0.846

10

DP
sB
BCPNN
PRR
LRT

2.87
3.28
4.96
17.53
3.32

0.574
0.654
0.822
0.947
0.654

0.001
0.004
0.148
0.721
0.011

0.998
1.000
1.000
1.000
1.000

Small(n⋅j∗ =600 )

BCPNN, Bayesian confidence propagating neural network; DP, Dirichlet process; FDR, false
discovery rate; LRT, likelihood ratio test; PRR, proportional reporting ratio; sB, simplified Bayes.

We also investigate the performance of different numbers of true signals for datasets with a moderate
sample size (n⋅j∗ = 1500). The results are shown in Table V.

Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

2733

5.2.1. Comparison of Dirichlet process with simplified Bayes and likelihood ratio test. The LRT method
is analytically proved to control the type-I error and FDR [6]. For large datasets (shown in Table II),
the DP method performs well, with high ST (>0.89 except the case rr = 3), low FDR (<0.002), and
high power (>0.9). Especially when rr is large (rr = 10 ), the DP method can detect all the true signals
(ST = 1, FDR = 0, and power = 1). The sB and LRT methods have similar performance as the DP
method when rr is large, with only a slightly larger FDR than the DP method. However, when rr is small
(rr = 3), the sB method performs worse than the DP method. It has lower ST and higher FDR. The LRT
method also has higher FDR than the DP method in this case.

N. HU, L. HUANG AND R. C. TIWARI

Table V. Summary of all statistics—moderate sample size—different numbers of true signals.
No. of signals

rr

Model

No. of detected
signals

Sensitivity

FDR

Power

3

DP
sB
BCPNN
PRR
LRT

0.05
0.30
2.93
19.49
0.43

0.052
0.280
0.868
0868
0.372

0.000
0.022
0.624
0.954
0.043

0.052
0.300
0.976
1.000
0.402

5

DP
sB
BCPNN
PRR
LRT

0.66
0.94
2.87
18.99
1.02

0.662
0.926
0.996
0.996
0.996

0.000
0.008
0.563
0.945
0.029

0.662
0.926
1.000
1.000
0.956

10

DP
sB
BCPNN
PRR
LRT

1.00
1.01
2.72
18.67
1.03

1.000
1.000
1.000
1.000
1.000

0.001
0.003
0.529
0.945
0.029

1.000
1.000
1.000
1.000
1.000

3

DP
sB
BCPNN
PRR
LRT

3.33
2.50
7.58
22.44
3.80

0.333
0.249
0.644
0.746
0.376

0.001
0.006
0.137
0.660
0.008

0.956
0.988
1.000
1.000
1.000

5

DP
sB
BCPNN
PRR
LRT

6.62
6.16
8.98
22.02
6.37

0.662
0.615
0.829
0.900
0.636

0.000
0.006
0.071
0.581
0.002

1.000
1.000
1.000
1.000
1.000

10

DP
sB
BCPNN
PRR
LRT

8.86
8.60
9.83
20.04
8.46

0.886
0.860
0.957
0.983
0.845

0.001
0.000
0.024
0.497
0.001

1.000
1.000
1.000
1.000
1.000

1

10

BCPNN, Bayesian confidence propagating neural network; DP, Dirichlet process; FDR, false discovery
rate; LRT, likelihood ratio test; PRR, proportional reporting ratio; sB, simplified Bayes.

For moderate datasets (shown in Table III), when rr is low (rr = 3), the DP method has ST
much lower than that in the large datasets, while the FDR is still good. The sB and LRT methods
have a little bit higher ST and also higher FDR. When rr is large (rr = 5 or 10), the ST of all the
three methods improves considerably. But the sB and LRT methods still have larger FDR than the
DP method.
For small datasets (shown in Table IV), none of the three methods has a good performance because
the sample size is too small. All of them have low sensitivities in all cases. The DP method is more
conservative than the other methods and has small FDR in all situations. The performance of the three
methods for small datasets becomes better with rr’s increased to 10.
To sum up, the results show that the DP method controls FDR reasonably well in all situations. The
DP method has ST similar to that of the sB and LRT methods for moderate and small datasets. For large
datasets with small rr, the DP method has a larger ST than the sB method.

2734

5.2.2. Comparison of Dirichlet process with proportional reporting ratio and Bayesian confidence
propagating neural network. As shown in Tables II–IV, the PRR and BCPNN methods have similar
performance. The BCPNN method always detects many more signals than the DP, sB, and LRT methods. The PRR method detects even more signals than the BCPNN. Both PRR and BCPNN have high ST
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

N. HU, L. HUANG AND R. C. TIWARI

compared with the DP, sB, and LRT methods, but they also result in a large number of false-positive
signals or wrongly detected signals.
5.3. Comparison of Dirichlet process, simplified Bayes, Bayesian confidence propagating neural
network, proportional reporting ratio, and likelihood ratio test for robustness evaluation
We also study the robustness of the signal detection methods by simulating the data from single discrete
uniform distributions or a mixture of several discrete uniform distributions. It is a challenge to simulate
the cell count data from uniform distributions with fixed marginal row totals ni⋅ , fixed sample size n⋅j ,
and controlled relative reporting rates, rri , as we did before (using multinomial distribution). For these
reasons, it is also a challenge to generate the cell count data from other distributions such as normal,
lognormal, exponential, and negative binomial distributions.
For computational ease, we assume that all the row marginal totals are the same, with a common value
of 10,000 (this will not be true in real practice), and generate counts from discrete uniform distributions
shown in Table VI. The total sample size for the datasets is fixed at 8000 for the 500 cells (AEs). If the
sum of the simulated counts for cells i = 1, … , i ∗ (<500) exceeds 8000, we assign each of the remaining
cells a zero count. The locations of the cells with assigned discrete uniform distributions are fixed. Counts
were generated for these cell locations from their assigned distributions with larger means first, followed
by the ones with smaller means.
For this kind of data, we do not know the true signals; however, the expected cell count is 8000∕500 =
16. Therefore, the cell counts generated earlier, with a value greater than 16, are likely to be a signal.
Usually, a cell count is claimed to be a signal if the lower bound of confidence interval (for the estimated
cell counts in this case) is above 16. Table VI presents the average number of signals detected by different
methods over 1000 repeats. If the uniform distribution has a small range and includes the expected count
of 16 (e.g., U[15, 22]), none of the methods detected any signal (average number is zero), which is
reasonable. In some cases, BCPNN and PRR found some signals, but DP, sB, and LRT methods did
not detect any signals (e.g., U[15, 26] and U[15, 25]); sB found similar signals as detected by DP, but
sometimes, it found less signals than the LRT method. For case a, the average number of signals detected
by BCPNN and PRR is in the 30s and close to the numbers detected by the other methods because the
total number of cells with a cell count bigger than 16 is only about 40. All the signals detected are in the
cells from uniform distributions with higher mean, which is reasonable.
In general, the PRR and BCPNN methods are more sensitive but also give more false-positive signals.
The DP, sB, and LRT methods are comparable, with similar average numbers of detected signals. The
LRT method tends to be more sensitive than the DP and sB methods in those cases, but the numbers
of signals are close. The sB method has been shown to be more sensitive most of the time for the data
generated from multinomial distributions (Tables I–V); however, the average numbers of signals detected
by the sB method for the data from the discrete uniform distributions are usually the same or fewer than
that of the DP method. The variation of the number of signals detected over repeats is smaller for the sB
method and bigger for the DP and LRT methods (results are not shown), which is expected because the
Table VI. Average number of signals detected for datasets generated from discrete uniform
distributions.
Discrete distributions
a: 5 cells from U[501, 1000], 10 cells with U[51, 500],
35 cells from U[11, 50], 50 cells from U[4, 10],
and 400 cells from U[0, 3]
b: 5 cells from U[101, 150], 10 cells from U[51, 100],
35 cells from U[26, 50], and others from U[0, 25]
c: 50 cells from U[26, 50] and others from U[0, 25]
d: 5 cells from U[50, 80] and others from U[15, 25]
e: 5 cells from U[30, 60] and others from U[15, 25]
f: 5 cells from U[50, 80] and others from U[15, 22]
g: All cells from U[15, 25]
h: All cells from U[15, 26]
i: All cells from U[15, 22]

DP

sB

BCPNN

PRR

LRT

30

22

36

37

29

34
29
5
3
5
0
0
0

26
19
5
3
5
0
0
0

67
71
40
39
5
38
75
0

83
74
74
74
5
74
110
0

38
36
5
4
5
0
0
0

Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

2735

BCPNN, Bayesian confidence propagating neural network; DP, Dirichlet process; LRT, likelihood
ratio test; PRR, proportional reporting ratio; sB, simplified Bayes.

N. HU, L. HUANG AND R. C. TIWARI

sB method is a fully parametric method, the DP method is semi-parametric, and the LRT method uses
a nonparametric approach to obtain the p-values. The results from the sB method may be biased to the
misspecified parametric distribution.
5.4. Bayesian model selection
To assess the model fit, we use a Bayesian model selection approach based on the log pseudo-marginal
likelihood (LPML) to compare the DP and sB methods. The LPML is defined as the sum of the logs
(logarithms) of the conditional predictive ordinate (CPO) [31, 32]. The LPML has been extensively used
for model diagnostic and assessment in the published literature [33]. For a fixed drug j∗ and each AE i
associated with this drug, the CPO is defined as
(
)
[ (
)
]
CPOij∗ = P nij∗ |n−i,j∗ = E𝜃 P nij∗ |𝜇ij∗ |n−i,j∗ ,
where n−i,j∗ = (n1j∗ ,…,ni−1,j∗ ,ni+1,j∗ ,…,nIj∗ ) denote the observations in the j∗ th column with the ith observation
deleted and 𝜃 denotes all unobservables in the model under consideration and the expectation is taken
with respect to the posterior of 𝜃 given n−i,j∗ . Thus, the LPML for the j∗ th drug is
LPMLj∗ =

I
∑

)
(
log CPOij∗ .

i=1

A Monte Carlo estimate of the CPO statistic is presented in detail by Chen et al. [32]. It is provided
̂ ij∗ is the
by the harmonic mean of the likelihood. Specifically, based on M MCMC iterations, the CPO
inverse of the posterior mean of the inverse likelihood of nij∗ and is computed as follows:
−1

̂ ij∗
CPO

⎤
⎡
M
⎥
⎢1 ∑
1
=⎢
(
)⎥
|
(b)
M
⎢ b=1 p nij∗ |𝜇ij∗ ⎥
|
⎦
⎣

,

∕Eij∗ . The model with the larger LPML value is preferred.
where 𝜇ij(b)∗ = 𝜆(b)
ij∗
The Bayes factor is another popular method for model comparison, which gives a summary of the
evidence of one model against another provided by the data. But it is difficult to compute when the model
involves the DP. One alternative approximation is the pseudo-Bayes factor (PsBF) [34]. It is a surrogate
for the Bayes factor [35] based on the CPO for comparing the two models DP and sB. The PsBF for the
j∗ th drug is defined as
PsBFj∗ (DP, sB) =

I
∏
CPOij∗ (DP)
i=1

CPOij∗ (sB)

.

Usually, 2 log10 (PsBF) is used. A larger value of PsBF(DP, sB) indicates the evidence in favor of the DP
model. In this section, LPML and PsBF are both used to compare the DP and sB models. We did not use
the deviance information criterion, introduced by Spiegelhalter et al. [36], as it requires the knowledge
of model complexity, which depends on the average values for all parameters in the model. However, this
is unknown in the case of the DP model.
The estimated LPML values along with the PsBF values for the DP and sB models under different
scenarios are reported in Table VII. Both the LPML and PsBF model selection criteria select the DP
model in all scenarios.

6. Application to the adverse event reporting system database

2736

To illustrate an application of the proposed methods, we apply the methods presented in Sections 3 and
4 to analyze the reports in the AERS database collected from the first quarter of 2006 to the last quarter
of 2011 with suspected and concomitant drugs. In this specific AERS database, there are 14,415 AEs
associated with 6928 drugs, and a total of 26,883,994 report cases are collected. In this real-data analysis,
we will not substantiate any signals detected by means of credible clinical gold standard and will not
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

N. HU, L. HUANG AND R. C. TIWARI

Table VII. Summary of model selection.
Dataset

rr

Model

3

DP
sB
DP
sB
DP
sB

−398,025.8
−573,772.6
−388,710.2
−562,932.1
−391,013.7
−576,181.9

DP
sB
DP
sB
DP
sB

−58,993.41
−80,619.78
−59,497.23
−80,870.78
−59,208.51
−80,840.74

5

Large

10

3
5

Moderate

10

LPML

PsBF
52,651.71
52,458.23
52,723.13

18,784.42
18,564.83
18,789.51

3

DP
21,337.4
19,433.52
−1,036.25
sB
5
DP
28,215.13
Small
25,380.99
sB
1,005.87
10
DP
32,110.45
27,411.97
sB
1,832.91
DP, Dirichlet process; LPML, log pseudo-marginal likelihood;
PsBF, pseudo-Bayes factor; sB, simplified Bayes.

Table VIII. Number of signals detected for drugs in statin drug class.
Generic name

n⋅j

No. of AEs

DP

ZIP-DP

sB

ZIP-sB

MGPS

BCPNN

PRR

LRT

Atorvastatin
243,510
5,230
42
40
81
71
225
561
905
176
Fluvastatin
12,342
1,952
24
22
36
25
100
168
670
27
Lovastatin
26,990
2,251
6
0
7
5
85
196
556
23
Rosuvastatin
99,987
3,351
66
56
102
88
86
405
801
156
Simvastatin
210,354
5,006
61
60
45
35
259
508
838
127
AEs, adverse events; BCPNN, Bayesian confidence propagating neural network; DP, Dirichlet process; LRT, likelihood ratio test; MGPS, multi-item gamma Poisson shrinker; PRR, proportional reporting ratio; sB, simplified Bayes;
ZIP, zero-inflated Poisson.

Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

2737

apply clinical interpretations to evaluate the plausibility of the detected signals, including limitations
imposed by confounding by indications, which is a big challenge with the AERS data.
We select the ‘statin’ drug class including atorvastatin, fluvastatin, lovastatin, rosuvastatin, and
simvastatin. They have been widely used to lower the cholesterol levels by inhibiting the enzyme
3-hydroxy-3-methyl-glutaryl-coenzyme A reductase, which plays a central role in the production of
cholesterol in the liver. Increased cholesterol levels have been associated with cardiovascular disease, and
statins are therefore used in the prevention of these disease. We apply the proposed DP method along with
the SB, BCPNN, PRR, and LRT methods to each statin drug, in order to identify the AEs with unusually high reporting rates within each drug. Table VIII displays the total number of report cases collected
for the drug during 2006–2011, the number of AEs associated with the drug, and the number of signals
detected by the DP, SB, BCPNN, PRR, and LRT. The table also displays the number of common signals
detected by all of the five methods.
The results are consistent with the information obtained from the simulation study. The BCPNN and
PRR methods detect many more signals than did other methods. The LRT and sB methods detect much
less signals. Because LRT has been theoretically proved to have well-controlled type-I error and FDR,
it is possible that many of the extra signals detected by BCPNN and PRR methods are false-positive
signals. The proposed DP method detects the least number of signals (most conservative), and most of
the signals detected by the DP method are also detected by all other methods (e.g., for atorvastatin, all
the 42 signals detected by DP are the common signals detected by all other methods).

N. HU, L. HUANG AND R. C. TIWARI

7. Discussion

2738

In this paper, we proposed a new Bayesian method, using the DP prior, as a data-mining tool for screening
very large, sparse-frequency tables such as the AERS database. This method, in addition to existing
frequentist and Bayesian methods, is expected to greatly improve the work efficiency of safety reviewers,
compared with traditional methods of manually reviewing the reports. As shown, through simulation
study, both the PRR and BCPNN methods have high ST and detect a larger set of possible signals, but they
also burden the work load in order to investigate the false-positive signal detected because of their high
FDR. The sB method performs better than both BCPNN and PRR. We also included the performance of
HsB in the Bayesian model selection along with the sB and DP methods but did not report the results in
Table VII. We observed that HsB performed better than sB for small and moderate sample datasets, but
sB performed better than HsB for large datasets. We also compared the performance of the proposed DP
method with the frequentist LRT method in the simulation and application. The LRT method has been
theoretically proved to control FDR, but the DP method tends to be more conservative, with lower values
of FDR and ST.
In addition, the nonparametric nature of the DP model helps in clustering the AEs within each drug.
The samples from DP are discrete with probability 1, and distinct values drawn from the output distributions represent different clusters of AE. For example, in the application, there are 7, 9, 2, 13, and 15
clusters (with parameter 𝜆 values ranging from 2 to 5) detected for atorvastatin, fluvastatin, lovastatin,
rosuvastatin, and simvastatin, respectively (results are not shown). The number of AEs in each cluster
ranges from one to hundreds, and the AEs in the same cluster indicate possible common features.
One advantage of the nonparametric method (DP method) compared with other Bayesian methods is
that it is robust to the underlying data distribution. The performance of the DP method is robust when
data are generated from a multinomial distribution or from a mixture of distributions. However, both the
sB and BCPNN methods have worse performance when the underlined distribution is misspecified (such
as the mixture distribution as specified in Section 5).
The Bayesian Poisson–DP method use the posterior estimates of the reporting rates of AEs (for a given
drug of interest) to define signals, whereas the LRT compares their reporting rates and finds the ones that
have the likelihood of being significantly large (compared with others). The Bayesian methods provide
signals from different aspects (based on the lower bound of the credible interval exceeding a threshold
value) compared with LRT method (testing the null hypothesis that the relative reporting rates for all AEs
are the same versus the alternative that for at least one AE the relative reporting rate is greater than that
for others). Thus, the two approaches of the signal detection are not the same. They both can be used side
by side, and the totality of the evidence, in terms of the common signals, from the two methods can be
the basis for their further validation. In addition, the DP method can be applied to the entire I × J matrix
of the AERS data or to a sub-matrix selected with some restrictions based on clinical input.
For the selection of baseline distribution in the DP prior for 𝜆ij ’s, a single gamma (DP-SG) distribution
with mean 1 is not the only choice. We can try some other baseline distributions such as a mixture gamma
(DP-MG) distribution, with some positive mass at 𝜆ij = 1, that is, G0 = 𝜋I{1} + (1 − 𝜋)Gamma(𝛼, 𝛼); a
lognormal (DP-LN) distribution, that is, 𝜆∗ij = log(𝜆ij ), 𝜆∗ij |G ∼ G, G ∼ DP(𝜌, G0 ), G0 = (𝜇, 𝜎 2 );
and a mixture lognormal distribution with a spike-and-slab baseline, G0 = 𝜋I{0} + (1 − 𝜋)N(𝜇, 𝜎 2 ). In
the simulation study, we compared the performance of these models (results not shown here). Generally,
the DP-LN detects more signals than the other compared models. The DP-MG has much less signals
compared with the DP-SG, and the posterior mean of parameter 𝜋 is close to 1, which indicates high
mass at point 𝜆 = 1. In this case, some signals are smoothed to 1, which may not be detected. Another
extension of the proposed DP model is to use the hierarchical DP model, when 𝜆ij∗ (j∗ fixed) has DP
prior D(𝜂, Hj∗ ) with precision parameter 𝜂 and the baseline distributions Hj∗ have DP prior D(𝜌, H0 ). As
described in Section 4, one may work with the Poisson–DP model for the entire I × J table (similar to
the MGPS model) rather than by each single drug. However, just as is the case with MGPS, one cannot
assess the performance of this model, by a simulation study, as it is impossible to generate the I × J table
with the row and column marginal totals fixed.
As for the threshold, some of the existing methods use arbitrary thresholds for signal detection where
decision rules are not defined by any error-limiting constraint (such as cutoffs from a normal distribution).
We can also use the lower bound of 90% or 99% confidence intervals as the cutoff score of disproportionate rate instead of 95%. Also, there are some suggestions in the published literature about using joint
criteria such as a lower bound greater than 0 and a cell count nij greater than 2 [37]. Hauben et al. [37]
performed a small simulation study suggesting that this additional criterion may reduce the number of
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

N. HU, L. HUANG AND R. C. TIWARI

signals detected and may in turn reduce the FDR. When we evaluated the performance of the DP method,
we also tried some other threshold such as 1.64 and 1. Because the DP method (with a threshold of 2) is
very conservative, there is no need to increase the threshold greater than 2. When we lowered the threshold to 1.64, as expected, it increased the ST slightly, especially for sparse data and low relative reporting
rates. A threshold of lower than 1 was not appropriate, as it resulted in too many false-positive signals.
Finally, for many drugs in large safety observational databases (e.g., the AERS database), there are a
large number of cells with zero count. For example, there are 64%, 86%, 84%, 77%, and 65% of the cells
with zeros observed for atorvastatin, fluvastatin, lovastatin, rosuvastatin, and simvastatin, respectively, in
the 2006–2011 AERS data used in the application. To handle the extra zeros, the proposed Poisson–DP
model can be extended to the ZIP-DP model. A similar extension can be performed for the sB model
(the new model is the ZIP-sB model). The ZIP models are more conservative with the adjustment of the
possible true zero cells. More details on the formulation of ZIP models are given in the Appendix, and
their application to the statin data is given in Table VIII. Fewer numbers of signals were detected by ZIP
models, and almost all the signals from the ZIP-DP model are overlapped with those from the DP model;
and a similar pattern is observed for ZIP-sB and sB.
In summary, the DP method being a nonparametric procedure is more robust and conservative compared with other Bayesian methods studied in detecting safety signals. We suggest that safety evaluators
use the DP and other Bayesian methods and compare the results with the frequentist’s LRT method. Note
that these methods are only signal-generating methods and do not necessarily establish any causality for
the signals identified. The ZIP model can be used when the counts are rare and there are many zeros.

Appendix A: Likelihood function, posterior of 𝜃, and conditional distributions
The likelihood function and the posterior distribution of 𝜽 are
L(data|𝜽) =

J
I
∏
∏

p(nij |𝜽)

i=1 j=1

∝

I
J
∏
∏
exp(−𝜆ij Eij )(𝜆ij Eij )nij
i=1 j=1

nij !

,

𝜋post (𝜽|data) = L(data|𝜽)𝜋(𝜽)
=

I
J
∏
∏

p(nij |𝜽)𝜋(𝜆ij , i = 1, ..., I, j = 1, ..., J|𝛼j , 𝜌j )𝜋(𝛼j )𝜋(𝜌j ).

i=1 j=1

Then, the (full) conditional distributions of all the parameters are as derived in the following:
𝜋(𝜆ij |rest) ∝ p(nij |𝜆ij , 𝛼j , 𝜌j )𝜋(𝜆i′ j′ , (i′ , j′ ) ≠ (i, j), 𝛼j , 𝜌j )
Lij
⎞
∑
𝜌j
exp(−𝜆ij Eij )(𝜆ij Eij )nij ⎛
1
⎜
g(𝜆ij |𝛼j , 𝛼j ) +
pijl 𝛿𝜆∗ (d𝜆ij )⎟
∝
ijl
⎜ 𝜌j + IJ − 1
⎟
nij !
𝜌j + IJ − 1 l=1
⎝
⎠
(
)(
)𝛼j (
)nij
𝛼
E
𝜌j
𝛼 n + 𝛼j − 1
j
ij
g(𝜆ij |𝛼j + nij , 𝛼j + Eij )
Eijj ij
∝
𝜌j + IJ − 1
𝛼j + Eij
𝛼j + nij
𝛼j
)
(
Lij
exp −𝜆∗ijl Eij (𝜆∗ijl Eij )nij
∑
1
p
+
𝜌j + IJ − 1 l=1 ijl
nij !

Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

2739

Lij
I ⎛
⎞
∏
∑
𝜌j
1
⎜
g(𝜆ij |𝛼j , 𝛼j ) +
pijl 𝛿𝜆∗ (d𝜆ij ) ⎟ 𝛿(0,1) (𝛼j )
𝜋(𝛼j |rest) =
ijl
⎜ 𝜌 + IJ − 1
⎟
𝜌j + IJ − 1 l=1
i=1 ⎝ j
⎠
Lij
I ⎛
⎞
∏
∑
𝜌j
1
⎜
g(𝜆ij |𝛼j , 𝛼j ) +
pijl 𝛿𝜆∗ (d𝜆ij ) ⎟ 𝛿(0.2,10) (𝜌j ),
𝜋(𝜌j |rest) =
ijl
⎜ 𝜌 + IJ − 1
⎟
𝜌j + IJ − 1 l=1
i=1 ⎝ j
⎠

N. HU, L. HUANG AND R. C. TIWARI
𝛼

𝛼j

𝛼 −1

where g(𝜆ij |𝛼j , 𝛼j ) = Γ(𝛼j ) exp(−𝜆ij 𝛼j )𝜆ijj .
j
An MCMC procedure, such as the Gibbs sampling, can be implemented, on these conditionals to draw
samples from the posterior distribution of 𝜽.

Appendix B: Zero-inflated Poisson Bayesian models
Most of the Bayesian methods assume that the count follows a Poisson distribution. However, some drugs
in the AERS database contain a large number of zero cells, and some cells will never have a count bigger
than 0 owing to the nature of the particular drug and AE. In such a situation, one may use the ZIP model.
The ZIP model includes a proportion p0 of true zeros and a proportion (1 − p0 ) × (e−𝜆ij Eij ) of zeros coming
from the Poisson distribution, Poisson(𝜆ij Eij ). That is,
{
nij =

0
with probability p0
.
Poisson(𝜆ij Eij ) with probability (1 − p0 )

In the Bayesian approach (ZIP-sB or ZIP-DP method), the probability p0 can be assigned a fixed value
or a beta prior, and 𝜆ij , as before, the DP prior.
For the ZIP-sB model, we have 𝜆ij ∼ Gamma(𝛼, 𝛼) and p0 ∼ Beta(a, b). Then P(nij = n|p, 𝜆ij , Eij ) =
p0 I(n = 0) + (1 − p0 )P(n ∗ij = n|𝜆ij , Eij ), where 0 < p0 < 1 and n ∗ij ∼ Poisson(𝜆ij Eij ). Let zij be the latent
variable corresponding to nij ; the complete likelihood function is
L(z, n|p, 𝜆, E) =

∏∏
i

m

= p0 0 (1 − p0 )m−m0

z
p0ij

{
(1 − p0 )

j

exp(−𝜆ij Eij )(𝜆ij Eij )nij
nij !

∏ exp(−𝜆ij Eij )(𝜆ij Eij )nij ∏
nij >0

nij !

}1−zij

(exp(−𝜆ij Eij ))1−zij ,

nij =0

∑
where m = IJ and m0 = i,j zij .
In context of ZIP-sB method, when 𝛼 is fixed, Gibbs sampling for the latent variable zij , p, and 𝜆ij has
standard conditionals given by
{
zij |(nij = 0, 𝜆ij , Eij , p0 ) ∼ Bernoulli

p0
p0 + (1 − p0 )exp(−𝜆ij Eij )

}
,

p0 |(zij , i = 1, · · · , I, j = 1, · · · , J) ∼ Beta(a + m0 , b + m − m0 ),
𝜆ij |(zij , Eij , nij ) ∼ Gamma(𝛼 + nij , 𝛼 + Eij (1 − zij )).
When 𝛼 is not fixed and assume that 𝛼 ∼ Uniform(c, d), zij , 𝜆ij and p are the same as the 𝛼 fixed case,
and additionally
{
𝛼|(𝜆ij , Eij ) ∼ exp

∑
− [(𝛼 + Eij )𝜆ij − (nij + 𝛼)ln𝜆ij ]

}
I(c < 𝛼 < d).

i,j

The ZIP-DP model can be implemented by first generating the latent variables zij and p0 as above and
then conditional on zij , generating the 𝜆ij , 𝛼j and 𝜌j as given in Appendix Section 4 and Appendix A.

2740

Acknowledgements
The authors wish to thank the Associate Editor and the two referees for their valuable comments.
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

N. HU, L. HUANG AND R. C. TIWARI

References

Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

2741

1. Evans SJ, Waller PC, Davis S. Use of proportional reporting ratios (PRRs) for signal generation from spontaneous adverse
drug reaction reports. Pharmacoepidemiology and Drug Safety 2001; 10(6):483–486.
2. Rothman KJ, Lanes S, Sacks ST. The reporting odds ratio and its advantages over the proportional reporting ratio.
Pharmacoepidemiology and Drug Safety 2004; 13(8):519–523.
3. Yule GU, Kendall MG. An Introduction to the Theory of Statistics 14th ed. Griffin: London, 1957, 30.
4. Greenwood PE, Nikulin MS. A Guide to Chi-Squared Testing. Wiley: New York, 1996.
5. Tubert P, Begaud B, Pere JC, Haramburu F, Lellouch J. Power and weakness of spontaneous reporting: a probabilistic
approach. Journal of Clinical Epidemiology 1992; 45(3):283–286.
6. Huang L, Zalkikar J, Tiwari RC. A likelihood ratio test based method for signal detection with application to FDA’s drug
safety data. Journal of the American Statistical Association 2011; 106(496):1230–1241.
7. Huang L, Zalkikar J, Tiwari RC. Likelihood ratio tests for longitudinal drug safety data. Statistics in Medicine 2014;
33(14):2408–2424.
8. Bate A, Lindquist M, Edwards IR, Olsson S, Orre R, Lansner A, De Freitas RM. A Bayesian neural network method for
adverse drug reaction signal generation. European Journal of Clinical Pharmacology 1998; 54(4):315–321.
9. Noren GN, Bate A, Orre R, Edwards IR. Extending the methods used to screen the WHO drug safety database towards
analysis of complex associations and improved accuracy for rare events. Statistics in Medicine 2006; 25(21):3740–3757.
10. DuMouchel W. Bayesian data mining in large frequency tables, with an application to the FDA spontaneous reporting
system. The American Statistician 1999; 53(3):177–190.
11. DuMouchel W, Pregibon D. Empirical Bayes screening for multi-item associations. Proceedings of the Seventh ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD’01, San Francisco, CA, 2001,
67–76. DOI: 10.1145/502512.502526.
12. Huang L, Zalkikar J, Tiwari RC. Likelihood ratio test based method for signal detection in drug classes using FDA’s AERS
database. Journal of Biopharmaceutical Statistics 2013; 23(1):178–200.
13. Van Puijenbroek EP, Bate A, Leufkens HG, Lindquist M, Orre R, Egberts AC. A comparison of measures of disproportionality for signal detection in spontaneous reporting systems for adverse drug reactions. Pharmacoepidemiology and Drug
Safety 2002; 11(1):3–10.
14. Roux E, Thiessard F, Fourrier A, Begaud B, Tuber-Bitter P. Evaluation of statistical association measures for the automatic signal generation in pharmacovigilance. IEEE Transactions on Information Technology in Biomedicine 2005; 9(4):
518–527.
15. Spiegelhalter D, Grigg O, Kinsman R, Treasure T. Risk-adjusted sequential probability ratio tests: applications to bristol,
shipman and adult cardiac surgery. International journal for quality in health care 2003; 15(1):7–13.
16. Evans S. Sequential probability ratio tests applied to public health problems. Controlled Clinical Trials 2003; 24:67S.
17. Almenoff JS, Lacroix KK, Yuen NA, Fram D, DuMouchel W. Comparative performance of two quantitative safety
signalling methods: implications for use in a pharmacovigilance department. Drug Safety 2006; 29(10):875–887.
18. Ferguson TS. A Bayesian analysis of some nonparametric problems. The Annals of Statistics 1973; 1(2):209–230.
19. Blackwell D. Discreteness of Ferguson selections. The Annals of Statistics 1973; 1(2):356–358.
20. Blackwell D, MacQueen JB. Ferguson distributions via Polya urn schemes. The Annals of Statistics 1973; 1(2):353–355.
21. Basu D, Tiwari RC. A note on the Dirichlet Process. In Statistics and Probability: Essays in Honor of C. R. Rao. NorthHolland: New York, 1982; 89–103.
22. Sethuraman J, Tiwari RC. Convergence of Dirichlet measure and the interpretation of their parameters. Statistical Decisions
Theory and Related Topics III 1982; 2:305–315.
23. Sethuraman J. A constructive definition of Dirichlet priors. Statistica Sinica 1994; 4:639–650.
24. Huang L, Zheng D, Zalkikar J, Tiwari R. Zero-Inflated Poisson Model based Likelihood Ratio Test for Drug Safety Signal
Detection. Statistical Methods in Medical Research, published on line 2014. DOI: 10.1177/0962280214549590.
25. Hauben M, Aronson JK. Defining ‘signal’ and its subtypes in pharmacogivillence based on a systematic review of previous
definitions. Drug Safety 2009; 32(2):99–110.
26. Huang L, Guo T, Zalkikar J, Tiwari RC. A review of statistical methods for safety surveillance. Therapeutic Innovation &
Regulatory Science 2014; 48(1):98–108.
27. Pearl J. Probabilistic Reasoning in Intelligent Systems. San Francisco: Morgan Kaufmann, 1988.
28. Noren GN, Sundberg R, Bate A, Edwards IR. A statistical methodology for drug-drug interaction surveillance. Statistics
in Medicine 2008; 27(16):3057–3070.
29. Ishwaran H, James LF. Gibbs sampling methods for stick-breaking priors. Journal of the American Statistical Association
2001; 96(453):161–173.
30. Ishwaran H, James LF. Approximate Dirichlet process computing in finite normal mixtures: Smoothing and prior
information. Journal of Computational and Graphical Statistics 2002; 97:1154–1166.
31. Gelfand AE, Dey DK, Chang H. Model determination using predictive distributions with implementation via Samplingbased Methods (with discussion). In Bernado JM, Berger JO, Dawid AP and Smith AFM (eds.) Bayesian Statistics 1992;
4(16):147–167. Oxford: Oxford University Press.
32. Chen MH, Qi-man S, Joseph GI. Monte Carlo Methods in Bayesian Computation. Springer-Verlag Inc: Berlin, New York,
2000, Chapter 10.
33. Brown ER, Ibrahim JG. Bayesian approaches to joint cure-rate and longitudinal models with applications to cancer vaccine
trials. Biometrics 2003; 59(3):686–693.
34. Geisser S, Eddy WF. A predictive approach to model selection. Journal of the American Statistical Association 1979;
74(365):153–160.

N. HU, L. HUANG AND R. C. TIWARI
35. Gelfand AE. Model determination using sampling based methods. In Markov Chain Monte Carlo in Practice. Chapman &
Hall: London, 1996; 145–161.
36. Spiegelhalter DJ, Best NG, Carlin BP, Van der Linde A. Bayesian measures of model complexity and fit (with discussion).
Journal of the Royal Statistical Society, Series B 2002; 64(4):583–616.
37. Hauben M, Reich L, De Micco J, Kim K. Extreme duplication in the US FDA Adverse Events Reporting System data base.
Drug Safety 2007; 30(6):551–554.

2742
Copyright © 2015 John Wiley & Sons, Ltd.

Statist. Med. 2015, 34 2725–2742

