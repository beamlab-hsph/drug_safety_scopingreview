Drug Safety (2019) 42:743–750
https://doi.org/10.1007/s40264-018-00792-0

ORIGINAL RESEARCH ARTICLE

A Comparison Study of Algorithms to Detect Drug–Adverse
Event Associations: Frequentist, Bayesian, and Machine‑Learning
Approaches
Minh Pham1

· Feng Cheng2 · Kandethody Ramachandran1

Published online: 14 February 2019
© Springer Nature Switzerland AG 2019

Abstract
Introduction It is important to monitor the safety profile of drugs, and mining for strong associations between drugs and
adverse events is an effective and inexpensive method of post-marketing safety surveillance.
Objective The objective of our work was to compare the accuracy of both common and innovative methods of data mining
for pharmacovigilance purposes.
Methods We used the reference standard provided by the Observational Medical Outcomes Partnership, which contains
398 drug–adverse event pairs (165 positive controls, 233 negative controls). Ten methods and algorithms were applied to
the US FDA Adverse Event Reporting System data to investigate the 398 pairs. The ten methods include popular methods
in the pharmacovigilance literature, newly developed pharmacovigilance methods as at 2018, and popular methods in the
genome-wide association study literature. We compared their performance using the receiver operating characteristic (ROC)
plot, area under the curve (AUC), and Youden’s index.
Results The Bayesian confidence propagation neural network had the highest AUC overall. Monte Carlo expectation maximization, a method developed in 2018, had the second highest AUC and the highest Youden’s index, and performed very well
in terms of high specificity. The regression-adjusted gamma Poisson shrinkage model performed best under high-sensitivity
requirements.
Conclusion Our results will be useful to help choose a method for a given desired level of specificity. Methods popular in
the genome-wide association study literature did not perform well because of the sparsity of data and will need modification
before their properties can be used in the drug–adverse event association problem.

1 Introduction
Pharmacovigilance, initiated in response to the thalidomide
disaster [1], is the provision of safety signals for medicinerelated adverse events. However, clinical trials cannot provide comprehensive data on adverse events, especially events
* Feng Cheng
fcheng1@health.usf.edu
* Kandethody Ramachandran
ram@usf.edu
1

Department of Mathematics and Statistics, University
of South Florida, 4202 East Fowler Ave, CMC342, Tampa,
FL 33620, USA

2

Department of Pharmaceutical Sciences, College
of Pharmacy, University of South Florida, 12901 Bruce
B. Downs Blvd, MDC 30, Tampa, FL 33612, USA

Key Points
The Monte Carlo expectation maximization algorithm
performed best when a high level of specificity was
required.
The regression-adjusted gamma Poisson shrinkage
model performed best when a high level of sensitivity
was required.
Methods that worked for the genome-wide association study did not fit well into the drug–adverse event
problem.

Vol.:(0123456789)

744

that are rare or unknown. To overcome this challenge, spontaneous reporting systems have been implemented around
the world to provide rich sources of data for pharmacovigilance. For instance, VigiBase is the World Health Organization’s global database of individual case safety reports and
has collected more than 16 million reports of medicine- and
vaccine-related adverse events from its member states [2].
The US FDA Adverse Event Reporting System (FAERS)
has been in operation since 1968 and has collected over 17
million reports of pharmaceutical products globally and is
increasing by more than 300,000 reports each year [3]. The
gigantic and rapidly increasing size of spontaneous reporting
systems creates challenges for data mining.
Many methods and algorithms have been proposed to mine
for significant drug–adverse event associations since the late
1990s. The earliest proposed method was association rules
(AR), a machine-learning algorithm that originated from the
market-basket problem [4, 5] but was criticized for a lack of
statistical soundness [5] so is less commonly used than the
statistical methods. The most common statistical methods
used in the literature are the frequentist approaches—such
as the proportional reporting ratio (PRR) and the reporting odds ratio (ROR) [6–8]—and the Bayesian approaches,
such as the gamma Poisson shrinkage (GPS) model [9, 10]
and the Bayesian confidence propagation neural network
(BCPNN) [11]. To deal with multi-pharmacy problems,
such as drug–drug interactions and commonly co-prescribed
drugs, DuMouchel et al. [12] applied logistic regression (LR)
to the FAERS database in 2008. In 2012, DuMouchel and
Harpaz [13] proposed the regression-adjusted GPS (RGPS)
algorithm, which is a hybrid of LR and the GPS model. In
2018, Xiao et al. [14] also proposed a modified version of
the GPS model, the Monte Carlo expectation maximization
(MCEM), to cope with the multi-pharmacy problem. Xiao
et al. [14] assumed that each adverse event in each case report
is caused by only one medicine and then iteratively modified the sample based on GPS signals (expectation step) and
recalculated the GPS signals (maximization step). To our
knowledge, RGPS and MCEM are the latest developments
for the drug–adverse event association study problem. Nevertheless, detecting drug–drug interactions remains a challenge.
DuMouchel’s multi-item GPS model [10] and LR can both
evaluate drug–drug interactions, but they require the interaction terms to be specified in the model. This may be laborious
if a large number of drugs are of interest.
We wanted to apply methods to the drug–adverse event
problem that have performed well in the genome-wide association study (GWAS) problem, the objective of which is to
mine for associations between genetic variants and traits.
Random forests (RF) and Monte Carlo logic regression
(MCLR) have proven effective in detecting significant main
effects as well as interactions in GWAS [15–19]. According to Witte and Fijal [20], MCLR was the only one of ten

M. Pham et al.

approaches to identify all correct associations between
genetic sequences and a disease, including the interactions
between genetic sequences. If these methods are proven to
work properly to identify drug–adverse event associations,
applying them to the identification of drug–drug interactions
that cause adverse events is a viable and interesting option.
The objective of this study was to perform an equitable comparison study of the ability of all these methods to accurately
detect drug–adverse event associations. This includes frequentist statistical methods (PRR and ROR), Bayesian methods
(GPS and BCPNN), multivariate methods (LR, RGPS, and
MCEM), and machine-learning algorithms (AR, RF, and
MCLR). The reference standards and evaluation metrics used
in this paper are similar to those in the study by Harpaz et al.
[21] but are performed on a wider range and more up-to-date
algorithms and on a more recent set of FAERS data. The background to and details of the algorithms’ strengths and weaknesses are discussed in Pham [22]. We were also interested
in the algorithms’ performance in the detection of drug–drug
interactions responsible for adverse events, but the first priority
was to conduct a comparison study on drug–adverse event associations to evaluate the fitness of the uncommon methods for
this particular problem (MCEM, RF, and MCLR). Therefore,
this study focuses on comparing the algorithms and their ability
to detect drug–adverse event associations. Another comparison
study on drug–drug interactions may be suggested for future
work depending on the results of this study.

2 Materials and Methods
2.1 True Ground for Testing
The Observational Medical Outcomes Partnership (OMOP)
provided a large test set comprising 398 drug–adverse event
pairs (165 positive controls and 233 negative controls) [23].
Positive controls were determined if the event was included
in the product label, observational database research had
previously suggested an association, and an expert panel
agreed with this allocation. Negative controls were determined if the association was absent from the product label
and the published literature and an expert panel endorsed
this allocation. The 398 drug–event pairs included four distinct adverse events (acute kidney injury, acute liver injury,
acute myocardial infarction, and gastrointestinal bleed) and
183 distinct drugs.

2.2 Data
The FAERS quarterly submissions from the second quarter of 2014 to the fourth quarter of 2017 were combined
into a local database. We then removed duplicates using the

745

Comparison of Algorithms to Detect Drug–Adverse Event Associations

drug table’s “primaryid” and drug sequence (“drug_seq”).
Finally, we filtered out cases that contained at least one of
the 183 drugs or at least one of the four adverse events in the
OMOP testing set. Ideally, this filter should not be applied
and we should be using all the drugs and adverse events
from the database. However, obtaining the entire list of
drugs from FAERS is impossible because the drugs for one
case are concatenated in a string without a clear separator.
For example, one case has “.ALPHA.-TOCOPHEROL ACETATE, DL-\ASCORBIC ACID\CYANOCOBALAMIN\
FLUORIDE ION\FOLIC ACID\NIACIN\PYRIDOXINE\
RIBOFLAVIN\THIAMINE\VITAMIN A\VITAMIN D” as
drugs taken and another case has “ESTROGENS, CONJUGATED”. Therefore, the most feasible way to extract data
from the database was to check whether the case contained
one of the drug names in which we were interested. The
final dataset contained 418,852 cases. Only 224 of the 398
testing pairs had at least one case report. All 224 of the testing pairs were coded into binary outcome (with or without
association). The goal for the algorithms was to classify each
pair as being with or without an association. The receiver
operating characteristic (ROC) curve was obtained by tuning
the decision threshold for each algorithm and recording both
the false-positive and the true-negative rate.

2.3 Data Mining Methods and Algorithms
The following methods and algorithms were applied to the
dataset:
• Frequentist statistical methods: PRR and ROR. For each

drug–adverse event pair, we constructed a contingency
table (Table 1). PRR and ROR could then be calculated
as:
	 
a∕(a + c)
PRR =
b∕(b + d)

	 
a∕c
ROR =
b∕d
	  Then,(the confidence interval of) PRR could be calcu( )
, PRR ∗ exp z𝛼 s , where zα is a critical
lated as expPRR
z
s
(𝛼)
value from the standard normal distribution and

Table 1  Contingency table constructed for each drug–adverse event
pair

Effect
Other effects

Drug

Other drugs

a
c

b
d

√

. The confidence interval for
log (ROR)±(z𝛼 ∗s)
, where
ROR
√ was calculated as e
1
1
1
1
s = a + b + c + d . A drug–adverse event pair was

s=

1
a

+

1
c

−

1
a+b

−

1
c+d

determined to have a significant association if the lower
bound of the confidence interval of PRR or ROR was > 1.
We repeated this process for α in the set {0.01, 0.02,
0.03, …, 1} to obtain a series of pairs of sensitivity and
specificity.
• Bayesian statistical methods: GPS and BCPNN. The calculation of the GPS statistic can be found in DuMouchel
and Pregibon [10]. The calculation of BCPNN can be
found in Bate et al. [11]. For GPS, we calculated the x­ th
percentile of the posterior distribution (x is a threshold to
obtain ROC) and classed an association as significant if
the percentile was > 1. For BCPNN, we calculated the xth
percentile of the posterior distribution and determined an
association as significant if the percentile was > 0. We
repeated this process with x in the set {1, 2, 3, … 100}
to obtain a series of pairs of sensitivity and specificity.
• Multivariate methods: LR, RGPS, and MCEM.
– For LR, we created a dummy variable for each
drug (1 if drug existed in a case, 0 otherwise) and
a dummy variable for each adverse event (1 if event
existed in a case, 0 otherwise). We then fit four LR
models, each using a drug as a predicted variable
and the dummy variables of drugs as predictors. The
significance of each drug was tested with the t-test.
A drug–adverse event was classed as significant if
the drug’s coefficient in the model for that adverse
event was significant. We repeated this process for
p-values in the set {0.01, 0.02, 0.03,…, 1} to obtain
a series of pairs of sensitivity and specificity.
– For RGPS, as described in DuMouchel and Harpaz
[13], we first fit the LR models as described. Then,
we used the models to predict adverse events for each
case (i.e., each row) and used these predictions to
calculate the expected count for each drug–adverse
event pair. These expected counts were then used
in the regular GPS model instead of the expected
counts that were calculated based on the assumption
of independence between drugs and adverse events.
The rest of the process followed the GPS process.
– For MCEM, we followed the iterative procedure
described in Xiao et al. [14]. Simply put, we first
created a GPS model that used counts of drug–
adverse event pairs as input. Then, we iteratively
changed the drugs taken in each case in the database according to the GPS model and recalculated
the GPS model. Upon convergence, we used the
converged GPS model to determine associations.

746

M. Pham et al.

• Machine-learning methods: AR, RF, and MCLR.

– For AR, for each drug–adverse event pair, we
calculated “support”, which is the proportion of
data that observes both the given drug and adverse
event, and “confidence”, which is the proportion
of data that has the drug, given the adverse event.
Confidence being larger than a threshold determined that the association existed between the pair.
We repeated this process for confidence in the set
{1, 0.99, 0.98, …, 0.01} to obtain a series of pairs
of sensitivity and specificity.
– For RF, the implementation was similar to that
with LR. We fit four RF models, each using a drug
as predicted variable and the dummy variables of
drugs as predictors. The variable importance of
each drug in a model was used to rank the strength
of association between drugs and the adverse event.
Association with an adverse event was determined
by taking a number of top drugs in the ranking.
– For MCLR, the implementation was also similar to
that with LR. For each adverse event, we generated
a number of LRs with variable selection following
the Monte Carlo approach described in Kooperberg
and Ruczinski [19]. The appearance of each drug
in the models was then counted and ranked. Association with an adverse event was determined by
taking a number of top drugs in the ranking.
We used the entire dataset to train the methods that
usually require separate training and evaluation, such as
RF and LR. This is because we were interested in the significance of the drugs in each model rather than the performance of the model. In addition, some drug–adverse event
pairs had only a few observations. Splitting the data into
training and evaluation may have affected the significance

Fig. 1  Receiver Operating Characteristic curves for frequentist
methods

of a rare drug in a model in return for a level of model
performance that we did not need.
Although we classify RGPS and MCEM as multivariate
methods, they both use a Bayesian approach. The thresholds used to determine significant associations are not
comparable. For example, the threshold α of ROR and the
threshold p-value in LR both represent the probability of
the tail distribution, but the same level of α and p-value
may not give us the same sensitivity because the distribution in ROR and in LR differ. We used a range of thresholds for each method simply to obtain series of sensitivity
and specificity.
All of these methods, except for RGPS and MCEM, are
publicly available in R packages. We programmed RGPS
and MCEM in R and have made the source code available
at https​://githu​b.com/minhh​pham/Multi​Pharm​a.
For each method, we plotted the ROC curve, calculated
the area under the curve (AUC), and found the optimal
sensitivity and specificity level using Youden’s index. The
ROC curve is created by plotting the true-positive rate (i.e.,
algorithm detects an association, given that the association
exists) against the false-positive rate (i.e., algorithm detects
an association, given that the association does not exist).
A ROC curve that lies in a straight line from (0,0) to (1,1)
shows performance equal to random guess. The higher above
the ROC curve compared with the (0,0)–(1,1) line, the better an algorithm performs. AUC is simply the area covered
by the ROC, the x-axis, and the vertical line at x = 1. The
higher the AUC, the better an algorithm performs. Youden’s
index can be calculated as follows: We first calculated (truepositive rate − false-positive rate) for each point on the ROC.
The maximum of these values is Youden’s index, and the
position of Youden’s index suggests the best cut-off point
of the decision threshold for an algorithm.

Comparison of Algorithms to Detect Drug–Adverse Event Associations

3 Results
The ROC for the two frequentist statistical methods are
plotted in Fig. 1. ROR generally performed better than
PRR. The ROC for the two Bayesian statistical methods are
Fig. 2  Receiver Operating
Characteristic curves for Bayesian methods

Fig. 3  Receiver Operating
Characteristic curves for multivariate methods

Fig. 4  Receiver Operating Characteristic curves for machine
learning methods

747

plotted in Fig. 2. BCPNN generally performed better than
GPS. The ROC for the three multivariate methods are plotted in Fig. 3. LR generally performed worse than the other
two. MCEM has higher sensitivity at high specificity points
(> 0.6 specificity), whereas RGPS had higher sensitivity at

748

M. Pham et al.

Fig. 5  Receiver Operating
Characteristic curves for all
methods

Table 2  Area under the
curve, optimal sensitivity and
specificity, and maximum
Youden’s index, sorted in
descending order of area under
the curve

Method

Area under Youden’s
the curve
sensitivity

Youden’s
specificity

Youden’s index

Bayesian confidence propagation neural network
Monte Carlo expectation maximization
Gamma Poisson shrinkage
Association rules
Regression-adjusted gamma Poisson shrinkage
Reporting odds ratio
Logistic regression
Proportional reporting ratio
Monte Carlo logic regression
Random forests

0.6939
0.6830
0.6803
0.6700
0.6681
0.6653
0.6604
0.6514
0.5850
0.5208

0.6847
0.9099
0.6306
0.7477
0.8378
0.6577
0.4595
0.5856
0.8198
0.9369

0.3396
0.4409
0.2943
0.3141
0.3099
0.3125
0.2648
0.2936
0.1807
0.1051

low specificity points (< 0.6 specificity). The ROC for the
three machine-learning methods are plotted in Fig. 4. AR
performed the best, whereas RF was barely better than a
random guess. The ROC curves for all methods are plotted
in Fig. 5.
AUC, optimal sensitivity and specificity, and maximum
Youden’s index are presented in Table 2.

4 Discussion
Our comparison study yielded some interesting results.
First, statistical methods based on a Bayesian approach are
superior to frequentist and machine-learning approaches.
BCPNN, a quasi-Bayesian approach, and GPS, an empirical Bayes model, had the highest and third-highest AUC.
MCEM, a multivariate approach developed based on GPS,
had the second-highest AUC and the highest Youden’s
index. We expected Bayesian methods to be revealed as
superior to frequentist methods, because many drug–adverse
event pairs have small counts in the FAERS database. The
small samples create a critical violation to PRR and ROR’s

0.6549
0.5310
0.6637
0.5664
0.4720
0.6549
0.8053
0.7080
0.3609
0.1681

assumption of normality. Our findings are similar to those
of Harpaz et al. [21] in that the performances of PRR and
ROR were similar and that GPS outperformed both of them.
Second, the two machine-learning approaches, MCLR
and RF, did not perform well because certain of their
characteristics are unsuitable for this problem. For RF,
the sparseness in the drug–adverse event data caused problems for the bagging strategy because many bootstrapped
samples contained little or no information. For instance,
the adverse event gastrointestinal bleed had an occurrence
probability of 0.0000525 in our data (22 reported cases out
of 418,852). Since RFs create bootstrapped samples with
sizes equal to 0.7 × 418,852 = 293,196, some bootstrapped
samples would contain no information on gastrointestinal
bleed. The naïve Bayes classifier is less affected by sparse
data than other common classification algorithms [24–26].
Applying naïve Bayes to this problem will be an interesting future development.
Third, the two multivariate methods, MCEM and RGPS,
performed well on the high and the low end of specificity,
respectively. MCEM had the highest sensitivity among all
methods when specificity was > 0.7. RGPS had the highest

749

Comparison of Algorithms to Detect Drug–Adverse Event Associations

sensitivity among all methods when specificity was < 0.5.
This result may be used when needing to pick a method
given a desired level of specificity.
Finally, multi-pharmacy is a common concern in pharmacovigilance. Methods that rely on contingency tables,
such as BCPNN, GPS, ROR, and PRR, cannot be used to
detect drug–drug interactions. Nor can they adjust for confounding factors such as commonly co-prescribed drugs and
demographic variables. For example, consider a drug with
a strong association with an adverse event; using univariate
methods, any other drug usually co-prescribed with that drug
will also be detected as having a strong association with the
adverse event. Since the multivariate methods MCEM and
RGPS show good performance on identifying drug–adverse
event associations, testing their performance in the detection
of drug–drug interactions is viable.

4.1 Study Limitations
The AUCs for BCPNN, MCEM, and GPS were quite close.
A limitation of using a reference set such as that of the
OMOP to evaluate performance is that the performance of
the algorithms depends on the characteristics of the pairs
in the reference set. In addition, we used the FAERS database, most of the data for which are collected from the USA.
Using a different reference set or database might result in
different performance characteristics.

5 Conclusions
To our knowledge, this is the most comprehensive comparison study in the pharmacovigilance literature, using popular methods and the latest developments up until 2018. The
results show that MCEM performs best when a high level
of specificity is required, and the RGPS model performed
best when a high level of sensitivity was required. The two
methods we borrowed from the GWAS have certain properties that do not fit well into the drug–adverse event problem
and will require modifications if their properties are to be
used in this area.

Compliance with Ethical Standards
Funding This project was funded by the Florida Department of
Health Ed and Ethel Moore Alzheimer’s Disease Research Program
(Grant number 7AZ23), and the University of South Florida Proposal
Enhancement Grant to Feng Cheng. These grants enabled all the
FAERS data submissions to be combined and stored in a local database.
Conflicts of interest Minh Pham, Feng Cheng, and Kandethody Ramachandran have no conflicts of interest that are directly relevant to
the content of this study.

References
1. Lawson DH. Pharmacovigilance in the 1990s. Br J Clin Pharmacol. 1997;44(2):109–10.
2. VigiBase. The WHO global ICSR Database system: basic facts.
Drug Inf J. 2008;42(5):409–19.
3. Szarfman A, Machado SG, O’neill RT. Use of screening algorithms and computer systems to efficiently signal higher-thanexpected combinations of drugs and events in the US FDA’s spontaneous reports database. Drug Safety. 2002;25(6):381–92.
4. Agrawal R, Imieliński T, Swami A (1993) Mining association
rules between sets of items in large databases. In: ACM sigmod
record, ACM.
5. Silverstein C, Brin S, Motwani R. Beyond market baskets: generalizing association rules to dependence rules. Data Min Knowl
Discov. 1998;2(1):39–68.
6. Evans S, Waller PC, Davis S. Use of proportional reporting ratios
(PRRs) for signal generation from spontaneous adverse drug reaction reports. Pharmacoepidemiol Drug Saf. 2001;10(6):483–6.
7. Rothman KJ, Lanes S, Sacks ST. The reporting odds ratio and its
advantages over the proportional reporting ratio. Pharmacoepidemiol Drug Saf. 2004;13(8):519–23.
8. Waller P, et al. The reporting odds ratio versus the proportional reporting ratio: ‘deuce’. Pharmacoepidemiol Drug Saf.
2004;13(8):525–6.
9. DuMouchel W. Bayesian data mining in large frequency tables,
with an application to the FDA spontaneous reporting system. Am
Stat. 1999;53(3):177–90.
10. DuMouchel W, Pregibon D. Empirical Bayes screening for multiitem associations. In: Proceedings of the seventh ACM SIGKDD
international conference on knowledge discovery and data mining,
ACM. 2001.
11. Bate A, et al. A Bayesian neural network method for adverse
drug reaction signal generation. Eur J Clin Pharmacol.
1998;54(4):315–21.
12. DuMouchel W, et al. Antipsychotics, glycemic disorders, and lifethreatening diabetic events: a Bayesian data-mining analysis of
the FDA adverse event reporting system (1968–2004). Ann Clin
Psychiatry. 2008;20(1):21–31.
13. DuMouchel W, Harpaz R. Regression-adjusted GPS algorithm
(RGPS). ORACLE Health Sciences; 2012.
14. Xiao C, et al. An MCEM framework for drug safety signal detection and combination from heterogeneous real world evidence. Sci
Rep. 2018;8(1):1806.
15. Chen X, Ishwaran H. Random forests for genomic data analysis.
Genomics. 2012;99(6):323–9.
16. Qi Y, Klein-Seetharaman J, Bar-Joseph Z. Random forest similarity for protein-protein interaction prediction from multiple
sources. In: Altman RB, editor. Biocomputing. Singapore: World
Scientific; 2005. pp. 531–42.
17. Li J, et al. Detecting gene-gene interactions using a permutationbased random forest method. BioData Min. 2016;9(1):14.
18. Ruczinski I, Kooperberg C, LeBlanc ML. Exploring interactions
in high-dimensional genomic data: an overview of logic regression, with applications. J Multivar Anal. 2004;90(1):178–95.
19. Kooperberg C, Ruczinski I. Identifying interacting SNPs
using Monte Carlo logic regression. Genet Epidemiol.
2005;28(2):157–70.
20. Witte JS, Fijal BA. Introduction: analysis of sequence data and
population structure. Genet Epidemiol. 2001;21(S1):S600–1.
21. Harpaz R, et al. Performance of pharmacovigilance signal-detection algorithms for the FDA adverse event reporting system. Clin
Pharmacol Ther. 2013;93(6):539–46.

750
22. Pham MH. Signal detection of adverse drug reaction using the
adverse event reporting system: literature review and novel methods. Tampa: University of South Florida; 2018.
23. Ryan PB, et al. Defining a reference set to support methodological
research in drug safety. Drug Saf. 2013;36(1):33–47.
24. Domingos P, Pazzani M. On the optimality of the simple Bayesian
classifier under zero-one loss. Mach Learn. 1997;29(2–3):103–30.

M. Pham et al.
25. Hand DJ, Yu K. Idiot’s Bayes—not so stupid after all? Int Stat
Rev. 2001;69(3):385–98.
26. Bermejo P, Gámez JA, Puerta JM. Speeding up incremental wrapper feature subset selection with Naive Bayes classifier. KnowlBased Syst. 2014;55:140–7.

