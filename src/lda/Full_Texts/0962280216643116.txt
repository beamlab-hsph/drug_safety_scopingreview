Article

Class-imbalanced subsampling lasso
algorithm for discovering adverse
drug reactions

Statistical Methods in Medical Research
2018, Vol. 27(3) 785–797
! The Author(s) 2016
Reprints and permissions:
sagepub.co.uk/journalsPermissions.nav
DOI: 10.1177/0962280216643116
journals.sagepub.com/home/smm

Ismaı̈l Ahmed,1,2,3 Antoine Pariente4,5,6 and Pascale Tubert-Bitter1,2,3

Abstract
Background: All methods routinely used to generate safety signals from pharmacovigilance databases rely on
disproportionality analyses of counts aggregating patients’ spontaneous reports. Recently, it was proposed to analyze
individual spontaneous reports directly using Bayesian lasso logistic regressions. Nevertheless, this raises the issue of
choosing an adequate regularization parameter in a variable selection framework while accounting for computational
constraints due to the high dimension of the data.
Purpose: Our main objective is to propose a method, which exploits the subsampling idea from Stability Selection, a
variable selection procedure combining subsampling with a high-dimensional selection algorithm, and adapts it to the
specificities of the spontaneous reporting data, the latter being characterized by their large size, their binary nature and
their sparsity.
Materials and method: Given the large imbalance existing between the presence and absence of a given adverse event,
we propose an alternative subsampling scheme to that of Stability Selection resulting in an over-representation of the
minority class and a drastic reduction in the number of observations in each subsample. Simulations are used to help
define the detection threshold as regards the average proportion of false signals. They are also used to compare the
performances of the proposed sampling scheme with that originally proposed for Stability Selection. Finally, we compare
the proposed method to the gamma Poisson shrinker, a disproportionality method, and to a lasso logistic regression
approach through an empirical study conducted on the French national pharmacovigilance database and two sets of
reference signals.
Results: Simulations show that the proposed sampling strategy performs better in terms of false discoveries and is faster
than the equiprobable sampling of Stability Selection. The empirical evaluation illustrates the better performances of the
proposed method compared with gamma Poisson shrinker and the lasso in terms of number of reference signals
retrieved.

1 Introduction
A challenging task in pharmacovigilance is the early identiﬁcation of the adverse eﬀects of marketed drugs. Active
pharmacological substances are expected to have side-eﬀects of which only some are discovered during the
preapproval developmental phase. Before a drug is approved, it goes through a long process of development
whose last step is its evaluation with clinical trials. However, as clinical trials are constrained by size, duration, and
patient heterogeneity, they cannot capture the full range of adverse drug reactions (ADRs) observed in widespread
clinical use. Post-marketing surveillance of ADRs spontaneously reported by healthcare providers is of crucial
importance to ensure the safe use of drugs in the long term. Indeed, once a drug receives its approval and is
1

Inserm UMR 1181, Biostatistics, Biomathematics, Pharmacoepidemiology and Infectious Diseases (B2PHI), F-94807 Villejuif, France
Institut Pasteur, UMR 1181, B2PHI, F-75015 Paris, France
3
Univ. Versailles St Quentin, UMR 1181, B2PHI, F-94807 Villejuif, France
4
University of Bordeaux, UMR 1219, F-33000 Bordeaux, France
5
Inserm UMR 1219, Bordeaux Population Health Research Center, Pharmacoepidemiology team, F-33000 Bordeaux, France
6
Department of Medical Pharmacology, CHU de Bordeaux, F-33000 Bordeaux, France
2

Corresponding author:
Ismaı̈l Ahmed, Inserm UMR 1181, Biostatistics, Biomathematics, Pharmacoepidemiology and Infectious Diseases (B2PHI), F-94807 Villejuif, France.
Email: ismail.ahmed@inserm.fr

786

Statistical Methods in Medical Research 27(3)

introduced on the market, a large number of people are rapidly exposed, even during the ﬁrst year of marketing,
and possibly in conditions diﬀerent from those evaluated in the clinical trials. Thus, improving the responsiveness
and the eﬃciency of the system is of major interest for public health. In France, more than 20,000 ADRs are
reported to the pharmacovigilance authorities annually, and this number has been constantly increasing in recent
years.1 At the end of 2014, the French database contained about 330,000 reports. Post-marketing databases held
by the World Health Organization (WHO) and the Food and Drug Administration (FDA) contain more than 10
and 5 millions reports, respectively. At a national or trans-national level, the accumulation of spontaneous reports
constitutes a huge quantity of data, which has led to the development of several automated signal detection tools.
The objective of this data mining exercise is to show up signals i.e. adverse event (AE)—drug combinations that
are statistically over-represented. The most obvious limitation of spontaneous reporting data is variable reporting.
Computerized statistical methods have been developed as ‘‘within’’ analysis tools drawing attention to
associations, for which no causal relationship can be directly deduced without further evaluation by
pharmacovigilance experts. In this context, minimizing the burden of false positives caused by further
investigation of generated signals is crucial.
Currently, the largest pharmacovigilance databases are routinely mined by automated signal detection tools. All
these methods rely on disproportionality analyses of counts aggregating patients’ reports for each drug-adverse
event pair. The information component method is used to screen the WHO safety database,2,3 the gamma Poisson
shrinker (GPS) method for the FDA reporting system4,5 and the proportional reporting ratio for the European
Medicines Agency EudraVigilance database.6,7 The value of these methods has been demonstrated in a number of
empirical studies8–13 as well as in several comparative simulation studies.14,15
Recently, Caster et al.16 analyzed individual spontaneous reports directly. In this new approach, the
observation becomes the individual report, the outcome is the presence/absence of a given AE, and the
covariates are all drug presence indicators (Figure 1). To select a small number of drugs, a Bayesian
multivariate logistic regression model17 aiming at parsimonious models has been used to shrink the coeﬃcients
of the regression toward zero, some to exactly zero. Maximum a posteriori estimates of the coeﬃcients are known

(a)

(b)

Figure 1. Data structure and notations for (a) logistic regression-based approaches and (b) disproportionality methods. n, J, and P
are the number of spontaneous reports, the number of AEs and the number of drugs respectively. For report i 2 f1,. . . ,ng, yij denotes
the presence or absence of AE j 2 f1,. . . ,Jg andPxip indicatesP
the presence orP
absence
P of drug p 2 f1,. . . ,Pg. njp denotes the number of
reports involving both AE j and drug p. n:p ¼ j njp , nj: ¼ p njp and n:: ¼ p j njp . Logistic regression-based approaches require
adjusting J regression models (one for each AE j) on very large databases. In comparison, disproportionality approaches are run only
once on a much smaller database (J  P).

Ahmed et al.

787

to be equivalent to those estimated by a logistic regression model penalized by an L1 norm constraint on the
coeﬃcients, i.e. the lasso (Least Absolute Shrinkage and Selection Operator18) logistic regression, a state-of-the-art
tool for high-dimensional data that is at the core of important ongoing work in variable selection. Caster et al.16
illustrated through two real case examples how multivariate regression-based approaches can handle two issues
speciﬁc to the disproportionality methods: (i) the masking eﬀect, a phenomenon whereby the background relative
reporting rate of an ADR is distorted by massive reporting on the ADR with a particular drug or drug group;
(ii) the confounding eﬀect due to co-reported drugs. Their study suggests that multivariate regression-based
approaches could be used for safety surveillance16,19 although the complete screening of very large spontaneous
reporting databases such as that held by the WHO is very challenging from a computational point of view.
Selection of appropriate detection thresholds is of paramount importance in pharmacovigilance as they directly
aﬀect the amount of assessment work to be done by pharmacovigilance experts. In the lasso regression framework,
this translates into the choice of the regularization parameter, l, which directly governs the number of selected
features. For computational reasons, empirical tuning for l was performed in the pioneering pharmacovigilance
application by Caster et al.:16 l was identical for all AEs and was chosen so as to provide the same number of
signals as the information component method. Classically, l is determined with regard to prediction error by
k-fold cross-validation. Nevertheless pharmacovigilance signal generation from spontaneous reporting data is not
concerned by prediction, but rather falls into the variable selection statistical framework. Theoretical works have
shown that optimal l for prediction leads to the inclusion of too many false-positive variables.20,21 More generally,
the choice of l for the purpose of variable selection is arguably more diﬃcult than for prediction. Recently,
Meinshausen and Bühlmann22 introduced Stability Selection, a general procedure combining subsampling with
high-dimensional selection algorithm such as the lasso. The idea of subsampling seems to be particularly adapted
to the issue of variable selection and, as shown by the authors, results in the selection of a more parsimonious set
of predictors than cross-validation.
The main purpose of the present work is to propose a multivariate regression-based method which exploits the
subsampling idea from Stability Selection and adapts it to the speciﬁcities of spontaneous reporting data, the latter
being characterized by their large size (especially in terms of observations), their binary nature and their sparsity
both in terms of drugs and adverse events. More precisely, we propose a nonequiprobable sampling scheme
resulting in an over-representation of the minority class (presence of a given AE) and a drastic reduction in the
number of observations in each subsample. Compared with the original random sampling strategy proposed in
Stability Selection, our proposed class-imbalanced subsampling lasso (CISL) algorithm is shown to be less
computationally demanding and to have greater statistical power. A simulation study using data from the
French national pharmacovigilance database was conducted in order (i) to compare both sampling strategies in
terms of both false positives and run times and (ii) to help choose the signal detection threshold with regard to the
average proportion of false signals. Finally, our approach is compared to the GPS disproportionality method and
an approach combining the lasso logistic regression and the Bayesian information criterion (BIC23). The
comparison is based on the French pharmacovigilance data and two sets of reference signals: one was
established by the French pharmacovigilance during the period 1996–2002 while the other was recently
proposed by the Observational Medical Outcomes Partnership.24 Code to implement the proposed method is
available in R on request from the corresponding author.

2 Methods
2.1 The logistic lasso
Let n be the number of spontaneous reports in the database, each of them possibly involving several drugs and
several AEs. They constitute the observations, i 2 f1, . . . , ng. Let J and P denote the total number of AEs and
drugs. These reports can be structured as two large matrices YnJ and XnP , corresponding to the matrices of AEs
and drugs, respectively (Figure 1). Both matrices contain binary variables attesting the presence/absence of the
event/drug in each report. For each AE j considered, j 2 f1, . . . , Jg, the logistic regression model can be written as
P
X
logitðPrð yij ¼ 1ÞÞ ¼ j0 þ
jp xip
ð1Þ
p¼1

where for each spontaneous report i, yij denotes the presence (1) or absence (0) of AE j and xip indicates the
presence or absence of the drug p 2 f1, . . . , Pg.
In the classical regression framework, for a given AE j, the regression parameters of model (1) are estimated by
likelihood maximization. Even if the number of observations, i.e. the reports, is far greater than the number

788

Statistical Methods in Medical Research 27(3)

of covariates, adjusting a regression model on several hundreds of regressors is likely to pose numerical issues.
More importantly, among this large number of candidate regressors, only a small number is expected to exhibit a
signiﬁcant association, making attractive the use of alternative strategies designed to produce a parsimonious set
of nonzero coeﬃcients. Among these strategies, the lasso,18 which is a penalized regression method, is appealing
since it forces regression coeﬃcients of ‘‘unimportant variables’’ to strictly equal 0. Applied to our setting, the lasso
consists in maximizing lpen
deﬁned as the log-likelihood (lj ) derived from the logistic regression model penalized by
j
a quantity proportional to the L1 norm of the regression coeﬃcients
P
X
lpen
¼ lj  lj
jjp j
ð2Þ
j
p¼1

lpen
j

in equation (2) depends on a regularization parameter, lj, which determines the strength of the penalization
term and thus the ﬁnal number of non-zero regression coeﬃcients: the larger lj, the fewer variables will be selected.
Classically, lj is determined with regard to prediction error by k-fold cross-validation. An alternative strategy,
recently evaluated in a variable selection context,25 relies on the use of the BIC model selection criterion: the lasso
solution is ﬁrst computed for a predeﬁned grid of regularization parameter values ljs. This results in the selection
of several sets of predictors, i.e. one for each lj tested value. The BIC is then calculated from a ‘‘classical’’ logistic
regression model for each of those sets. The ﬁnal set of predictors is the set minimizing the BIC.

2.2

Stability selection

The key idea of Stability Selection is to use subsampling to lessen the importance of the choice of regularization
parameter.
  The algorithm starts by applying lasso regressions on B sets randomly drawn without replacement of
size n=2 . The selection of a drug p 2 f1, . . . , Pg is based on the calculation of
^ lp ¼

B
h
i
1X
1 ^l,b
p 6¼ 0
B b¼1

ð3Þ

where ^l,b
p designates the regression coeﬃcient estimated with the lasso for drug p on subsample b and for a
value l of the regularization parameter. For sake of clarity, the j index referring to AEs is dropped in equation
(3) and in the remainder of the ‘‘Methods’’ section. Finally the set of selected variables is chosen according to
the maximum value of the probability of inclusion ^ lp over a set of regularization parameters. Meinshausen and
Bühlmann proposed a theoretical bound for setting the selection threshold according to the control of the
family-wise error rate multiple hypothesis criterion. However, this bound was found to be too conservative
in real applications in the ﬁeld of genome-wide association studies.26,27 Moreover, the family-wise error rate
itself may be considered a too conservative error criterion for the purpose of signal detection in
pharmacovigilance.

2.3

Class-imbalanced subsampling lasso

Spontaneous reporting data are characterized by their very large size in terms of observations and a very large
imbalance between the presence and absence of a given AE. Indeed, it is common to observe a ratio smaller
than 1:1000. Our CISL procedure accounts for this by using a nonequiprobable sampling scheme. For a given
AE, let us assume there are n1 observations whose values equal 1 (set S1) and n0 observations whose values
equal 0 (set S0). For a given subsample b, n1 observations are ﬁrst sampled with replacement from (S1). Second,
R observations are sampled with replacement from (S0). In practice, R was heuristically chosen as being roughly
equal to maxð4n1 , 4PÞ. The choice of 4n1 was based on an analogy with epidemiological case-control studies in
which it is argued that little power improvement is expected by increasing a ratio of controls to cases above
4:1.28 We used 4P to ensure a ‘‘reasonable’’ number of observations given the large number of predictors in the
models.
As regards the detection of important drugs, the CISL procedure consists in ﬁrst computing the following
quantity
^ bp ¼

E
h
i
1X
1 ^,b
p 40
E ¼1

ð4Þ

Ahmed et al.

789

where  2 f1, . . . , Eg corresponds to the number of drug predictors included in the model and E is the maximum
size of the models investigated with the logistic lasso. ^,b
p denotes the regression coeﬃcient estimated with the lasso
for drug p on subsample b and for a model including  drug predictors. ^ bp corresponds to the average number of
times drug p is selected over the diﬀerent models visited by the lasso in subsample b. From the B subsamples, we
thus obtain an empirical distribution of ^ bp . Using the same idea as for most of the current disproportionality
methods, our detection threshold is based on a quantile of the empirical distribution of ^ bp ; a drug p is selected if
the % quantile, q ð pÞ of this distribution is greater than 0. We performed simulations to obtain insights as to
which level  to choose so as to keep the proportion of false discoveries acceptable.
There are several diﬀerences between the statistics ^ lp (3) and ^ bp (4). First, as the aim of a signal detection tool
is to highlight potential adverse drug eﬀects, only drug–event combinations associated with positive
regression coeﬃcients are of interest. Second, the calculation of our statistic ^ bp (4) is performed for each
subsample over a set of models with increasing complexity, i.e. by increasing the number of predictors from
1 to E in the lasso regressions. This allows us to obtain an empirical distribution of ^ bp from the B subsamples
from which various quantiles q ð pÞ can be derived. Third, compared with formula (3), the calculation of ^ bp is
also more straightforward to implement. State-of-the-art implementations of the lasso (relying on coordinate
descent algorithms) such as in the glmnet R package maximize formula (2) for a grid of regularization
parameters calculated from the data. Calculation of our statistic ^ bp is achieved by running the lasso with a
relatively ﬁne grid of l in order to ensure that most of the models are visited and if some of them are missed,
averaging over them will still provide a good approximation of ^ bp . In comparison, because the grid of
regularization parameters is speciﬁc to each dataset, diﬀerent subsamples will result in diﬀerent grids of
regularization parameters, which makes the calculation of formula (3) diﬃcult. Of course, one can force all
subsamples to be analyzed with the same grid of regularization parameter values but doing so would necessarily
require some sort of calibration involving additional lasso runs in order to choose this grid. Finally, it is worth
noting that ^ lp is potentially calculated from models with various numbers of predictors since there is no guarantee
that a given value of l will result in the same number of predictors selected over the diﬀerent subsamples.

3 Simulations
The aim of the simulation
  study was twofold: ﬁrst, to compare the performances of the sampling strategy proposed
in CISL with the n=2 sampling proposed in Stability Selection; second to help choose .

3.1

Comparison set-up

AEs werePsimulated according to a logistic regression model: yi  Bernouilliði Þ, with i ¼ 1=ð1 þ
exp½0  Pp¼1 p xip Þ. As for the drug exposure matrix, we used the French pharmacovigilance database for
the period 1 January 1995 to 1 July 2002 (see section 4 for a description of the data), which contains n ¼ 117160
observations and P ¼ 1111 drugs. We investigated 25 scenarios that diﬀered according to
. the value of the intercept 0, the latter being used to simulate AEs of varying scarcity: 0 ¼ 8,  7,  6,  5,
and –4;
. the number of drugs associated with the AE: nTP ¼ 0, 10 and 30;
. the value of the regression coeﬃcients for the true nTP predictors: TP ¼ 1 and 2.
Five hundred datasets were generated for a given scenario. For each dataset, the true predictors, if any, were
randomly chosen from the P ¼ 1111 drugs. The number of subsamples B was set to 250 and the maximum size
of the models investigated with the lasso regressions was set to E ¼ 50 drug predictors. Performances of the
methods were measured by the average proportion of false discoveries (FDR) over the 500 datasets according to
the average number of signals detected over the 500 datasets. All the calculations were performed with the R
software, v3.1.2 (R-Foundation for Statistical Computing, Vienna, Austria), for which we used the glmnet R
package v2.0-229 to implement the lasso and the parallel R package v3.2.2 to perform parallel computing.
Performances were also measured in terms of run times using the microbenchmark R package v1.4-2 on a
subset of 10 of the 25 scenarios for which 25 datasets (out of the 500) were randomly selected. Both
subsampling procedures were applied 10 times on each of these 10  25 datasets to account for run time
variability. Run time performances were measured using the 8 cores of an iMac equipped with a quad core
3.5 GHz intel i7 processor.

790

3.2

Statistical Methods in Medical Research 27(3)

Results

Table 1 shows the average number of cases calculated over the 500 datasets for the 25 scenarios. It shows that we
investigated situations ranging from a 1:0 ratio of about 0.00033 (39/117160; 0 ¼ 8, nTP ¼ 0) to a ratio of about
0.027 (3137/117160; 0 ¼ 4, nTP ¼ 30 and TP ¼ 2).
Figure 2 summarizes the comparison between both sampling schemes for the
 25scenarios. For all scenarios, the
proposed imbalanced sampling performed better than or as well as the n=2 sampling in terms of FDR.
Performances were identical when there were no true predictors (Figure 2(a), (f), (k), (p), (u)). They were close
when the AE was rare and the true signals were weak (0 ¼ 8, TP ¼ 1; Figure 2(b) and (c)). They also tended to
be similar in the event of very common AEs and strong truesignals
 (0 ¼ 4, TP ¼ 2; Figure 2(x) and (y)). In all
other scenarios, the curve of CISL were below these of the n=2 sampling, indicating better performances of our
approach.
Table 2 shows a comparison
  of the run times of both sampling strategies. It shows that CISL was about 4 to
37 times faster than the n=2 sampling depending on the scenario settings; the rarer the AE, the higher the run
time ratio in favor of CISL. Table 2 also shows that running CISL took between 2 and 6 s per AE.
Table 3 shows the performances of the proposed sampling scheme in terms of FDR according to diﬀerent q .
The FDR increased with  and for a given q , Table 3 shows that the FDR decreased when the AE was more
common. In our experiments, q5% kept the FDR below 10% for all scenarios. In practice, given the low power to
detect true predictors in the event of rare AEs, q10% also seems to be a sensible choice.

4 Comparison with reference signal sets
Building realistic simulation procedures is particularly diﬃcult owing to the underlying spontaneous rate, which is
known to vary according to several factors such as the drug, the adverse event, the drug adverse event pair
considered and patients’ individual characteristics. A complementary approach to simulations is thus to
measure performances of methods on the basis of their ability to detect known previously validated signals.

4.1

The French pharmacovigilance database

The performance of our approach was evaluated and compared by an empirical analysis using data from the
French pharmacovigilance database. Spontaneous reporting of ADRs has been mandatory in France since 1984;
all physicians, pharmacists, midwives, and dentists must reports ADRs to their regional pharmacovigilance
centers, as mentioned in the French public health code. These reports are assessed, coded and recorded in the
national pharmacovigilance database, which is managed by the French medicines agency (Agence Nationale de
Se´curite´ du Me´dicament et des produits de sante´). The data were coded according to the Anatomical Therapeutic
Chemical hierarchy, 5th level, chemical subgroup30 for the drugs and the Preferred Term granularity of the
Medical Dictionary for Regulatory Activities31 for the AEs.

4.2

Sets of reference signals

Two distinct sets of reference signals were used. The ﬁrst one (RS1) corresponds to investigations launched by the
French Pharmacovigilance Technical Committee (Comite´ Technique de Pharmacovigilance) of the French
medicines agency, which is in charge of coordinating regulatory investigations related to ADRs. This reference
set was extracted from the 380 alerts launched by the committee during the period 1 January 1996 to 1 July 2002.
More details of these reference signals are provided in Ahmed et al.9 and Thiessard.32

Table 1. Average number of cases observed in the 25 simulated scenarios.
TP

nTP

0 ¼ 8

0 ¼ 7

0 ¼ 6

0 ¼ 5

0 ¼ 4

NA
1
1
2
2

0
10
30
10
30

39
41
45
47
65

106
111
122
127
173

290
301
327
342
463

783
818
893
913
1218

2106
2203
2381
2446
3137

Ahmed et al.

791

Figure 2. FDR according to the number of generated signals for the 25 scenarios in the simulation study. Each column corresponds
to different 0 ð8,  7,  6,  5,  4Þ and each row corresponds to a given setting as regards nTP (0, 10 or 30) and TP ð1,2Þ. The
black curve corresponds to n=2 sampling and the grey curve to CISL sampling. Each dot symbol (^,) corresponds to a particular
level of quantile q .
FDR: False discovery rate; CISL: class-imbalanced subsampling lasso.

The second set (RS2) was established by the Observational Medical Outcomes Partnership within the
framework of the analysis of large observational databases.24 The set comprises 165 positive controls and 234
negative controls for four adverse eﬀects: acute liver injury, acute kidney injury, acute myocardial infarction, and
upper gastrointestinal bleeding. The set was established on the basis of a systematic literature review and natural
language processing of structured product labeling. The correspondence between AE Preferred Terms codes used
for the French data and the four adverse eﬀect labels was obtained from Appendix A of a report by Duke et al.33

4.3

Comparison set-up

We used two diﬀerent extractions from the French pharmacovigilance database for the two reference signal sets.
For RS1, the database was restricted to the period 1 January 1995 to 1 July 2002 in order to match the period of
the alerts launched by the French Pharmacovigilance Technical Committee.1 For RS2, data from the period
1 January 2000 to 31 December 2010 were used. For the latter, reports from the period 1995–2000 were not
used because in 2010 the French medicines agency cleaned the data up to 2000. For both extractions, the sets of

792

Statistical Methods in Medical Research 27(3)
 
Table 2. Comparison
of run times (in seconds) between CISL and n=2 sampling for 10 of the 25 scenarios.
 
The CISL and n=2 columns contain run times averaged over the 25 selected datasets
 and
 represent the average
run time per AE for each of the scenarios. The last column contains the ratio of the n=2 sampling run times over
those of the CISL.
 
0
TP
nTP
# cases
CISL
n=2
Ratio
NA
2
NA
2
NA
2
NA
2
NA
2

8
8
7
7
6
6
5
5
4
4

0
30
0
30
0
30
0
30
0
30

39
65
106
173
290
463
783
1218
2106
3137

3.31
3.04
2.75
2.69
2.35
2.62
2.18
2.93
2.82
5.84

121.69
80.56
63.32
71.68
32.93
30.88
15.24
23.36
13.01
25.32

36.8
26.5
23.0
26.6
14.0
11.8
7.0
8.0
4.6
4.3

CISL: class-imbalanced subsampling lasso.

Table 3. FDR and average number of signals (# sig.) according to the simulated scenarios and different q% .
q1%

q5%

q10%

q15%

0

TP

nTP

# cases

FDR

# sig.

FDR

# sig.

FDR

# sig.

FDR

# sig.

8
8
8
8
8
7
7
7
7
7
6
6
6
6
6
5
5
5
5
5
4
4
4
4
4

0
1
1
2
2
0
1
1
2
2
0
1
1
2
2
0
1
1
2
2
0
1
1
2
2

0
10
30
10
30
0
10
30
10
30
0
10
30
10
30
0
10
30
10
30
0
10
30
10
30

39
41
45
47
65
106
111
122
127
173
290
301
327
342
463
783
818
893
913
1218
2106
2203
2381
2446
3137

0.010
0.006
0.004
0.010
0.003
0.002
0.002
0.002
0.003
0.001
0.000
0.000
0.000
0.001
0.002
0.000
0.000
0.000
0.002
0.003
0.000
0.000
0.000
0.006
0.004

0.01
0.01
0.01
0.16
0.63
0.00
0.01
0.03
0.48
1.90
0.00
0.05
0.16
1.26
4.21
0.00
0.24
0.86
2.60
8.00
0.00
0.90
2.74
4.32
12.89

0.082
0.048
0.051
0.052
0.020
0.020
0.032
0.016
0.012
0.008
0.006
0.000
0.003
0.008
0.008
0.000
0.002
0.001
0.006
0.007
0.002
0.005
0.005
0.009
0.007

0.09
0.07
0.10
0.43
1.27
0.02
0.07
0.14
0.90
3.05
0.01
0.12
0.41
1.83
5.83
0.00
0.43
1.48
3.30
10.07
0.00
1.31
3.91
5.09
15.02

0.308
0.249
0.222
0.204
0.096
0.128
0.119
0.083
0.055
0.030
0.036
0.026
0.020
0.023
0.016
0.008
0.017
0.019
0.010
0.010
0.002
0.016
0.009
0.014
0.010

0.35
0.33
0.42
0.86
2.14
0.13
0.21
0.37
1.32
4.16
0.04
0.23
0.69
2.30
7.04
0.01
0.63
2.08
3.80
11.46
0.00
1.71
4.87
5.63
16.44

0.796
0.741
0.650
0.541
0.230
0.474
0.425
0.309
0.208
0.055
0.126
0.132
0.074
0.047
0.022
0.050
0.034
0.043
0.016
0.013
0.016
0.026
0.019
0.017
0.012

1.54
1.54
1.60
2.15
3.69
0.65
0.75
0.98
2.08
5.26
0.14
0.47
1.11
2.77
8.21
0.05
0.85
2.72
4.31
12.66
0.02
2.01
5.83
6.12
17.65

FDR: false discovery rate.

drugs investigated were restricted to those present in at least 10 reports. The ﬁrst analysis was performed on
117160 reports and focused on the 68 AEs of RS1 and 1111 drugs. As regards the second analysis, it was
conducted on 219340 reports for the four adverse eﬀects of RS2 and for 1421 drugs. We also restricted RS1
and RS2 to pairs with some data support in the French pharmacovigilance data i.e. reported in at least three
reports during the period studied: RS1 contained 181 (positive controls) and RS2 142 (99 positive controls and 43
negative controls).

Ahmed et al.

793

The proposed methodology with  ¼ 5% and 10% was compared with GPS,4 a disproportionality method
applied to the aggregated data (Figure 1). In the Bayesian GPS model, the number of reports njp with both drug p
and AE j is assumed to be Poisson-distributed with parameter mjp ejp , where ejp is the expected counts according to
the hypothesis of independence between the reports of both drug and event in the contingency table. It is
n n
calculated as (see Figure 1 for notations) ejp ¼ j:n:::p . The prior parameter mjp is assumed to be distributed
according to a mixture of two gamma leading to the posterior distribution of mjp, which is also a mixture of
two gamma. A signal is generated if the 5% quantile of the posterior distribution of m is greater than 2.5
CISL was also compared with a strategy combining the lasso logistic regression and the BIC described at the
end of section 2.1. For the latter, we declared as signals all drugs positively associated with the AE under study for
the model minimizing the BIC. The maximum number of predictors in the investigated models was set to E ¼ 50.
The strategy was run with the speedglm R package v0.3 and parallel computations were used to calculate the BICs.
GPS was applied to the entire databases, i.e. including all the drugs and AEs mentioned in at least 10 reports.
The list of signals was then restricted to signals involving the AEs of RS1 and RS2.

4.4

Results

Figure 3 summarizes the results of our empirical study on RS1. Our approach retrieved more reference signals
than the other methods for a wide range of numbers of signals generated. On this dataset, the lasso-BIC performed
rather less well than the GPS method. CISL led to smaller numbers of generated signals than GPS: 520 with q5% ,
631 with q10% versus 765 with GPS. The lasso-BIC generated the largest number of signals (1045). For seven AEs,
the models selected with the lasso-BIC were the largest investigated. With regard to the results from RS2, Figure 4
shows that the performances of our approach were still better than those of GPS for a wide range of number of
signals generated. With regard to the lasso-BIC, it seems to order the signals better than GPS. On the other hand,
like for RS1, this approach generated signiﬁcantly more signals than the other methods: 160 for the lasso-BIC

Figure 3. Number of reference signals detected according to the number of signals generated in RS1. For CISL and GPS, signals are
ordered according to a given quantile. For the lasso-BIC, signals are ordered according to the p-values testing the significance of the
regression coefficients in the selected regression model.
GPS: gamma Poisson shrinker; BIC: Bayesian information criterion; CISL: class-imbalanced subsampling lasso.

794

Statistical Methods in Medical Research 27(3)

Figure 4. Number of reference signals detected according to the number of signals generated in RS2. For CISL and GPS, signals are
ordered according to a given quantile. For the lasso-BIC, signals are ordered according to the p-values testing the significance of the
regression coefficients in the selected regression model.
GPS: gamma Poisson shrinker; BIC: Bayesian information criterion; CISL: class-imbalanced subsampling lasso.

versus less than 100 for the other approaches. In addition, while our approach did not highlight any negative
controls, GPS highlighted 4 and the lasso-BIC 5.
Figure 5 shows that there is a large overlap between positive controls retrieved by GPS, lasso-BIC, and CISLq10% . Indeed, more than half of the positive controls detected by at least one the methods were detected by all of
them: 50 out of 90 for RS1 and 18 out of 33 for RS2.
Finally, running our approach on the 68 AEs of RS1 took about 320 s, i.e. 4.71 s per AE on average. The lassoBIC was slightly slower: 350 s for the 68 AEs, i.e. 5.15 s per AE on average.

5 Discussion
The use and development of advanced statistical methods is essential to unravel complex eﬀects in massive
pharmacovigilance datasets. The present work proposes to tailor and extend recent powerful algorithms
adapted to variable selection in order to improve the detection of ADR risks in pharmacovigilance. More
speciﬁcally, we exploit the idea of coupling subsampling with the lasso proposed in Stability Selection and to
adapt it to the very imbalanced nature of spontaneous reporting data.
Compared to the random sampling used in Stability Selection, the proposed CISL has several advantages. First,
the simulations show that the procedure results in the generation of fewer false positives for a variety of scenarios.
Second, the run time is greatly decreased owing to the large reduction in the number of observations in each
subsample. The over-representation of the minor class also eases the convergence of the algorithm, especially in the
event of rare AEs. These computational advantages could be even more pronounced for the very large databases
administered by the FDA and the WHO. Overall, while being simulated from pharmacovigilance spontaneous
reporting data, these simulation results are likely applicable to the analysis of large datasets with unbalanced
binary outcomes.

Ahmed et al.

795

Figure 5. Coverage of the true positives among GPS, lasso-BIC, and CISL-q10% for RS1 (a) and RS2 (b). The Figures also indicate in
brackets the number of signals detected by the methods.
GPS: gamma Poisson shrinker; BIC: Bayesian information criterion; CISL: class-imbalanced subsampling lasso.

The value of the proposed approach is also illustrated in our empirical study where it showed better overall
performances in terms of reference signals detected in comparison with the GPS method and a lasso-BIC based
approach. In terms of run times, it is obvious that none of the regression-based method can compete with any of
the disproportionality methods. However, CISL took only a few seconds to run on each AE of our data using a
desktop machine. Mining the complete French pharmacovigilance database would therefore take a couple of
hours by exploiting the multicore capacity of server/workstation type machines. Using subsampling is also
likely to make our approach more stable than the lasso-BIC since the latter requires running lasso logistic
regression multiple times on the whole database to compute the BIC. In addition, although the BIC is often
advocated as a criterion for performing variable selection, the combination of the results of both our simulations
and empirical studies suggests that its use may lead to a high rate of false discoveries. This result is in accordance
with a very recent simulation study (Figure 2)25 where the use of the lasso-BIC approach led to FDR estimates
larger than 0.25.
CISL relies on the choice of several parameters but we did not investigate the impact of varying them on its
performances. This notably includes R and the maximum size of the regression models investigated with the lasso
(set to 50). In addition, like for the majority of the signal detection methods in pharmacovigilance, our detection
strategy relies on the comparison of a prespeciﬁed quantile to a threshold. Simulations were performed in order
not to choose it arbitrarily. Nevertheless, a more satisfactory solution would be to base our detection rule directly
on an estimate of an error criterion such as the FDR. We initially investigated the use of a permutation-based
strategy that we previously proposed in the context of genome-wide association studies.27 However, the increase in
the run times appeared too prohibitive to be a realistic solution. Bringing lasso-based approaches into the
hypothesis-testing framework is an ongoing statistical research area.
Despite recent interest in pharmacovigilance based on the analysis of electronic health care data such as
electronic health records and administrative claims, there is still a need to improve statistical methods to mine
spontaneous reporting data, as they currently represent valuable and readily available resources for identifying
new adverse eﬀects of drugs. The recent introduction of large-scale regression-based approaches for mining
spontaneous reporting databases opens up interesting new perspectives for addressing some of the limitations
of the disproportionality methods. They also raise a number of methodological, computational and practical
issues, some of them being speciﬁc to the spontaneous reporting data. This work constitutes an attempt to
address some of these diﬃculties and to bring automated signal detection into the variable selection statistical
framework.

796

Statistical Methods in Medical Research 27(3)

Acknowledgements
The authors thank the regional pharmacovigilance centers and the ANSM for providing the pharmacovigilance database
dataset. They also wish to thank Francesco Salvo for his contribution in data preprocessing.

Declaration of conflicting interests
The author(s) declared no potential conﬂicts of interest with respect to the research, authorship, and/or publication of this
article.

Funding
The author(s) disclosed receipt of the following ﬁnancial support for the research, authorship, and/or publication of this article:
This work was supported by the French National Agency for Medicines and Health Products Safety (ANSM).

References
1. Thiessard F, Roux E, Miremont-Salame G, et al. Trends in spontaneous adverse drug reaction reports to the French
pharmacovigilance system (1986-2001). Drug Saf 2005; 28: 731–740.
2. Noren GN, Bate A, Orre R, et al. Extending the methods used to screen the who drug safety database towards analysis of
complex associations and improved accuracy for rare events. Stat Med 2006; 25: 3740–3757.
3. Bate A, Lindquist M, Edwards IR, et al. A data mining approach for signal detection and analysis. Drug Saf 2002; 25:
393–397.
4. DuMouchel W. Bayesian data mining in large frequency tables, with an application to the FDA spontaneous reporting
system. Am Statist 1999; 53: 177–190.
5. Szarfman A, Machado SG and O’Neill RT. Use of screening algorithms and computer systems to efficiently signal higherthan-expected combinations of drugs and events in the us FDA’s spontaneous reports database. Drug Saf 2002; 25:
381–392.
6. Evans SJ, Waller PC and Davis S. Use of proportional reporting ratios (PRRS) for signal generation from spontaneous
adverse drug reaction reports. Pharmacoepidemiol Drug Saf 2001; 10: 483–486.
7. Slattery J, Alvarez Y and Hidalgo A. Choosing thresholds for statistical signal detection with the proportional reporting
ratio. Drug Saf 2013; 36: 687–692.
8. Harpaz R, DuMouchel W, LePendu P, et al. Performance of pharmacovigilance signal-detection algorithms for the FDA
adverse event reporting system. Clin Pharmacol Ther 2013; 93: 539–546.
9. Ahmed I, Thiessard F, Miremont-Salamé G, et al. Early detection of pharmacovigilance signals with automated methods
based on false discovery rates: A comparative study. Drug Saf 2012; 35: 495–506.
10. Candore G, Juhlin K, Manlik K, et al. Comparison of statistical signal detection methods within and across spontaneous
reporting databases. Drug Saf 2015; 38: 577–587.
11. Hochberg AM and Hauben M. Time-to-signal comparison for drug safety data-mining algorithms vs. traditional signaling
criteria. Clin Pharmacol Ther 2009; 85: 600–606.
12. Alvarez Y, Hidalgo A, Maignen F, et al. Validation of statistical signal detection procedures in EudraVigilance postauthorization data: A retrospective evaluation of the potential for earlier signalling. Drug Saf 2010; 33: 475–487.
13. Pizzoglio V, Ahmed I, Auriche P, et al. Implementation of an automated signal detection method in the French
pharmacovigilance database: A feasibility study. Eur J Clin Pharmacol 2012; 68: 793–799.
14. Roux E, Thiessard F, Fourrier A, et al. Evaluation of statistical association measures for the automatic signal generation in
pharmacovigilance. IEEE Trans Inf Technol Biomed 2005; 9: 518–527.
15. Ahmed I, Thiessard F, Miremont-Salamé G, et al. Pharmacovigilance data mining with methods based on false discovery
rates: A comparative simulation study. Clin Pharmacol Ther 2010; 88: 492–498.
16. Caster O, Norén GN, Madigan D, et al. Large-scale regression-based pattern discovery: The example of screening the
WHO global drug safety database. Stat Anal Data Mining 2010; 3: 197–208.
17. Genkin A, Lewis DD and Madigan D. Large-scale Bayesian logistic regression for text categorization. Technometrics 2007;
49: 291–304.
18. Tibshirani R. Regression shrinkage and selection via the lasso. J Roy Stat Soc Ser B 1996; 58: 267–288.
19. Harpaz R, DuMouchel W, LePendu P, et al. Performance of pharmacovigilance signal-detection algorithms for the FDA
adverse event reporting system. Clin Pharmacol Ther 2013; 93: 539–546.
20. Leng CL, Lin Y and Wahba G. A note on the lasso and related procedures in model selection. Stat Sin 2006; 16:
1273–1284.
21. Meinshausen N and Bühlmann P. High-dimensional graphs and variable selection with the lasso. Ann Stat 2006; 34:
1436–1462.
22. Meinshausen N and Bühlmann P. Stability selection. J Roy Stat Soc 2010; 72: 417–473.

Ahmed et al.

797

23. Schwarz G. Estimating the dimension of a model. Ann Statist 1978; 6: 461–464.
24. Ryan PB, Schuemie MJ, Welebob E, et al. Defining a reference set to support methodological research in drug safety. Drug
Saf 2013; 36: S33–47.
25. Sabourin J, Valdar W and Nobel A. A permutation approach for selecting the penalty parameter in penalized model
selection. Biometrics 2015.
26. Alexander DH and Lange K. Stability selection for genome-wide association. Genet Epidemiol 2011; 35: 722–728.
27. Ahmed I, Hartikainen AL, Jarvelin MR, et al. False discovery rate estimation for stability selection: Application to
genome-wide association studies. Stat Appl Genet Mol Biol 2011; 10.
28. Grimes DA and Schulz KF. Compared to what? Finding controls for case-control studies. Lancet 2005; 365: 1429–1433.
29. Friedman J, Hastie T and Tibshirani R. Regularization paths for generalized linear models via coordinate descent. J Stat
Softw 2010; 33: 1–22.
30. Brown EG, Wood L and Wood S. The medical dictionary for regulatory activities (meddra). Drug Saf 1999; 20: 109–117.
31. Miller GC and Britt H. A new drug classification for computer systems: The ATC extension code. Int J Biomed Comput
1995; 40: 121–124.
32. Thiessard F. De´tection des effets inde´sirables des me´dicaments par un syste`me de ge´ne´ration automatise´e du signal adapte´ à la
base nationale française de pharmacovigilance. PhD Thesis, Université Bordeaux 2, France, 2004.
33. Duke J and Friedlin J. Exploration of four outcomes: Outcomes and labeling information, in conjunction with other
evidence. Technical report, 2011.

