Regulatory Science
title

Systematic Investigation of Time Windows
for Adverse Event Data Mining for
Recently Approved Drugs
Alan M. Hochberg, Manfred Hauben, MD, MPH, Ronald K. Pearson, PhD,
Donald J. O’Hara, and Stephanie J. Reisinger

The optimum timing of drug safety data mining for a
new drug is uncertain. The objective of this study was
to compare cumulative data mining versus mining with
sliding time windows. Adverse Event Reporting System
data (2001-2005) were studied for 27 drugs. A literature
database was used to evaluate signals of disproportionate reporting (SDRs) from an urn model data-mining
algorithm. Data mining was applied cumulatively and
with sliding time windows from 1 to 4 years in width.
Time from SDR generation to the appearance of a publication describing the corresponding adverse event was
calculated. Cumulative data mining and 1- to 2-year
sliding windows produced the most SDRs for recently

S

ince 1968, the Food and Drug Administration
(FDA) has maintained a computerized database
of adverse event reports, which is available to the
public.1 The database, which in its current form is
known as the Adverse Event Reporting System
(AERS) database, collects spontaneous reports of
adverse events made directly to the FDA or to drug
manufacturers. The focus of the database is on
postmarketing experience after FDA approval of a
drug. (A fraction of the data, however, derives
from clinical trials or from non-US experience with
compounds that are subsequently marketed in the

From ProSanos Corporation, Harrisburg, Pennsylvania (Mr Hochberg,
Dr Pearson, Mr O’Hara, Ms Reisinger); Pfizer Corporation, New York
(Dr Hauben); New York University School of Medicine, New York
(Dr Hauben); New York Medical College, Valhalla, New York (Dr Hauben);
and Brunel University, West London, UK (Dr Hauben). Submitted for publication December 11, 2008; revised version accepted February 5, 2009.
Address for correspondence: Alan Hochberg, ProSanos Corporation,
225 Market St, Suite 502, Harrisburg, PA 17102; e-mail: alan.hochberg@
prosanos.com.
DOI: 10.1177/0091270009333484

626 • J Clin Pharmacol 2009;49:626-633

approved drugs. In the first postmarketing year, data mining produced SDRs an average of 800 days in advance of
publications regarding the corresponding drug-event combination. However, this timing advantage reduced to zero
by year 4. The optimum window width for sliding windows
should increase with time on the market. Data mining may
be most useful for early signal detection during the first 3
years of a drug’s postmarketing life. Beyond that, it may be
most useful for supporting or weakening hypotheses.
Keywords:   Pharmacovigilance; data mining; time to signal
Journal of Clinical Pharmacology, 2009;49:626-633
© 2009 the American College of Clinical Pharmacology

United States.) One of the purposes of the database
is to identify adverse events associated with a drug
that occur at a low frequency, to the point where the
drug-event association cannot be readily appreciated during clinical trials.
In recent years, computerized data-mining algorithms (DMAs) have been applied to look for patterns
in the aggregate data that are not readily apparent
from the scrutiny of individual case reports.2,3 These
statistical algorithms generally look for signals of disproportionate reporting (SDRs),4 that is, drug-event
combinations that occur with a frequency higher than
that expected due to chance alone. The objective of
such data mining is to identify safety issues for pharmaceuticals in as timely a manner as possible while
minimizing the generation of SDRs that do not correspond to causal drug-event relationships.
Most pharmacovigilance data-mining publications have used adverse event report data in a cumulative fashion. As new adverse event reports arrive
(in quarterly updates for the case of the AERS database), the new reports are added to existing ones to
produce a total number of reports for each ­drug-event

TIME WINDOWS FOR DATA MINING
combination that begins with the earliest available
data and continues to the present. However, a number of investigators have considered specialized
algorithms that use sliding time windows, involving
the analysis of data that covers a fixed duration of
time backward from the present. Time windowing
has been studied for a limited number of drug-event
case studies by Ivkovic et al.5 Statistics that consider
windows in both space and time have been considered for adverse event detection, as well as for the
related problem of biosurveillance and disease outbreak detection, particularly by Kulldorff et al.6,7 In
this article, we consider whether sliding time windows offer any advantage when used with pharmacovigilance data-mining algorithms based on
disproportionality analysis that are typically used
with cumulative data.
In considering the time span of data to be used,
it is clear that cumulative data mining will capture the largest number of reports, both in the
numerator (ie, reports for the drug under study)
and the denominator or background (ie, reports
for other drugs as a basis for rate comparisons).
However, there is concern based on first principles
and from the biosurveillance literature that the
time-averaging effect of cumulative data mining
may cause the data-mining algorithm to respond
sluggishly.8 This might delay the recognition of
an SDR. A shorter time window might be more
responsive, on theoretical grounds at least. With
shorter windows, though, the question is whether
the relatively greater random fluctuations due to
smaller numbers in the numerator and denominator will result in reduced accuracy. Reduced
accuracy would mean increased numbers of falsepositive and false-negative SDRs (under various
definitions of those terms).
Here we report on a systematic comparison of
data-mining results where several windowing strategies are used. We focus on data mining in the first
5 to 7 years of a drug’s postmarketing life cycle,
when there is intense interest in postmarketing surveillance to identify safety issues that did not appear
during clinical trials.
METHODS
Data Sources and Selection of Drugs for Study
Input data for the study were taken from the public
release, known as the “Freedom of Information Act
(FOI)” version, of the FDA AERS database, covering
the period from the first quarter of 2001 through the

Regulatory Science

end of 2005. In the AERS database, adverse events
are described at the Medical Dictionary for Regula­
tory Activities (MedDRA)* Preferred Term (PT) level,
and terms at this level were used throughout the
study to describe SDRs. Obsolete MedDRA PTs were
updated to Version 10.1.
We conducted this study using a set of drugs that
we had previously investigated, for which a Reference
Event Database of published drug safety information
was available.9 These drugs were selected from a list
of new molecular entities (NMEs) initially approved
by the US FDA during 2000 to 2004. The intent was
to generate a “typical drug” list that includes both
drugs with serious safety issues, as well as relatively
innocuous ones. We obtained a list of 35 drugs in
a prespecified manner by considering the NMEs
approved in even years (2000, 2002, and 2004) and
by ordering this list alphabetically and choosing
every second drug, starting with the first drug.
We then eliminated 1 insulin formulation, 2 multiingredient drugs, and 1 pure-isomeric form of a previously marketed racemic compound because of the
ambiguity in determining the representation of these
drugs in the AERS database. To include some older
drugs and to make up for the lack of certain key
therapeutic categories in our drug set, we added on
an ad hoc basis the following: amlodipine, a cardiovascular drug approved in 1996; rosiglitazone, an
antidiabetic agent approved in 2000; and venlafaxine, an antidepressant approved in 1993. Table I
shows the complete list of 35 drugs for the study. The
footnotes describe further eliminations for unavoidable technical reasons, which brought the number of
drugs actually analyzed to 27. These unavoidable
eliminations took place after the data were generated
but before data analysis was conducted. Thus, they
were not influenced in a post hoc fashion by any
findings related to the results of the study.
Data Mining
Data mining was conducted with the urn model
algorithm,10 an algorithm that builds on classical
statistical testing methods.11 Data mining and
result-scoring software were implemented in S-Plus
(Insightful Corporation, Seattle, Washington). The
data-mining algorithm accepted a specified time
window of AERS data as input and produced a
corresponding list of SDRs.

*
MedDRA is a registered trademark of the International Federa­
tion of Pharmaceutical Manufacturers and Associations (IFPMA).

627

HOCHBERG ET AL
Table I   List of the 35 Drugs Included in the Study and Their Food
and Drug Administration Approval Datesa,b
Adefovir dipivoxil
(September 20, 2002)
Amlodipine
(July 31, 1992)
Apomorphine HCl
(April 20, 2004)
Aripiprazole
(November 15, 2002)
Azacitidine
(May 19, 2004)
Bivalrudin
(December 15, 2000)
Cevimiline
(January 11, 2000)
Clofarabine
(December 28, 2004)
Darifenacin HBr
(December 22, 2004)
Docosanol
(July 25, 2000)
Eletriptan HBr
(December 26, 2002)
Erlotinib HCl
(November 18, 2004)

Ezetimibe
(October 25, 2002)
Gadobenate meglumine
(November 24, 2004)
[Human secretin]
(April 9, 2004)
Icodextrin
(December 20, 2002)
Lanthanum carbonate
(October 26, 2004)
Mifepristone
(September 28, 2000)
Nitazoxanide
(November 22, 2002)
Olmesartan medoxomil
(April 25, 2002)
Ovine hyaluronidase
(March 4, 1996)
Oxcarbazepine
(June 14, 2000)
Pegaptanib sodium
(December 17, 2004)
Pregabalin
(December 30, 2004)

Rivastigmine
(April 21, 2000)
Rosiglitazone
(May 25, 1999)
Solifenacin
(November 19, 2004)
Telithromycin
(April 1, 2004)
Tinzaparin sodium
(June 14, 2000)
Treprostinil sodium
(May 21, 2000)
Trospium chloride
(May 28, 2004)
Unoprostone isopropyl
(August 3, 2000)
Venlafaxine
(December 22, 1999)
Voriconazole
(May 24, 2002)
Zonisamide
(May 27, 2002)

a. The study originally included Kaletra (lopinavir/ritonavir) and Septocaine (articaine/epinephrine). These drugs were eliminated after the study began
because validation revealed that the coding of the AERS data does not unambiguously distinguish between combination products and individual drugs
used concomitantly. Data reported here do not include those drugs.
b. Human secretin is used in diagnostic testing. It was one of the NMEs chosen for this study, but no records appeared for it in the AERS database in
the time period studied.

Categorization of SDRs
Using the Reference Event Database, SDRs were
assigned as described previously to one of the following mutually exclusive categories: INDICATION
[-related], GENERIC (terms such as unexpected therapeutic effect), DUPLICATES (SDRs that are artifacts
of duplicate reports in AERS), REGULATORY (SDRs
that are associated with FDA regulatory actions
regarding a drug), ORIGINAL LABEL (SDRs that correspond to terms on the original US prescribing
information for the drug), DEFINITE, PROBABLE,
POSSIBLE (SDRs for which information regarding
possible causality can be incorporated), MINIMAL
(SDRs for which there is a mention in the Reference
Event Database that does not provide any information related to potential causality), or LACKING
(SDRs that do not appear in the Reference Event
Database).

628  •  J Clin Pharmacol 2009;49:626-633

Time Windowing and Analysis
of Data-Mining Results
We evaluated 5 schemes of time windowing as
shown in Figure 1: cumulative, 1-year sliding window, 2-year sliding window, 3-year sliding window,
and 4-year sliding window. For each time window,
we tallied the number of SDRs in each of the categories defined above. SDR counts were broken down
into bins, based on the number of years from the
initial FDA approval of the drug until the appearance of the SDR. In addition to the total number of
SDRs, we considered SDRs in certain categories as
unlabeled/supported SDRs, that is, SDRs that did
not appear in the prescribing information for
the product at the time of its initial approval and
those for which there is at least some external supporting evidence. The categories considered as
“unlabeled/supported” are REGULATORY ACTION,

TIME WINDOWS FOR DATA MINING

Windowing
Scheme

700

2001

2002

2003

2004

2005
600

Cumulative
500

Total SDRs

1
2
3
4
5

400
300
200

One-Year Sliding
1
2
3
4
5

100
0
0

Two-Year Sliding
1
2
3
4
Three-Year Sliding
1
2
3

1

2
3
4
5
6
Years from Approval to SDR

Cumulative

1-y Sliding

3-y Sliding

4-y Sliding

7

2-y Sliding

Figure 2.   Total number of signals of disproportionate reporting
(SDRs) for the various windowing schemes, as a function of the
number of years from initial Food and Drug Administration
(FDA) approval of a drug.

Four-Year Sliding
1
2

Figure 1.   Time-windowing schemes used for data mining in this
study.

DEFINITE, PROBABLE, POSSIBLE, and MINIMAL.
We also categorized “persistent” SDRs versus total
SDRs. An SDR was considered “persistent” if it
remained above the detection threshold in all subsequent quarters after it was first detected. Each persistent SDR was tallied in the year in which it first
appeared. We further considered “lost” SDRs, which
became statistically nonsignificant as the windows
moved forward in time. (As noted below, this category accounted for only a small fraction of the
total.)
In addition to counting SDRs, we also tallied the
number of individual case safety reports associated
with each SDR.
We considered the relative timing of the SDR versus the appearance of the adverse event in the
Reference Event Database. In other words, did data
mining “pick up the signal” before it was published
and, if so, by how long? We calculated the time lag
between appearance of the SDR and the corresponding appearance of a pub­lication in the Reference
Event Database. By convention for this analysis, the
Regulatory Science

SDR appearance date was taken to be the closing
date of the AERS data release in which the SDR was
first detected. We did not attempt to account for the
publication lag (typically 6-9 months) between the
close of the AERS quarter and the actual public
availability of the data. An adjustment for outliers
was necessary. Because a few of the Reference Event
Database entries went far back in time (as early as
1971), lag times were truncated at 5 years. Any lag
time greater than 5 years was entered into the calculation as “5 years.” This truncation affects less than
1% of the data items but eliminates the undue influence of outliers.
Finally, we examined the SDRs based on the various sources of external evidence in the Reference
Event Database that they matched. The external
evidence categories were Original Label, Generic/
Indication/Duplicate, Formularies and Reviews,
Label Changes and Regulatory Actions, Clinical
Trials, and Case Reports and Case Series.
RESULTS
SDRs, Unlabeled/Supported SDRs,
and Persistent SDRs
The total number of SDRs in each time window is
shown in Figure 2. Cumulative data mining always

629

HOCHBERG ET AL

Persistent Unlabeled Supported SDRs

90

Unlabeled Supported SDRs

80
70
60
50
40
30
20
10
0
0

1

2

3

4

5

6

7

Years from Approval to SDR
Cumulative

1-y Sliding

3-y Sliding

4-y Sliding

2-y Sliding

400
350

Persistent SDRs

300
250
200
150
100
50
0

1

2
3
4
5
6
Years from Approval to SDR

Cumulative
3-y Sliding

1-y Sliding

7

2-y Sliding

4-y Sliding

Figure 4.   Number of persistent signals of disproportionate
reporting (SDRs) for the various windowing schemes, for each
year after initial Food and Drug Administration (FDA) approval
of a drug.

produced the greatest number of SDRs. For sliding
windows of various widths, the curves cross. That
is, in the early years of a drug’s life on the market,
the narrow windows (1-year and 2-year sliding
630  •  J Clin Pharmacol 2009;49:626-633

45
40
35
30
25
20
15
10
5
0

0

1

2

3

4

5

6

7

Years from Approval to SDR

Figure 3.   Number of unlabeled/supported signals of disproportionate reporting (SDRs) for the various windowing schemes, as a
function of the number of years from initial Food and Drug
Administration (FDA) approval of a drug.

0

50

Cumulative
3-y Sliding

1-y Sliding
4-y Sliding

2-y Sliding

Figure 5.   Number of persistent signals of disproportionate
reporting (SDRs) that fall in the unlabeled/supported categories,
for each year after initial Food and Drug Administration (FDA)
approval of a drug.

windows) actually yield a higher number of SDRs
than the wider windows. In the later years, the
wider windows (3-year and 4-year) produce more
SDRs. The overall falloff at 7 years is simply due to
censoring in this particular study. (The drugs are
less than 7 years old.)
Figure 3 shows that similar trends hold for the
category of unlabeled/supported SDRs as for the
overall SDR total. Figure 4 shows persistent SDRs
(ie, newly arising SDRs) for each year. We note
that the number of persistent SDRs reaches a peak
in the second year of postmarketing experience.
This is consistent with the so-called Weber effect,
which indicates that the peak of adverse event
reporting activity for a typical drug occurs in this
time frame.12
Figure 4 clearly shows the crossing of the curves
between the shorter sliding windows and the longer
ones. In years 3 to 7, it can be seen that the longer
sliding windows actually yield more persistent
SDRs than cumulative data mining does. Figure 5
shows persistent unlabeled/supported SDRs for each
year, and these curves follow the same trends as in
Figure 4.
Figure 6 shows the percentage of total SDRs
that fall in the unlabeled/supported category. Here
not much difference is seen among the various
­windowing schemes, but all of them exhibit a
U-shaped curve. A possible mechanism for this can

40.0%

120

Average Case Reports per SDR

Percent Unlabeled Supported SDRs

TIME WINDOWS FOR DATA MINING

35.0%
30.0%
25.0%
20.0%
15.0%
10.0%
5.0%
0.0%
1

2

3

4

5

6

7

Years from Approval to SDR
Cumulative
3-y Sliding

1-y Sliding

60
40
20

4-y Sliding

SDR Sources by Year after Approval

80%

60%

40%

20%

1

2

Original label

3
4
5
Years After Approval

6

7

Generic/Indication/Duplicate

Formularies and reviews

Case reports & series

Label changes & regulatory actions

Clinical trials

Figure 7.   Sources of the Reference Event Database entries that
match signals of disproportionate reporting (SDRs), for each
year after initial Food and Drug Administration (FDA) approval
of a drug.

Regulatory Science

1

2

Cumulative
3-y Sliding

100%

0

0

3

4

5

6

7

Years from Approval to SDR
2-y Sliding

Figure 6. Percentage of signals of disproportionate reporting
(SDRs) that fall in the unlabeled/supported categories, for each
year after initial Food and Drug Administration (FDA) approval
of a drug.

Fraction of Total SDRs

80

0
0

0%

100

1-y Sliding

2-y Sliding

4-y Sliding

Figure 8.   Average number of individual case safety reports
associated with each signal of disproportionate reporting (SDR),
for each year after initial Food and Drug Administration (FDA)
approval of a drug.

be seen by examining Figure 7, which categorizes
SDRs based on matching to particular sources of
data in the Reference Event Database. The bottommost 4 categories—Case Reports, Clinical Trials,
Label Changes, and Formularies—comprise the unlabeled/supported SDRs. In the first year, we see that
the unlabeled/supported SDRs are made up heavily
of SDRs appearing in label changes, formularies, and
review articles. This might reflect publication activity regarding a newly approved drug, along with
fine-tuning of the label in response to safety feedback. We also note a large number of SDRs in the
“Generic/Indication/Duplicate” category. This category is domi­nated by indication-related terms. In
other words, during the first year, the indication-related terms for the drug produce a flurry of SDRs,
which decreases somewhat in subsequent years as
these are “used up.” In other words, there are a limited number of indication-related terms, and eventually most of them appear as SDRs. It is also possible
that, as experience with the drug increases, the
reporting of indication-related terms is diluted, due
to a ­proportionately increase reporting of nonindication related events.
Tracing along the top of Figure 7, we see that
events that are on the original label for the drug
appear predominantly in year 2 and then slowly
diminish starting in year 4, presumably as these too
are used up.

631

HOCHBERG ET AL

Time from U/S SDR to Reference Event
Database Entry (days)

800
600
400
200
0

0

1

2

3

4

5

6

7

8

­ egative numbers indicating that the SDR came first.
n
Early in the drug’s life, cumulative data mining and
short windows give SDRs the greatest lead time.
After 3 to 4 years, the curves for the various window
widths converge, and the time lag between SDR and
publication disappears. In subsequent years, on
average, the SDR actually lags the publication in the
Reference Event Database.

-200

DISCUSSION

-400
-600

Choice of Windowing Scheme

-800

-1000
Years from Approval to SDR
Cumulative
1-y Sliding
2-y Sliding
3-y Sliding
4-y Sliding

Figure 9.   For unlabeled/supported signals of disproportionate
reporting (SDRs), time from Reference Event Database publication to detection of the SDRs. Negative numbers indicate that
detection of the SDR preceded publication regarding the corresponding adverse event.

As time progresses, we see in Figure 7 increasing
numbers of case reports and case series, with a long lag
time following the approval of the drug. These represent rare cases of adverse reactions that are of enough
concern, and clearly enough attributable to the drug,
for someone to write an article about them that meets
the standards of peer review. At 7 years after drug
approval, such case reports and case series become a
significant component of the Reference Event Database,
among entries that match unlabeled/supported SDRs.
Individual Case Safety Reports per SDR
Figure 8 shows the average number of individual
case safety reports associated with each SDR. This
relates directly to the safety-physician workload in
reviewing SDRs. No clear and consistent difference
is apparent with respect to the various windowing
schemes (cumulative vs 1-, 2-, 3-, or 4-year sliding).
There is a dramatic increase in reports per SDR as
the drug remains on the market for longer periods.
Timing of SDR Appearance vs Reference
Event Database Entry
Figure 9 shows the actual time from Reference Event
Database publication to SDR appearance, with

632  •  J Clin Pharmacol 2009;49:626-633

In terms of the number of total SDRs, persistent SDRs,
or unlabeled/supported SDRs, none of the sliding
window schemes appeared to be uniformly superior
to simple cumulative data mining, in other words,
including all data from the time of drug approval to
the present. However, there is a suggestion that one
could optimize the number of persistent unlabeled/
supported SDRs (ie, desirable SDRs) by “shifting
gears”: using cumulative data mining or narrow, 1- to
2-year sliding windows early in the postapproval
life of the drug and then switching to wider sliding
windows around years 4 to 5 of the drug’s life.
Evolution of Matching Reference
Event Database Entries
We noted a pattern over time in the matching of
SDRs to entries in the Reference Event Database.
Early in the life of the drug, SDRs related to the drug
indication predominate, along with SDRs related to
label changes and early appearing review articles.
There then follows a period where many SDRs
describe adverse events that appear on the original
label for the product. As these are a fixed “nonrenewable” set of adverse events, they are gradually
used up over the years. In later years, case reports
and case series for drug safety issues are published,
and SDRs appear that match these.
Lead Time Between SDR and Reference
Event Database Entry
We noted that the lead time for SDRs is greater early
on, then disappears by about year 5 of the drug’s
postmarketing life. Here we did not see significant
differences among windowing schemes. In interpreting these results, we should note that an SDR may be
worthwhile even if it occurs at or near the same time
as a publication regarding the same adverse event. In

TIME WINDOWS FOR DATA MINING
this context, it would be “hypothesis supporting.” It
has frequently been emphasized that data-mining
results cannot be used to demonstrate a causal relationship between a drug and an event. On the other
hand, the finding of an SDR corresponding to a published case report would certainly be of interest to
those responsible for risk management with respect
to a particular product and would generally indicate
that the association between the drug and the event,
whether causal or not, extends beyond a single published case.

Financial disclosure: This work was funded by a grant from
the Pharmaceutical Research and Manufacturers Association
(PhRMA) to ProSanos Corporation. Dr Manfred Hauben, as a representative of the funding committee of PhRMA, participated in
the design of the study, the interpretation of data, and the review
of the manuscript. Alan Hochberg, Ronald Pearson, Donald
O’Hara, and Stephanie Reisinger are employees of ProSanos
whose work was funded in part by the PhRMA grant. They were
responsible for the design and conduct of the study, data collection management and analysis, interpretation of the data, and
generation of the manuscript.

Limitations of the Study

REFERENCES

We acknowledge a number of significant limitations
to this study. As the title of this article states, we
studied data mining in the peri-approval period and
cannot estimate how our conclusions might apply to
the mining of older drugs.
We also cannot say how the results of this study
would generalize to other particular data-mining algorithms. We note that with the urn model studied here,
SDRs are generally persistent across time and are not
lost as time goes forward. For other algorithms, it is
possible that the loss of SDRs as time moves forward
is a significant phenomenon, and this might require a
different approach to time windowing.

1. Syed RA, Marks NS, Goetsch RA. Spontaneous reporting in
the United States. In: Strom BL, Kimmel SE, eds. Textbook of
Pharmacoepidemiology. West Sussex, England: John Wiley;
2006:91-116.
2. Gould AL. Practical pharmacovigilance analysis strategies.
Pharmacoepidemiol Drug Saf. 2003;12:559-574.
3. Meyboom RHB, Lindquist M, Egberts ACG, Edwards IR. Signal
selection and follow-up in pharmacovigilance. Drug Saf.
2002;25:459-465.
4. Hauben M, Reich L. Communication of findings in pharmacovigilance: use of the term “signal” and the need for precision in
its use. Eur J Clin Pharmacol. 2005;61:479-480.
5. Ivkovic S, Saunders G, Ghosh R, et al. Using association
and overlapping time window approach to detect drug reaction
signals. In: Proceedings of the 2005 International Conference
on Computational Intelligence for Modeling, Control and
Automation, and International Conference on Intelligent
Agents, Web Technologies and Internet Commerce (CIMCAIAWTIC ’05): Volume 1. Washington, DC: IEEE Computer Society;
2005:1045-1053.
6. Kulldorff M, Mostashari F, Duczmal L, et al. Multivariate scan
statistics for disease surveillance. Stat Med. 2007;26:1824-1833.
7. Lieu TA, Kulldorff M, Davis RL, et al. Real-time vaccine safety
surveillance for the early detection of adverse events. Med Care.
2007;45(suppl 2):S89-S95.
8. Brown SM, Benneyan JC, Theobald DA, et al. Binary cumulative sums and moving averages in nosocomial infection cluster
detection. Persist Infect Dis. 2002;8:1426-1432.
9. Hochberg AM, Hauben M, Pearson RK, et al. An evaluation of
three signal detection algorithms using a highly inclusive reference event database. Drug Saf. In press.
10. Hochberg AM, Reisinger SJ, Pearson RK, et al. Using data mining to predict safety actions from FDA adverse event reporting
system data. Drug Inf J. 2007;41:633-644.
11. Ross SM. Introduction to Probability Models. New York:
Academic Press; 1972.
12. Weber JCP. Epidemiology of adverse reactions to nonsteroidal antiinflammatory drugs. In: Rainsford KD, Velo GP, eds.
Advances in Inflammation Research: Volume 6. New York:
Raven; 1984:1-6.

CONCLUSION
This study did not demonstrate clear superiority of
either cumulative data mining or a sliding time window approach. However, it appears that, for sliding
time windows, it is best if the width of the window
increases during the postmarketing period for the
drug under study. We have noted that early in a drug’s
postmarketing history, data mining can identify signals of disproportionate reporting in advance of the
publication of reports for corresponding adverse
events in the peer-reviewed literature or other wellregulated data sources. This timing advantage dwindles in later years, and it may be inferred from the
data presented here that the best use of data mining
during those years is for supporting or refuting hypotheses generated by the appearance of case reports and
case series in the literature rather than for hypothesis
generation and early detection of safety signals.
The authors thank David Goldsmith, Lawrence Gould, and
David Madigan for review of the manuscript.

Regulatory Science

633

